{
  "data": [
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa tujuan utama data science ",
              "id": 2843,
              "answers": [
                {
                  "answer_id": 1217,
                  "document_id": 995,
                  "question_id": 2843,
                  "text": "tujuan utama data science adalah menganalisis data  menemukan pola  dan membuat prediksi di masa depan",
                  "answer_start": 124,
                  "answer_end": 226,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data science atau sains data adalah kombinasi dari beberapa disiplin ilmu  seperti ilmu komputer  matematika  dan statistik tujuan utama data science adalah menganalisis data  menemukan pola  dan membuat prediksi di masa depan dalam sains data  ilmu komputer digunakan untuk pengenalan pola  visualisasi  pergudangan data  dan komputasi kinerja tinggi matematika digunakan untuk pemodelan matematika  sedangkan statistik digunakan untuk pemodelan statistic dan stohestic serta probabilitas dengan menggunakan teori dan teknik dari berbagai bidang  data science membantu mengumpulkan  membersihkan  mengintegrasikan  menganalisis  memvisualisasikan  dan berinteraksi dengan data untuk menghasilkan produk data yang bermanfaat bagi para pengambil keputusan di berbagai industri seperti sains  teknik  ekonomi  politik  keuangan  dan pendidikan",
          "document_id": 995
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa output dari data science?",
              "id": 3217,
              "answers": [
                {
                  "answer_id": 1570,
                  "document_id": 998,
                  "question_id": 3217,
                  "text": "data science menghasilkan output berupa pengetahuan dan wawasan domain  analisis statistik  visualisasi data  rekayasa data  dan kemampuan komputasi lanjutan",
                  "answer_start": 154,
                  "answer_end": 311,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data science menggunakan teknik dan pengetahuan dari disiplin ilmu tersebut untuk mengolah data  menganalisis pola  dan membuat prediksi dalam prosesnya  data science menghasilkan output berupa pengetahuan dan wawasan domain  analisis statistik  visualisasi data  rekayasa data  dan kemampuan komputasi lanjutan data science digunakan oleh para profesional yang terlibat dalam bidang tersebut data science menjadi penting dalam era digital saat ini karena dapat mengolah data secara efisien dan menghasilkan wawasan yang berharga dari data tersebut dengan demikian  data science memanfaatkan berbagai elemen untuk menghasilkan pemahaman yang mendalam tentang data",
          "document_id": 998
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Aspek apa saja yang termasuk ke dalam bidang data science?",
              "id": 3070,
              "answers": [
                {
                  "answer_id": 1411,
                  "document_id": 997,
                  "question_id": 3070,
                  "text": "data science adalah bidang yang menggabungkan berbagai aspek  termasuk data engineering  metode ilmiah  matematika  statistik  komputasi lanjutan  visualisasi  mindset hacker  dan keahlian domain ",
                  "answer_start": 490,
                  "answer_end": 686,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "matematika digunakan untuk pemodelan matematika  sedangkan statistik digunakan untuk pemodelan statistic dan stohestic serta probabilitas dengan menggunakan teori dan teknik dari berbagai bidang  data science membantu mengumpulkan  membersihkan  mengintegrasikan  menganalisis  memvisualisasikan  dan berinteraksi dengan data untuk menghasilkan produk data yang bermanfaat bagi para pengambil keputusan di berbagai industri seperti sains  teknik  ekonomi  politik  keuangan  dan pendidikan data science adalah bidang yang menggabungkan berbagai aspek  termasuk data engineering  metode ilmiah  matematika  statistik  komputasi lanjutan  visualisasi  mindset hacker  dan keahlian domain data science menggunakan teknik dan pengetahuan dari disiplin ilmu tersebut untuk mengolah data  menganalisis pola  dan membuat prediksi dalam prosesnya  data science menghasilkan output berupa pengetahuan dan wawasan domain  analisis statistik  visualisasi data  rekayasa data  dan kemampuan komputasi lanjutan",
          "document_id": 997
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "siapa yang menulis paper bagus tentang data science atau sains data ?",
              "id": 3112,
              "answers": [
                {
                  "answer_id": 1455,
                  "document_id": 994,
                  "question_id": 3112,
                  "text": "ada paper bagus yang ditulis oleh david donoho  2017 ",
                  "answer_start": 1,
                  "answer_end": 54,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " ada paper bagus yang ditulis oleh david donoho  2017   seorang profesor statistika dari stanford university yang bergelut dalam sains data donoho mempertegas bahwa tukey  1962  telah mendorong perlunya reformasi statistika dari fokus pada deskripsi dan inferensi menuju akuisisi data dan prediksi inilah yang kemudian dikenal sebagai data science atau sains data  clevaland  2001   yang menjadi istilah pertama kali untuk konsep tersebut data science atau sains data adalah kombinasi dari beberapa disiplin ilmu  seperti ilmu komputer  matematika  dan statistik tujuan utama data science adalah menganalisis data  menemukan pola  dan membuat prediksi di masa depan",
          "document_id": 994
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja faktor penentu jst?",
              "id": 3229,
              "answers": [
                {
                  "answer_id": 1586,
                  "document_id": 1035,
                  "question_id": 3229,
                  "text": "faktor penentu jst ada tiga yaitu pola hubungan antar neuron  fungsi aktivasi  dan metode untuk menentukan bobot penghubung ",
                  "answer_start": 258,
                  "answer_end": 382,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " jaringan syaraf manusia terdiri dari dendrit  akson  sinapsis  dan soma  sedangkan untuk jaringan syaraf tiruan atau disebut juga artificial neural network merupakan sistem pemroses informasi yang memiliki karakteristik mirip dengan jaringan syarat biologi faktor penentu jst ada tiga yaitu pola hubungan antar neuron  fungsi aktivasi  dan metode untuk menentukan bobot penghubung sebuah jst memiliki sejumlah neuron yang tersusun pada sejumlah layer atau lapisan sebagai berikut  satu layer input berfungsi menerima masukan  satu layer output untuk menghasilkan output dan layer tersembunyi yaitu layer di antara layer input dan output ada dua jenis jst berdasarkan layer yakni single layer dan multi layer sedangkan jenis jst yang berdasarkan aliran sinyal juga memiliki dua jenis yakni feedfoward dan recurrent karakterisik jst lapis tunggal cocok untuk pengenalan pola karena semua unit dihubungkan dengan unit output  unit input output dalam satu lapisan  layer  tidak saling berhubungan  bobot wji    bobot hubungan unit input i dengan unit input j  bobot saling independen",
          "document_id": 1035
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara menerapkan knn imputation dengan tepat?",
              "id": 3094,
              "answers": [
                {
                  "answer_id": 1435,
                  "document_id": 1038,
                  "question_id": 3094,
                  "text": "untuk menerapkan knn imputation dengan tepat  sebaiknya knn imputation hanya dihitung pada latih saja  lalu hasil yang didapat baru diterapkan pada data uji",
                  "answer_start": 245,
                  "answer_end": 401,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "pada knn imputation  sampel baru diperhitungkan dengan menemukan sejumlah sampel dalam training set yang  paling dekat  dengannya  kemudian nilai sampel yang kosong pada kolom tertentu diisi berdasarkan nilai sample terdekat pada kolom tersebut untuk menerapkan knn imputation dengan tepat  sebaiknya knn imputation hanya dihitung pada latih saja  lalu hasil yang didapat baru diterapkan pada data uji untuk mendapatkan hasil terbaik  paramater pada knn imputation juga dapat dieksperimen parameter tersebut seperti ukuran jarak  jumlah tetangga terdekat  dan bobot iterative imputation adalah proses di mana setiap fitur dimodelkan sebagai fungsi dari fitur lainnya  misalnya sebagai masalah regresi untuk memprediksi missing value",
          "document_id": 1038
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "mengapa fungsi aktivasi linier mengubah jaringan saraf menjadi hanya satu lapisan ",
              "id": 2872,
              "answers": [
                {
                  "answer_id": 1252,
                  "document_id": 1043,
                  "question_id": 2872,
                  "text": " karena kombinasi linear dari fungsi linear tetaplah linear fungsi",
                  "answer_start": 322,
                  "answer_end": 388,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "jadi tidak mungkin untuk kembali dan memahami yang bobot di input neuron dapat memberikan prediksi yang lebih baik dan semua lapisan jaringan saraf runtuh menjadi satu  dengan linier fungsi aktivasi  tidak peduli berapa banyak lapisan dalam saraf jaringan  lapisan terakhir akan menjadi fungsi linier dari lapisan pertama  karena kombinasi linear dari fungsi linear tetaplah linear fungsi jadi fungsi aktivasi linier mengubah jaringan saraf menjadi hanya satu lapisan model jaringan saraf modern menggunakan fungsi aktivasi non linier mereka mengizinkan model untuk membuat pemetaan kompleks antara input dan output jaringan  yang penting untuk belajar dan memodelkan data yang kompleks  seperti gambar  kumpulan video  audio  dan data yang tidak linier atau berdimensi tinggi mereka mengizinkan backpropagation karena mereka punya fungsi turunan yang terkait dengan input dan juga memungkinkan  penumpukan  beberapa lapisan neuron untuk membuat jaringan saraf yang dalam",
          "document_id": 1043
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja jenis jst berdasarkan layer?",
              "id": 3232,
              "answers": [
                {
                  "answer_id": 1589,
                  "document_id": 1044,
                  "question_id": 3232,
                  "text": "ada dua jenis jst berdasarkan layer yakni single layer dan multi layer ",
                  "answer_start": 0,
                  "answer_end": 71,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "ada dua jenis jst berdasarkan layer yakni single layer dan multi layer sedangkan jenis jst yang berdasarkan aliran sinyal juga memiliki dua jenis yakni feedfoward dan recurrent karakterisik jst lapis tunggal cocok untuk pengenalan pola karena semua unit dihubungkan dengan unit output  unit input output dalam satu lapisan  layer  tidak saling berhubungan  bobot wji    bobot hubungan unit input i dengan unit input j  bobot saling independen sedangkan jst lapis banyak memiliki karakteristik sebagai berikut  ada lapisan lain selain lapisan input dan output  disebut lapisan   layer tersembunyi   jumlah layer tersembunyi bisa 1 atau lebih  unit dalam satu layer tidak saling berhubungan dapat menyelesaikan masalah yang lebih kompleks  dan proses pelatihan lebih kompleks dan lama jaringan recurrent adalah jaringan yang terdapat neuron output yang memberi sinyal pada unit input sering disebut feedback loop fungsi aktivasi adalah  gerbang  matematis di antara input yang memberi makan neuron saat ini dan outputnya menuju lapisan berikutnya",
          "document_id": 1044
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja kegunaan dari metode group by?",
              "id": 3114,
              "answers": [
                {
                  "answer_id": 1457,
                  "document_id": 1126,
                  "question_id": 3114,
                  "text": " metode  group by  dapat membagi data menjadi grup berdasarkan beberapa kriteria  menghitung statistik  atau menerapkan fungsi  untuk setiap kelompok  dan mirip dengan fungsi dplyr   dalam r ",
                  "answer_start": 753,
                  "answer_end": 944,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "untuk contoh methods yaitu head  n    tail  n   sebagai first atau last n rows  describe   sebagai generate descriptive statistics  hanya untuk kolom numeric   max    min   sebagai return max atau min values untuk semua kolom numerik  mean    median   untuk return mean atau median values untuk semua kolom numerik  std   sebagai standard deviation  sample  n   sebagai return random sample dari data frame  dropna   sebagai drop all records dengan missing values untuk memilih kolom dalam data frame dapat menggunakan dua metode  metode pertama dengan subset data frame menggunakan nama kolom contohnya df  sex   dan metode kedua dengan menggunakan nama kolom contohnya df sex selanjutnya  dalam pandas memiliki data frame groupby method di mana dengan metode  group by  dapat membagi data menjadi grup berdasarkan beberapa kriteria  menghitung statistik  atau menerapkan fungsi  untuk setiap kelompok  dan mirip dengan fungsi dplyr   dalam r  nantinya setelah objek groupby dibuat barulah dapat menghitung berbagai statistik untuk setiap kelompok pada groupby ini terdapat catatan kinerjanya yaitu tidak ada pengelompokan atau pemisahan terjadi sampai diperlukan  membuat objek groupby hanya memverifikasi bahwa telah melewati pemetaan yang valid  secara default kunci grup diurutkan selama operasi groupby  dan untuk lulus sort   false untuk potensi speedup seperti dalam menghitung gaji rata rata untuk setiap peringkat profesor dengan df",
          "document_id": 1126
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa manfaat clustering pada bidang keamanan?",
              "id": 3258,
              "answers": [
                {
                  "answer_id": 1617,
                  "document_id": 1085,
                  "question_id": 3258,
                  "text": " clustering pada bidang keamanan bank internet dapat digunakan untuk penemuan pola penipuan spam",
                  "answer_start": 213,
                  "answer_end": 309,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "clustering pada bidang pemasaran dapat digunakan untuk membantu marketer menemukan kelompok yang berbeda dalam basis pelanggan mereka  dan kemudian menggunakan pengetahuan ini untuk mengembangkan program pemasaran clustering pada bidang keamanan bank internet dapat digunakan untuk penemuan pola penipuan spam clustering pada bidang information retrieval dapat digunakan untuk pencarian google  berita berbasis topik clustering pada bidang biologi dapat digunakan untuk taksonomi makhluk hidup seperti kingdom  filum  kelas  ordo  famili  genus  dan spesies k means clustering adalah prototype based clustering dan merupakan one level partitioning dari objek yang ada pada data",
          "document_id": 1085
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana melakukan evaluasi tanpa label?",
              "id": 3261,
              "answers": [
                {
                  "answer_id": 1620,
                  "document_id": 1088,
                  "question_id": 3261,
                  "text": "evaluasi tanpa label dilakukan dengan mengukur baik atau tidaknya hasil clustering tanpa menggunakan data luar atau label ",
                  "answer_start": 0,
                  "answer_end": 122,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "evaluasi tanpa label dilakukan dengan mengukur baik atau tidaknya hasil clustering tanpa menggunakan data luar atau label evaluasi ini disebut juga sebagai unsupervised measure evaluation evaluasi dengan label dilakukan dengan mengukur baik atau tidaknya hasil clustering dengan menggunakan data luar atau label evaluasi ini disebut juga sebagai supervised measure evaluation beberapa metode untuk melakukan evaluasi tanpa label  inner indices unsupervised evaluation measure  di antaranya adalah kohesi dan separasi",
          "document_id": 1088
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "mengapa cluster yang baik bersifat lebih kohesif ",
              "id": 2914,
              "answers": [
                {
                  "answer_id": 1284,
                  "document_id": 1089,
                  "question_id": 2914,
                  "text": "cluster yang baik mempunyai jarak antar data yang rendah karena diharapkan mempunyai tingkat kesamaan yang tinggi yang berarti jaraknya lebih kecil sehingga dapat disebut lebih kohesif",
                  "answer_start": 154,
                  "answer_end": 338,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "kohesi adalah ukuran kedekatan data dalam suatu cluster kohesi didapatkan dengan menghitung rata rata jarak data dengan data lain dalam cluster yang sama cluster yang baik mempunyai jarak antar data yang rendah karena diharapkan mempunyai tingkat kesamaan yang tinggi yang berarti jaraknya lebih kecil sehingga dapat disebut lebih kohesif kohesi dapat diukur dengan within cluster sum of square  wcss  atau sering disebut juga sebagai sum of squared error  sse separasi mengukur seberapa berbeda distinct suatu objek pada suatu cluster dengan objek pada cluster lain",
          "document_id": 1089
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang perlu diperhatikan dalam sumber data ",
              "id": 2994,
              "answers": [
                {
                  "answer_id": 1328,
                  "document_id": 1139,
                  "question_id": 2994,
                  "text": "apakah data berbayar  dan adakah data tambahan yang diperlukan",
                  "answer_start": 823,
                  "answer_end": 885,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data yang ada belum tentu bisa langsung dipakai karena bisa jadi datanya terpisah pisah atau justru terintegrasi secara ketat  sehingga diperlukan adanya data understanding data understanding dapat memberikan gambaran awal tentang kelebihan atau kekuatan data  kekurangan dan batasan penggunaan data  tingkat kesesuaian data dengan masalah bisnis yang akan dipecahkan  serta ketersediaan data  open data  data public  biaya akses  dll dokumentasi data understanding meliputi beberapa hal  yaitu data collection report  data description report  data exploration report  dan data quality report data collection report mencakup beberapa aspek penting yang terkait dengan sumber data  atribut data  kecukupan data  dan penggabungan beberapa data yang bervariasi sumber data perlu memperhatikan keberadaan data yang dibutuhkan  apakah data berbayar  dan adakah data tambahan yang diperlukan",
          "document_id": 1139
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "jika nilai simpangan baku besar maka data bagaimana?",
              "id": 3205,
              "answers": [
                {
                  "answer_id": 1557,
                  "document_id": 1147,
                  "question_id": 3205,
                  "text": "jika nilai simpangan baku besar  maka data secara umum tersebar jauh dari nilai rerata aritmetik jika nilai simpangan baku kecil  data secara umum terkumpul dekat dengan nilai rerata aritmetik",
                  "answer_start": 53,
                  "answer_end": 245,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "simpangan baku adalah salah satu ukuran sebaran data jika nilai simpangan baku besar  maka data secara umum tersebar jauh dari nilai rerata aritmetik jika nilai simpangan baku kecil  data secara umum terkumpul dekat dengan nilai rerata aritmetik median merupakan nilai tengah atau biasa disebut q2. iqr dapat dicari dengan rumus iqr   q3   q1. outlier adalah nilai yang lebih tinggi rendah dari 1.5 x iqr modus dipakai sebagai ukuran pusat data untuk data bertipe nominal kategoris dengan cara mencari nilai yang paling sering muncul pada sekumpulan data",
          "document_id": 1147
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa penyebab dari kegagalan dalam analisis data pada machine learning?",
              "id": 3197,
              "answers": [
                {
                  "answer_id": 1549,
                  "document_id": 1181,
                  "question_id": 3197,
                  "text": " kegagalan dalam analisis data maupun proyek machine learning sering disebabkan oleh data yang tidak berkualitas  bukan dari algoritma maupun vendornya ",
                  "answer_start": 9,
                  "answer_end": 161,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "terakhir  kegagalan dalam analisis data maupun proyek machine learning sering disebabkan oleh data yang tidak berkualitas  bukan dari algoritma maupun vendornya tujuan dari data preparation yaitu meningkatkan keseluruhan kualitas data dan proses analisisnya  mempercepat proses analisis pengambilan keputusan  menggabungkan sejumlah dataset yang terpisah ke dalam satu format  mendapatkan hasil analisis data yang berkualitas dan akurat tugas dalam data preparation meliputi data cleaning  transformasi data  dan reduksi dimensi data cleaning melibatkan identifikasi dan perbaikan error dalam dataset  seperti menghapus duplikasi  menangani missing data  dan outlier transformasi data dilakukan untuk mengubah format data agar lebih mudah dipahami dan dianalisis",
          "document_id": 1181
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa manfaat domain expert untuk sample?",
              "id": 3293,
              "answers": [
                {
                  "answer_id": 1658,
                  "document_id": 1189,
                  "question_id": 3293,
                  "text": "domain expert dapat dilibatkan untuk membantu dalam menginterpretasikan dan menentukan apakah sampel merupakan outlier atau tidak",
                  "answer_start": 183,
                  "answer_end": 312,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "selain itu  terdapat penanganan outlier dalam tugas data cleaning tidak ada definisi dan metode yang pasti untuk mengidentifikasi outlier karena bergantung pada dataset yang spesifik domain expert dapat dilibatkan untuk membantu dalam menginterpretasikan dan menentukan apakah sampel merupakan outlier atau tidak outlier dapat disebabkan oleh data entry error  measurement error  sampling error  data corruption  serta pengamatan outlier yang sebenarnya keberadaan outlier dapat menyebabkan masalah saat memodelkan  terutama dalam model linear  dan dapat mempengaruhi evaluasi seperti perhitungan mse  mean squared error",
          "document_id": 1189
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dimaksud dengan high dimensionality data ",
              "id": 3059,
              "answers": [
                {
                  "answer_id": 1390,
                  "document_id": 1218,
                  "question_id": 3059,
                  "text": " data domain saat ini yang melibatkan banyak fitur",
                  "answer_start": 7,
                  "answer_end": 57,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " banyak data domain saat ini yang melibatkan banyak fitur  high dimensionality data   contohnya  1  dokumen  terdiri atas ratusan ribuan kata  bigram   2  citra  terdiri atas ribuan jutaan piksel   3  genomics  terdiri atas ribuan gen  basa dna  dsb data berdimensi tinggi berpotensi berisi redundant features  irrelevent features ataupun noise sehingga memunculkan permasalahan seperti  1  fitur data yang redundan atau tidak relevan dengan konteks permasalahan dapat menurunkan performa algoritma machine learning   2  biaya komputasi biasanya akan meningkat secara eksponensial   3  lebih sulit untuk diinterpretasikan atau divisualisasikan   4  curse of dimensionality  saat dimensi data bertambah besar  maka jumlah sampel data yang tersedia juga harus ditambah tetapi jika dimensi data besar  namun jumlah sampel data terbatas maka akan terjadi curse of dimensionality yang dapat meningkatkan risiko overfitting reduksi dimensi menjadi solusi untuk permasalahan dimana ketika dimensi data meningkat  performa classifier juga meningkat hingga jumlah fitur yang optimal tertentu dan jika dimensi data terus ditambah  tanpa ada peningkatan jumlah sampel pelatihan  maka performa classifier juga akan menurun reduksi dimensi adalah proses mengurangi dimensi data ke ruang dimensi yang lebih rendah  namun tetap mempertahankan karakteristik asli dari data tersebut",
          "document_id": 1218
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang melambangkan data training atau data pembelajaran pada konteks machine learning supervised learning",
              "id": 3182,
              "answers": [
                {
                  "answer_id": 1529,
                  "document_id": 1237,
                  "question_id": 3182,
                  "text": "d merupakan data training atau data pembelajaran ",
                  "answer_start": 351,
                  "answer_end": 400,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "mendapatakan hipotesis yang paling mungkin  h  dari sekumpulan hipotesis kandidat  h  berdasarkan data observasi  d  dan maximuum likelihood ml  berlaku ketika dalam beberapa kasus kita akan mengamsumsikan bahwa setiap hipotesis h dalam h mempunyai probabilitas prior yang sama dalam konteks machine learning  supervised learning  perlu diingat bahwa d merupakan data training atau data pembelajaran dan h adalah kelas atau label data",
          "document_id": 1237
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Untuk apa intuisi diperlukan dalam sains data?",
              "id": 3077,
              "answers": [
                {
                  "answer_id": 1418,
                  "document_id": 1005,
                  "question_id": 3077,
                  "text": "intuisi diperlukan dalam memilih model yang tepat dengan akurasi yang sesuai  serta merasakan kapan model siap untuk diimplementasikan",
                  "answer_start": 408,
                  "answer_end": 542,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "langkah terakhir adalah menerapkan model yang memberikan hasil terbaik sesuai dengan pengujian  dan menyebarkannya di lingkungan produksi untuk digunakan dalam konteks bisnis karakteristik penting dalam sains data meliputi pemahaman bisnis  intuisi  dan keingintahuan seorang ilmuwan data perlu memiliki pemahaman yang baik tentang kebutuhan bisnis dan mampu mengembangkan analitik yang sesuai dengan mereka intuisi diperlukan dalam memilih model yang tepat dengan akurasi yang sesuai  serta merasakan kapan model siap untuk diimplementasikan keingintahuan juga menjadi kunci dalam sains data  karena bidang ini terus berkembang dengan metode dan teknologi baru yang terus muncul",
          "document_id": 1005
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kenapa data preparation merupakan tahapan yang penting?",
              "id": 3196,
              "answers": [
                {
                  "answer_id": 1548,
                  "document_id": 1185,
                  "question_id": 3196,
                  "text": "data preparation merupakan tahapan penting karena data diperoleh dari berbagai sumber yang umumnya didesain dalam format tertentu untuk menjalankan fungsi tertentu dalam aplikasi ",
                  "answer_start": 202,
                  "answer_end": 381,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " data preparation adalah serangkaian proses pembersihan dan transformasi raw data yang dilakukan sebelum proses analisis  modelling  reporting untuk menjadikan data clean  akurat  lengkap dan realiable data preparation merupakan tahapan penting karena data diperoleh dari berbagai sumber yang umumnya didesain dalam format tertentu untuk menjalankan fungsi tertentu dalam aplikasi  beberapa algoritma machine learning memerlukan data dalam format tertentu  seperti format numerik selain itu  data harus bersih  akurat  lengkap  dan telah diberi label dengan baik sebelum dilakukan proses analisis terakhir  kegagalan dalam analisis data maupun proyek machine learning sering disebabkan oleh data yang tidak berkualitas  bukan dari algoritma maupun vendornya tujuan dari data preparation yaitu meningkatkan keseluruhan kualitas data dan proses analisisnya  mempercepat proses analisis pengambilan keputusan  menggabungkan sejumlah dataset yang terpisah ke dalam satu format  mendapatkan hasil analisis data yang berkualitas dan akurat",
          "document_id": 1185
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kapan karnel linear digunakan pada svm?",
              "id": 3092,
              "answers": [
                {
                  "answer_id": 1433,
                  "document_id": 1033,
                  "question_id": 3092,
                  "text": "karnel linier digunakan ketika data yang akan diklasifikasi dapat terpisah dengan sebuah garis hyperplane",
                  "answer_start": 351,
                  "answer_end": 456,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "svm bertujuan untuk menemukan hyperplane terbaik yang memaksimalkan margin  yaitu jarak terdekat antara hyperplane dan titik data dari kelas yang berbeda beberapa macam fungsi kernel support vector machine  svm   linear  polinomial of degree d  polinomial of degree up to d  gaussian rbf  sigmoid  tangen hiperbolik   invers multi kuadratik  additive karnel linier digunakan ketika data yang akan diklasifikasi dapat terpisah dengan sebuah garis hyperplane karnel non linear digunakan ketika data hanya dapat dipisahkan dengan garis lengkung atau sebuah bidang pada ruang dimensi tinggi selanjutnya terdapat model assement merupakan proses mengestimasi dan mengevaluasi kinerja berbagai model untuk memilih yang terbaik dan model selection merupakan proses memilih model terbaik setelah melalui evaluasi performa dan mempertimbangkan kesalahan prediksi pada data baru",
          "document_id": 1033
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "fungsi apa yang mencegah masalah dari fungsi relu?",
              "id": 3095,
              "answers": [
                {
                  "answer_id": 1436,
                  "document_id": 1041,
                  "question_id": 3095,
                  "text": "fungsi leaky relu memiliki keuntungan mencegah kematian masalah relu ",
                  "answer_start": 309,
                  "answer_end": 378,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "fungsi relu memiliki keuntungan efisien secara komputasi dan memungkinkan jaringan untuk menyatu sangat cepat dan salah satu kekurangannya adalah masalah dying relu  ketika input mendekati nol  ataunegatif  gradien fungsi menjadi nol  jaringan tidak dapat melakukan backpropagation dan tidak bisa mempelajari fungsi leaky relu memiliki keuntungan mencegah kematian masalah relu variasi relu ini memiliki kemiringan positif kecil di area negatif  sehingga memungkinkan backpropagation  bahkan untuk nilai input negatif dan kekurangannya hasil tidak konsisten  relu yang bocor tidak tersedia prediksi yang konsisten untuk nilai input negatif fungsi parametric relu memiliki keuntungan yaitu memungkinkan kemiringan negatif dipelajari   tidak seperti relu yang bocor  fungsi ini menyediakan kemiringan bagian negatif dari berfungsi sebagai argumen oleh karena itu  dimungkinkan untuk melakukan backpropagation dan belajar yang paling tepat nilai Î± dan kekurangannya mungkin tampil berbeda untuk masalah yang berbeda fungsi softmax memiliki keuntungan mampu menangani banyak kelas hanya satu kelas di kelas lainnya fungsi aktivasi yaitu menormalkan output untuk masing masing kelas antara 0 dan 1  dan membaginya dengan jumlah mereka  memberikan probabilitas nilai input berada di kelas tertentu serta berguna untuk neuron keluaran  biasanya softmax hanya digunakan untuk lapisan output  untuk jaringan saraf yang perlu mengklasifikasikan input menjadi beberapa kategori",
          "document_id": 1041
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "mengapa proses data preparation dapat bervariasi?",
              "id": 3210,
              "answers": [
                {
                  "answer_id": 1562,
                  "document_id": 1136,
                  "question_id": 3210,
                  "text": "proses data preparation dapat bervariasi karena tergantung pada tujuan analisis  keahlian pengguna data  dan pertanyaan yang ingin dijawab",
                  "answer_start": 0,
                  "answer_end": 138,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "proses data preparation dapat bervariasi karena tergantung pada tujuan analisis  keahlian pengguna data  dan pertanyaan yang ingin dijawab aspek dalam data preparation meliputi data completeness  data correctness  data quantity  dan data usability dalam data completeness  penting untuk memastikan apakah data yang ada sudah cukup untuk merepresentasikan pola yang ingin diteliti  dan apakah ada tambahan data yang diperlukan dari sumber lain data correctness berkaitan dengan akurasi data  termasuk kebersihan dan standardisasi data data quantity mengevaluasi apakah jumlah data yang tersedia sudah mencukupi",
          "document_id": 1136
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "setelah mengidentifikasi tujuan bisnis maka selanjutnya tugas apa yang dilakukan dalam business understanding ",
              "id": 2973,
              "answers": [
                {
                  "answer_id": 1323,
                  "document_id": 1133,
                  "question_id": 2973,
                  "text": "2. menilai dan memahami situasi anda",
                  "answer_start": 990,
                  "answer_end": 1026,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " solusi  \n1. pelatihan model pembelajaran mesin yang lebih baik dengan menggunakan data yang lebih umum \n2. mengimplementasikan face recognition\n3. menggabungkan output sensor kamera dan radar serta lidar untuk memperoleh keakuratan yang lebih baik\n4. menerapkan machine learning ke data yang diambil oleh perangkat yang terpasang dan memberikan indikator yang menunjukkan potensi kesalahan\n5. dibutuhkan aturan yang meregulasi penggunaan data khusus untuk kendaraan bermotor\ntugas tugas dalam business understanding \n1. mengidentifikasi tujuan bisnis  \na business background   \n memahami latar belakang bisnis dari project  membuat bagan organisasi dan tanggung jawabnya\n mengidentifikasi internal sponsor dan problem area\n memahami motivasi project\nb business goals   \n mendeskripsikan masalah \n menentukan semua pertanyaan bisnis dan manfaat yang diharapkan\nc business success criteria  \n dokumentasikan kriteria keberhasilan project\n setiap tujuan bisnis memiliki kriteria untuk sukses\n2. menilai dan memahami situasi anda\na inventaris sumber daya yang ada \n hardware yang dibutuhkan \n sumber data dan penyimpanan pengetahuan serta sumber daya personal \nb",
          "document_id": 1133
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja karakteristik kualitas data yang harus diperhatikan?",
              "id": 3108,
              "answers": [
                {
                  "answer_id": 1450,
                  "document_id": 1154,
                  "question_id": 3108,
                  "text": " 5 karakteristik kualitas data yang harus diperhatikan  validity  kesesuaian dengan aturan bisnis   accuracy  ketepatan nilai data   completeness  kelengkapan semua data yang diperlukan   consistency  konsistensi dalam satu set atau beberapa set data   dan uniformity  penggunaan satuan ukuran yang sama",
                  "answer_start": 830,
                  "answer_end": 1133,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "untuk menghapus kolom baris berisi missing value yaitu menggunakan fungsi dropna   secara langsung berpotensi kehilangan banyak informasi penting karena baris kolom akan dihapus  meskipun hanya terdapat 1 missing value akan tetapi  terdapat langkah alternatif yang dapat dilakukan yaitu menghitung jumlah missing value pada setiap kolom  kolom yang memiliki hampir lebih dari separuh missing value dapat dihapus  dan jika ada beberapa baris data saja yang terdapat missing value juga dapat dihapus tugas terakhir dari cleaning data yaitu validasi data dan qa  quality assurance beberapa pertanyaan perlu dijawab untuk memastikan kevalidan data  seperti apakah datanya masuk akal  mengikuti aturan domainnya  membuktikan atau menyangkal working theory  serta dapat digunakan untuk mendapatkan insight baru selain itu  terdapat juga 5 karakteristik kualitas data yang harus diperhatikan  validity  kesesuaian dengan aturan bisnis   accuracy  ketepatan nilai data   completeness  kelengkapan semua data yang diperlukan   consistency  konsistensi dalam satu set atau beberapa set data   dan uniformity  penggunaan satuan ukuran yang sama",
          "document_id": 1154
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja yang termasuk dalam komponen kasus kendaraan otonom ",
              "id": 2963,
              "answers": [
                {
                  "answer_id": 1318,
                  "document_id": 1132,
                  "question_id": 2963,
                  "text": "komponen  deteksi dan klasifikasi objek  pengenalan pengemudi  sensor fusion  pemeliharaan dan privasi",
                  "answer_start": 300,
                  "answer_end": 402,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apakah hasil dari sensor merupakan output dalam tahapan desain alur sistem ",
              "id": 2971,
              "answers": [
                {
                  "answer_id": 1321,
                  "document_id": 1132,
                  "question_id": 2971,
                  "text": "inputnya adalah hasil dari sistem sensor untuk mendeteksi lingkungan sekitar kendaraan",
                  "answer_start": 213,
                  "answer_end": 299,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "business case   kasus kendaraan otonom dengan tujuan untuk menyediakan kendaraan tanpa pengemudi yang aman  ekonomis  dan praktis desain alur sistem  meliputi sistem sensor  machine learning  dan output  aktuator inputnya adalah hasil dari sistem sensor untuk mendeteksi lingkungan sekitar kendaraan komponen  deteksi dan klasifikasi objek  pengenalan pengemudi  sensor fusion  pemeliharaan dan privasi masalah   \n1. salah dalam mengklasifikasikan objek \n2. pengemudi yang mengantuk\n3. penggunaan kamera yang dapat mengurangi jarak pandang dan ketajaman visual\n4. mobil yang tidak bisa dikontrol pemeliharaannya\n5. sistem navigasi dan kamera yang dapat melanggar privasi pengemudi",
          "document_id": 1132
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "pendekatan apa yang dilakukan teorema bayes ketika kita memiliki beberapa alternatif hipotesis ",
              "id": 2862,
              "answers": [
                {
                  "answer_id": 1238,
                  "document_id": 1025,
                  "question_id": 2862,
                  "text": " maxmimum a posteriori  map",
                  "answer_start": 1007,
                  "answer_end": 1034,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa yang disebut bukti pengamatan d pada teorema bayes ",
              "id": 2858,
              "answers": [
                {
                  "answer_id": 1234,
                  "document_id": 1025,
                  "question_id": 2858,
                  "text": "mencerminkan probabilitas bahwa data pelatihan d akan diamati tanpa pengetahuan tentang hipotesis h yang berlaku",
                  "answer_start": 452,
                  "answer_end": 564,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "hal ini membantu dalam menentukan hipotesis yang paling mungkin berdasarkan data pelatihan yang diamati tujuan teorema bayes adalah untuk menentukan hipotesis yang paling mungkin  diberikan data d dan pengetahuan awal tentang probabilitas awal dari berbagai hipotesis dalam h probabilitas awal dari h  p h   menecerminkan pengetahuan awal kita tentang kemungkinan bahwa h adalah hipotesis yang benar  sebelum mengemati data   bukti pengamatan d  p d   mencerminkan probabilitas bahwa data pelatihan d akan diamati tanpa pengetahuan tentang hipotesis h yang berlaku  probabilitas kondisional pengamatan d  p d h   menunjukan probabilitas mengamati data d dalam suatu dunia dimana hipotesis h berlaku  probabilitas posterior h  p h d   mewakili probabilitas bahwa h berlaku berdasarkan data pelatihan yang diamati d  teorema bayes memungkinkan kita menghitung p h d  dengan cara p h d    p d h p h  p d terdapat dua pendekatan pada bayes learning yaitu maxmimum a posteriori  map  dan maximuum likelihood ml   maxmimum a posteriori  map   berlaku untuk kondisi dimana ketika kita memiliki beberapa alternatif hipotesis  lalu map memiliki tujuan mendapatakan hipotesis yang paling mungkin  h  dari sekumpulan hipotesis kandidat  h  berdasarkan data observasi  d  dan maximuum likelihood ml  berlaku ketika dalam beberapa kasus kita akan mengamsumsikan bahwa setiap hipotesis h dalam h mempunyai probabilitas prior yang sama dalam konteks machine learning  supervised learning  perlu diingat bahwa d merupakan data training atau data pembelajaran dan h adalah kelas atau label data",
          "document_id": 1025
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "fungsi apakah yang memiliki kekurangan yang sama dengan fungsi sigmoid ",
              "id": 2878,
              "answers": [
                {
                  "answer_id": 1251,
                  "document_id": 1042,
                  "question_id": 2878,
                  "text": "fungsi tanh ",
                  "answer_start": 126,
                  "answer_end": 138,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "hal ini dapat mengakibatkan jaringan menolak untuk belajar lebih jauh atau terlalu lambat untuk mencapai prediksi yang akurat fungsi tanh memiliki keuntungan berpusat pada nol mempermudah memodelkan input itu memiliki sangat negatif  netral  dan sangat positif nilai nilai tetapi kekurangannya adalah sama seperti fungsi sigmoid fungsi relu memiliki keuntungan efisien secara komputasi dan memungkinkan jaringan untuk menyatu sangat cepat dan salah satu kekurangannya adalah masalah dying relu  ketika input mendekati nol  ataunegatif  gradien fungsi menjadi nol  jaringan tidak dapat melakukan backpropagation dan tidak bisa mempelajari fungsi leaky relu memiliki keuntungan mencegah kematian masalah relu variasi relu ini memiliki kemiringan positif kecil di area negatif  sehingga memungkinkan backpropagation  bahkan untuk nilai input negatif dan kekurangannya hasil tidak konsisten  relu yang bocor tidak tersedia prediksi yang konsisten untuk nilai input negatif",
          "document_id": 1042
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara menginstal anaconda?",
              "id": 3274,
              "answers": [
                {
                  "answer_id": 1633,
                  "document_id": 1117,
                  "question_id": 3274,
                  "text": "dengan cara membuka link anaconda org menggunakan search engine kemudian download anaconda  lalu pilih konfigurasi sistem operasi  32 bit atau 64 bit   setelah proses download selesai dapat memulai instalasi anaconda  python 3.6  setelah itu instalasi selesai ",
                  "answer_start": 78,
                  "answer_end": 338,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " tools data science dapat menggunakan python yang diinstalasi dengan anaconda dengan cara membuka link anaconda org menggunakan search engine kemudian download anaconda  lalu pilih konfigurasi sistem operasi  32 bit atau 64 bit   setelah proses download selesai dapat memulai instalasi anaconda  python 3.6  setelah itu instalasi selesai python memiliki hal hal dasar yaitu sintak python  variabel  tipe data  operator  character atau string  array  logika dan statemen if  list  tuple  himpunan  fungsi  dan memiliki built in tipe numerik int  float  serta complex untuk variabel dibuat saat pertama kali diberi nilai  tidak perlu mendeklarasikan tipe karena tipe dikaitkan dengan objek bukan variabel kemudian untuk penulisan string dapat dibatasi dengan mencocokkan tanda kutip tunggal atau ganda contohnya  data science  atau  data science  dan menggunakan tanda kutip tiga kali lipat untuk string multi baris contohnya    this is the first line",
          "document_id": 1117
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa keuntungan fungsi softmax?",
              "id": 3234,
              "answers": [
                {
                  "answer_id": 1591,
                  "document_id": 1046,
                  "question_id": 3234,
                  "text": "fungsi softmax memiliki keuntungan mampu menangani banyak kelas hanya satu kelas di kelas lainnya ",
                  "answer_start": 168,
                  "answer_end": 266,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "oleh karena itu  dimungkinkan untuk melakukan backpropagation dan belajar yang paling tepat nilai Î± dan kekurangannya mungkin tampil berbeda untuk masalah yang berbeda fungsi softmax memiliki keuntungan mampu menangani banyak kelas hanya satu kelas di kelas lainnya fungsi aktivasi yaitu menormalkan output untuk masing masing kelas antara 0 dan 1  dan membaginya dengan jumlah mereka  memberikan probabilitas nilai input berada di kelas tertentu serta berguna untuk neuron keluaran  biasanya softmax hanya digunakan untuk lapisan output  untuk jaringan saraf yang perlu mengklasifikasikan input menjadi beberapa kategori fungsi swish yaitu fungsi aktivasi mandiri yang baru ditemukan oleh para peneliti di google menurut kertas mereka  itu berkinerja lebih baik daripada relu dengan tingkat yang sama efisiensi komputasi dalam percobaan di imagenet dengan model identik yang menjalankan relu dan swish  yang baru fungsi mencapai akurasi klasifikasi top  1 0 6 0 9  lebih tinggi",
          "document_id": 1046
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara mengevaluasi cluster dengan kohesi dan separasi ",
              "id": 2920,
              "answers": [
                {
                  "answer_id": 1277,
                  "document_id": 1081,
                  "question_id": 2920,
                  "text": "kohesi dapat diukur dengan within cluster sum of square  wcss  atau sering disebut juga sebagai sum of squared error  sse separasi mengukur seberapa berbeda distinct suatu objek pada suatu cluster dengan objek pada cluster lain separasi didapatkan dengan menghitung rata rata jarak data dengan data data pada cluster lain separasi dinyatakan dalam ukuran between cluster sum of square  ssb",
                  "answer_start": 0,
                  "answer_end": 389,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "kohesi dapat diukur dengan within cluster sum of square  wcss  atau sering disebut juga sebagai sum of squared error  sse separasi mengukur seberapa berbeda distinct suatu objek pada suatu cluster dengan objek pada cluster lain separasi didapatkan dengan menghitung rata rata jarak data dengan data data pada cluster lain separasi dinyatakan dalam ukuran between cluster sum of square  ssb cluster yang baik akan mempunyai nilai sse  kohesi  yang rendah dan nilai bss  separasi  yang tinggi",
          "document_id": 1081
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja library data science yang popular pada python?",
              "id": 3275,
              "answers": [
                {
                  "answer_id": 1634,
                  "document_id": 1119,
                  "question_id": 3275,
                  "text": "python memiliki pustakanya untuk data science dengan beberapa toolboxes atau libraries popular yaitu math  numpy  scipy  pandas  scikit learn",
                  "answer_start": 27,
                  "answer_end": 168,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa contoh command pada pustaka math?",
              "id": 3276,
              "answers": [
                {
                  "answer_id": 1635,
                  "document_id": 1119,
                  "question_id": 3276,
                  "text": " pada pustaka math terdapat beberapa command name yaitu abs value    absolute value  ceil value    rounds up  cos value    cosine  in radians  floor value    rounds down  log value    logarithm  base e  log10 value    logarithm  base 10  max value1  value2    larger of two values  min value1  value2    smaller of two values  round value    nearest whole number  sin value    sine  in radians  sqrt value    square root ",
                  "answer_start": 298,
                  "answer_end": 719,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "close   untuk menutup file python memiliki pustakanya untuk data science dengan beberapa toolboxes atau libraries popular yaitu math  numpy  scipy  pandas  scikit learn  serta libraries visualisasinya yaitu mathplotlib dan seaborn di mana semua pustaka terinstall pada scc  shared computing cluster pada pustaka math terdapat beberapa command name yaitu abs value    absolute value  ceil value    rounds up  cos value    cosine  in radians  floor value    rounds down  log value    logarithm  base e  log10 value    logarithm  base 10  max value1  value2    larger of two values  min value1  value2    smaller of two values  round value    nearest whole number  sin value    sine  in radians  sqrt value    square root  sebagian besar fungsi matematika tidak dibangun ke dalam inti python karena tersedia termuat dalam modul matematika seperti di atas dengan menggunakan sintaks awal from math import   untuk memanggil fungsi fungsinya sedangkan untuk pustaka numpy memiliki modul kunci untuk komputasi ilmiah  memiliki cara yang nyaman dan efisien untuk menangani array multi dimensi  dan banyak pustaka python lainnya dibangun di atas numpy  pada numpy dapat pula membuat array dan membuat program linear lalu untuk pustaka pada matplotlib  python 2d merencanakan perpustakaan yang menghasilkan angka kualitas publikasi dalam berbagai format hardcopy  matplotlib memiliki satu set fungsi yang mirip dengan matlab  dalam matplotlib dapat berisi plot garis  plot pencar  barcharts  histogram  bagan pai  dan lainnya  pada matplotlib ini memiliki tingkat yang relatif rendah dan beberapa upaya yang diperlukan untuk membuat visualisasi lanjutan",
          "document_id": 1119
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa  hasil dari studi kelayakan teknis?",
              "id": 3263,
              "answers": [
                {
                  "answer_id": 1622,
                  "document_id": 1095,
                  "question_id": 3263,
                  "text": " hasil dari studi kelayakan teknis adalah untuk menentukan berbagai pendekatan teknis yang dapat diikuti untuk mengimplementasikan proyek dengan sukses dengan risiko minimum",
                  "answer_start": 297,
                  "answer_end": 470,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "informasi ini kemudian digunakan untuk merencanakan pendekatan proyek dasar dan untuk melakukan studi kelayakan produk di bidang ekonomi  operasional dan teknis perencanaan untuk persyaratan jaminan kualitas dan identifikasi risiko yang terkait dengan proyek juga dilakukan dalam tahap perencanaan hasil dari studi kelayakan teknis adalah untuk menentukan berbagai pendekatan teknis yang dapat diikuti untuk mengimplementasikan proyek dengan sukses dengan risiko minimum outputnya studi kelayakan teknis   inisiasi proyek analysis phase inputnya studi kelayakan teknis dan pendanaan",
          "document_id": 1095
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara menangani array multi dimensi?",
              "id": 3279,
              "answers": [
                {
                  "answer_id": 1638,
                  "document_id": 1123,
                  "question_id": 3279,
                  "text": "sedangkan untuk pustaka numpy memiliki modul kunci untuk komputasi ilmiah  memiliki cara yang nyaman dan efisien untuk menangani array multi dimensi",
                  "answer_start": 0,
                  "answer_end": 148,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sedangkan untuk pustaka numpy memiliki modul kunci untuk komputasi ilmiah  memiliki cara yang nyaman dan efisien untuk menangani array multi dimensi  dan banyak pustaka python lainnya dibangun di atas numpy  pada numpy dapat pula membuat array dan membuat program linear lalu untuk pustaka pada matplotlib  python 2d merencanakan perpustakaan yang menghasilkan angka kualitas publikasi dalam berbagai format hardcopy  matplotlib memiliki satu set fungsi yang mirip dengan matlab  dalam matplotlib dapat berisi plot garis  plot pencar  barcharts  histogram  bagan pai  dan lainnya  pada matplotlib ini memiliki tingkat yang relatif rendah dan beberapa upaya yang diperlukan untuk membuat visualisasi lanjutan untuk pustaka scipy terdapat pengumpulan algoritma untuk aljabar linear  persamaan diferensial  integrasi numerik  optimasi  statistik  dan lainnya  untuk scipy ini merupakan bagian dari scipy stack dan dibangun di atas numpy untuk melihat fungsi pustaka scipy dengan import scipy dan help scipy scipy memiliki jenis scipy linear algebra   scipy linalg  scipy curve fitting   scipy curve_fit  dan scipy integral   scipy integrate",
          "document_id": 1123
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa tujuan dari membuat terminology istilah?",
              "id": 3265,
              "answers": [
                {
                  "answer_id": 1624,
                  "document_id": 1104,
                  "question_id": 3265,
                  "text": "d membuat terminology istilah \ntujuannya satu tim punya pemahaman istilah yang sama ",
                  "answer_start": 309,
                  "answer_end": 393,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " c mengidentifikasi resiko dan menentukan rencana antisipasi tiap resiko \n jadwal  bagaimana jika jadwal mundur dari rencana semula  \n keuangan  bagaimana jika sponsor project mengalami masalah anggaran  \n data  bagaimana jika kualitas data jelek \n hasil  bagaimana jika hasil tidak seperti yang diharapkan  \nd membuat terminology istilah \ntujuannya satu tim punya pemahaman istilah yang sama \ne mengestimasi cost dan menghitung keuntungan atau manfaat yang didapatkan\n3. mendefinisikan tujuan mengolah data\n mendeskripsikan tipe masalah seperti klustering  prediksi atau klasifikasi \n menentukan hasil dari pengolahan data seperti model  laporan  presentasi  dan dataset yang terproses\n menentukan kriteria keberhasilan pengolahan data\n4. merencanakan project\ntuliskan langkah demi langkah rencana kegiatan untuk project yang akan dikerjakan tambahkan tiap langkah tersebut   sumber daya yang dibutuhkan  input  output  ketergantungan langkah sebelumnya  perjelas langkah yang diulang",
          "document_id": 1104
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dicakup dari data collection report?",
              "id": 3285,
              "answers": [
                {
                  "answer_id": 1648,
                  "document_id": 1152,
                  "question_id": 3285,
                  "text": "data collection report mencakup beberapa aspek penting yang terkait dengan sumber data  atribut data  kecukupan data  dan penggabungan beberapa data yang bervariasi ",
                  "answer_start": 0,
                  "answer_end": 165,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data collection report mencakup beberapa aspek penting yang terkait dengan sumber data  atribut data  kecukupan data  dan penggabungan beberapa data yang bervariasi sumber data perlu memperhatikan keberadaan data yang dibutuhkan  apakah data berbayar  dan adakah data tambahan yang diperlukan data description report mencakup beberapa aspek penting  seperti gambaran data yang berisi jumlah data dan tipe nilai  kuantitas data  format dan metode mendapatkannya   kualitas data  karakteristik dan tipe data   penentuan statistik dasar dari atribut kunci  dan atribut yang menjadi prioritas data exploration report mencakup beberapa aspek penting  yaitu hipotesis data  atribut yang  menjanjikan  untuk dianalisis lebih lanjut  eksplorasi karakteristik baru dari data  bagaimana mengubah initial hipotesis  mengidentifikasi subset dari data untuk digunakan nantinya  serta perbandingan dengan tujuan data quality report mencakup beberapa aspek penting  yaitu missing data  kesalahan data  menghitung kesalahan  atribut yang hilang dan kosong  noise  memeriksa keberadaan redudansi data  pertimbangan untuk data pencicilan   outlier  serta bagaimana data disimpan",
          "document_id": 1152
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa  atribut data frame untuk melihat dimensi dari data frame?",
              "id": 3278,
              "answers": [
                {
                  "answer_id": 1637,
                  "document_id": 1121,
                  "question_id": 3278,
                  "text": "  ndim untuk mendefinisikan number dari dimensi",
                  "answer_start": 269,
                  "answer_end": 316,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "h5   df kemudian dapat pula untuk membuat data frame menggunakan list dengan atribut data frame yaitu dtypes untuk mendefinisikan list tipe dari kolom yang ada  columns untuk mendefinisikan list dari nama kolom  axes untuk mendefinisikan list baris label dan nama kolom  ndim untuk mendefinisikan number dari dimensi  size untuk mendifinisikan number dari elemen  shape untuk me return representasi tuple dari dimensi  dan values untuk mendefinisikan representasi numpy dari sebuah data sedangkan untuk data frame methods dalam pandas  tidak seperti atribut karena methods memiliki kurung  dan semua atribut serta methods dapat terdaftar dengan fungsi dir     dir df untuk contoh methods yaitu head  n    tail  n   sebagai first atau last n rows  describe   sebagai generate descriptive statistics  hanya untuk kolom numeric   max    min   sebagai return max atau min values untuk semua kolom numerik  mean    median   untuk return mean atau median values untuk semua kolom numerik  std   sebagai standard deviation  sample  n   sebagai return random sample dari data frame  dropna   sebagai drop all records dengan missing values untuk memilih kolom dalam data frame dapat menggunakan dua metode  metode pertama dengan subset data frame menggunakan nama kolom contohnya df  sex   dan metode kedua dengan menggunakan nama kolom contohnya df",
          "document_id": 1121
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa manfaat sains data untuk pemerintah?",
              "id": 3220,
              "answers": [
                {
                  "answer_id": 1576,
                  "document_id": 1013,
                  "question_id": 3220,
                  "text": "pemerintah juga dapat menggunakan sains data untuk menyusun kebijakan yang lebih baik berdasarkan data yang tersedia ",
                  "answer_start": 0,
                  "answer_end": 117,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "pemerintah juga dapat menggunakan sains data untuk menyusun kebijakan yang lebih baik berdasarkan data yang tersedia contoh aplikasi sains data dalam pemasaran dan iklan meliputi penggunaan analisis prediktif dan deskriptif untuk mengelompokkan pelanggan  serta analisis media sosial untuk memahami perilaku dan pola pikir pelanggan di sektor keuangan dan perbankan  sains data digunakan dalam analisis risiko  manajemen data pelanggan  dan deteksi penipuan dalam ritel dan e commerce  sains data dapat digunakan untuk sistem rekomendasi  analisis prediktif  analisis sentimen  dan lainnya secara keseluruhan  sains data memiliki aplikasi yang luas dan beragam dalam berbagai industri  membantu dalam pengambilan keputusan yang lebih baik dan memanfaatkan potensi data secara efektif",
          "document_id": 1013
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "jika output y bernilai kontinu maka jenis supervised learning apa yang diperlukan?",
              "id": 3223,
              "answers": [
                {
                  "answer_id": 1579,
                  "document_id": 1021,
                  "question_id": 3223,
                  "text": "regresi  jika ouput y bernilai kontinu ",
                  "answer_start": 464,
                  "answer_end": 503,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "variable ouput y berperan sebagai teacher yang membimbing proses pembelajaran  setelah fungsi f didapatkan  maka fungsi tersebut dapat digunakan untuk memetakan  memprediksi  input data baru  x  dengan tepat  fungsi f yang dihasilkan dari proses pembelajaran disebut juga sebagai model  classification model terdapat 3 jenis supervised learning yaitu 1  berdasarkan tipe ouputnya  pada jenis ini supervised learning dibagi menjadi 2 yaitu regresi dan klasifikasi  regresi  jika ouput y bernilai kontinu dan klasifikasi  jika ouput y bernilai diskret kategori 2  berdasarkan jumlah ouputnya  pada jenis ini supervised learning dibagi menjadi 2 yaitu binary classification dan multiclass classification  binary classification  target artibut hanya terdiri dari 2 kategori kelas dan multiclass classification  target atribut terdiri atas lebih dari dua kategori kelas 3  berdasarkan separability   linearity  pada jenis ini supervised learning dibagi menjadi 4 yaitu separable  kelompok yang berbeda menempati daerah pada ruang dimensi yang berbeda  non separable  kelompok yang berbeda bercampur dalam daerah yang sama dalam ruang dimensi  linearly separable  kelompok yang berbeda dapat dipisahkan dengan sebuah garis lurus  non linearly separable  kelompok yang berbeda tidak dapat dipisahkan dengan sebuah garis lurus selanjutnya ada beberapa algoritma supervised learning untuk classification task  yaitu 1  k nearest neighbors  algoritma ini juga bisa disebut dengan algortima knn dan algoritma ini termasuk kedalam tipe lazy learning",
          "document_id": 1021
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kapan maximum likelihood berlaku?",
              "id": 3225,
              "answers": [
                {
                  "answer_id": 1581,
                  "document_id": 1024,
                  "question_id": 3225,
                  "text": "maximuum likelihood ml  berlaku ketika dalam beberapa kasus kita akan mengamsumsikan bahwa setiap hipotesis h dalam h mempunyai probabilitas prior yang sama ",
                  "answer_start": 363,
                  "answer_end": 520,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "terdapat dua pendekatan pada bayes learning yaitu maxmimum a posteriori  map  dan maximuum likelihood ml   maxmimum a posteriori  map   berlaku untuk kondisi dimana ketika kita memiliki beberapa alternatif hipotesis  lalu map memiliki tujuan mendapatakan hipotesis yang paling mungkin  h  dari sekumpulan hipotesis kandidat  h  berdasarkan data observasi  d  dan maximuum likelihood ml  berlaku ketika dalam beberapa kasus kita akan mengamsumsikan bahwa setiap hipotesis h dalam h mempunyai probabilitas prior yang sama dalam konteks machine learning  supervised learning  perlu diingat bahwa d merupakan data training atau data pembelajaran dan h adalah kelas atau label data 4  support vector machine  linear classifiers dalam support vector machine  svm  adalah salah satu metode pengklasifikasi yang digunakan untuk memisahkan dua kelas data dengan menggunakan garis linear atau hyperplane svm bertujuan untuk menemukan hyperplane terbaik yang memaksimalkan margin  yaitu jarak terdekat antara hyperplane dan titik data dari kelas yang berbeda beberapa macam fungsi kernel support vector machine  svm   linear  polinomial of degree d  polinomial of degree up to d  gaussian rbf  sigmoid  tangen hiperbolik   invers multi kuadratik  additive",
          "document_id": 1024
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa alat untuk visualisasi data pada r?",
              "id": 3219,
              "answers": [
                {
                  "answer_id": 1575,
                  "document_id": 1011,
                  "question_id": 3219,
                  "text": "untuk visualisasi data  r  tableau  dan mentah menjadi pilihan yang populer untuk membuat visualisasi yang menarik dan informatif",
                  "answer_start": 0,
                  "answer_end": 129,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "untuk visualisasi data  r  tableau  dan mentah menjadi pilihan yang populer untuk membuat visualisasi yang menarik dan informatif sedangkan dalam pembelajaran mesin  alat seperti percikan  azure ml studio  dan mahout digunakan untuk mengembangkan dan menerapkan model pembelajaran mesin dengan menggunakan berbagai alat ini  ilmuwan data dapat memanfaatkan teknologi terkini untuk memproses  menganalisis  dan memvisualisasikan data secara efektif sains data memiliki berbagai aplikasi yang relevan dalam berbagai industri dalam bidang pemasaran  sains data dapat digunakan untuk mengembangkan strategi harga berdasarkan analisis data  meningkatkan keuntungan perusahaan  dan mengelompokkan pelanggan berdasarkan kebutuhan mereka",
          "document_id": 1011
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Apa saja latar belakang yang harus dimiliki oleh seorang saintis data?",
              "id": 3076,
              "answers": [
                {
                  "answer_id": 1417,
                  "document_id": 1004,
                  "question_id": 3076,
                  "text": "seorang saintis data perlu memiliki latar belakang dalam pembelajaran mesin  statistik  pemrograman  terutama python atau r   matematika  dan bidang database",
                  "answer_start": 537,
                  "answer_end": 694,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "kemampuan pemrograman  terutama dalam bahasa python atau r  penting dalam mengelola dan memproses data secara efisien pemahaman matematika juga diperlukan dalam pemodelan dan interpretasi data terakhir  pengetahuan dalam bidang database membantu dalam mengelola data secara efektif sebagai kunci dalam memanfaatkan potensi big data  saintis data membawa struktur ke dalamnya  menemukan pola menarik  dan memberikan saran kepada eksekutif tentang implikasi untuk produk  proses  dan pengambilan keputusan yang lebih baik dengan demikian  seorang saintis data perlu memiliki latar belakang dalam pembelajaran mesin  statistik  pemrograman  terutama python atau r   matematika  dan bidang database",
          "document_id": 1004
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana model decision tree memprediksi kelas?",
              "id": 3226,
              "answers": [
                {
                  "answer_id": 1583,
                  "document_id": 1031,
                  "question_id": 3226,
                  "text": "model decision tree dapat digunakan untuk memprediksi kelas dari data uji dengan mengikuti serangkaian kondisi yang ditentukan oleh pohon keputusan",
                  "answer_start": 328,
                  "answer_end": 475,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "setiap pemisahan menghasilkan cabang baru dalam pohon keputusan  yang mewakili kondisi yang harus dipenuhi proses ini dilakukan secara berulang hingga mencapai kondisi berhenti  seperti mencapai tingkat kedalaman maksimum atau tidak ada lagi pemisahan yang memberikan peningkatan signifikan dalam pemisahan kelas pada akhirnya  model decision tree dapat digunakan untuk memprediksi kelas dari data uji dengan mengikuti serangkaian kondisi yang ditentukan oleh pohon keputusan 3  naive bayes teorema bayes merupakan teorema yang memberikan cara untuk menghitung probabilitas suatu hipotesis berdasarkan probabilitas awalnya  probabilitas mengamati berbagai data yang diberikan hipotesis dan data yang diamati itu sendiri",
          "document_id": 1031
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "berapa jenis supervised learning berdasarkan separability   linearity?",
              "id": 3222,
              "answers": [
                {
                  "answer_id": 1578,
                  "document_id": 1020,
                  "question_id": 3222,
                  "text": "berdasarkan separability   linearity  pada jenis ini supervised learning dibagi menjadi 4",
                  "answer_start": 3,
                  "answer_end": 92,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "3  berdasarkan separability   linearity  pada jenis ini supervised learning dibagi menjadi 4 yaitu separable  kelompok yang berbeda menempati daerah pada ruang dimensi yang berbeda  non separable  kelompok yang berbeda bercampur dalam daerah yang sama dalam ruang dimensi  linearly separable  kelompok yang berbeda dapat dipisahkan dengan sebuah garis lurus  non linearly separable  kelompok yang berbeda tidak dapat dipisahkan dengan sebuah garis lurus selanjutnya ada beberapa algoritma supervised learning untuk classification task  yaitu 1  k nearest neighbors  algoritma ini juga bisa disebut dengan algortima knn dan algoritma ini termasuk kedalam tipe lazy learning pada algortima ini proses komputasi ditunda sampai prediksi klasifikasi dilakukan algoritma ini mempunyai teknik yang sederhana karena tidak diperlukan pengetahuan awal mengenai bagaimana distribusi data cara kerja dari algortima ini yang pertama algortima ini mengklasifikasikan data baru  test tuple  berdasarkan kelas data dari k tetangga terdekat  nearest neighbors",
          "document_id": 1020
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang digunakan algoritma berbasis  tree  dari beberapa decision tree untuk membuat keputusan ",
              "id": 2892,
              "answers": [
                {
                  "answer_id": 1240,
                  "document_id": 1026,
                  "question_id": 2892,
                  "text": "fitur kualitas ",
                  "answer_start": 250,
                  "answer_end": 265,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa yang dimaksud dengan random forest ",
              "id": 2882,
              "answers": [
                {
                  "answer_id": 1239,
                  "document_id": 1026,
                  "question_id": 2882,
                  "text": " random forest merupakan algoritma berbasis  tree  yang menggunakan fitur kualitas dari beberapa decision tree untuk membuat keputusan",
                  "answer_start": 182,
                  "answer_end": 316,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sementara kelemahananya adalah cenderung overfit dan perubahan kecil pada data cenderung menyebabkan perbedaan besar pada struktur decision tree  sehingga menyebabkan ketidakstabilan random forest merupakan algoritma berbasis  tree  yang menggunakan fitur kualitas dari beberapa decision tree untuk membuat keputusan algoritma random forest menggabungkan keluaran dari beberapa decision tree yang didapatkan secara ensemble untuk menghasilkan keluaran akhir dengan menggabungkan beberapa decision tree yang tidak berkorelasi  seringkali peningkatan akurasi model yang signifikan dapat dicapai decision tree yang memiliki kelemahan overfitting dapat dikurangi dengan menggunakan algoritma random forest",
          "document_id": 1026
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Kenapa data science penting dalam era digital saat ini?",
              "id": 3216,
              "answers": [
                {
                  "answer_id": 1569,
                  "document_id": 999,
                  "question_id": 3216,
                  "text": "data science menjadi penting dalam era digital saat ini karena dapat mengolah data secara efisien dan menghasilkan wawasan yang berharga dari data tersebut ",
                  "answer_start": 0,
                  "answer_end": 156,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data science menjadi penting dalam era digital saat ini karena dapat mengolah data secara efisien dan menghasilkan wawasan yang berharga dari data tersebut dengan demikian  data science memanfaatkan berbagai elemen untuk menghasilkan pemahaman yang mendalam tentang data data sceience juga diterapkan di berbagai industri dan bidang lainnya dengan menerapkan pengetahuan tentang data yang mendalam penggunaan data melibatkan langkah langkah seperti analisis eksplorasi data untuk memahami karakteristik dan pola data  pembangunan model pengetahuan untuk menggambarkan hubungan antarvariabel  dan pengembangan model prediktif untuk membuat prediksi di masa depan semua langkah langkah tersebut dilakukan di dalam proses penggunaan data",
          "document_id": 999
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Apa saja praktik yang dilakukan oleh ilmuwan data?",
              "id": 3178,
              "answers": [
                {
                  "answer_id": 1524,
                  "document_id": 1007,
                  "question_id": 3178,
                  "text": "praktik ilmuwan data melibatkan eksplorasi dalam data  pembersihan  persiapan data  pembuatan hipotesis dan pemodelan  evaluasi  dan interpretasi yang berulang",
                  "answer_start": 0,
                  "answer_end": 159,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "praktik ilmuwan data melibatkan eksplorasi dalam data  pembersihan  persiapan data  pembuatan hipotesis dan pemodelan  evaluasi  dan interpretasi yang berulang selama proses ini  ilmuwan data menggunakan berbagai teknik dan alat untuk mengoptimalkan penggunaan data dan menghasilkan wawasan yang berharga komponen utama dalam sains data meliputi eksplorasi data  pemodelan  pengujian model  dan implementasi model eksplorasi data melibatkan pengambilan sampel dan transformasi data  serta memeriksa hubungan antara fitur fitur dalam data menggunakan metode statistik selanjutnya  pemodelan melibatkan pemilihan model yang sesuai  seperti menggunakan algoritma machine learning  dan memasukkan data ke dalam model tersebut",
          "document_id": 1007
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu stratified k folds cross validation?",
              "id": 3228,
              "answers": [
                {
                  "answer_id": 1585,
                  "document_id": 1034,
                  "question_id": 3228,
                  "text": "stratified k folds cross validation  prinsipnya sama dengan k folds cross validation  hanya saja perbedaannya pada proses pemilihan data untuk masing masing fold dilakukan menggunakan stratified sampling",
                  "answer_start": 3,
                  "answer_end": 206,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "2  stratified k folds cross validation  prinsipnya sama dengan k folds cross validation  hanya saja perbedaannya pada proses pemilihan data untuk masing masing fold dilakukan menggunakan stratified sampling 3  leave one out cross validation  merupakan bentuk khusus dari k folds cross validation  dimana k n  untuk n adalah total jumlah data dilakukan n eksperimen dimana training set terdiri dari n  1 samples data serta 1 buah sampel data untuk validation set teknik ini tidak menjamin distribusi sample data yang sama untuk masing masing kelas selanjutnya ada confusion matrix  matriks yang digunakan untuk merangkum hasil klasifikasi yang benar atau salah yang dihasilkan oleh sebuah metode model klasifikasi pada suatu dataset",
          "document_id": 1034
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang disebut probabilitas awal dari h pada teorema bayes ",
              "id": 2860,
              "answers": [
                {
                  "answer_id": 1228,
                  "document_id": 1023,
                  "question_id": 2860,
                  "text": "pengetahuan awal ",
                  "answer_start": 651,
                  "answer_end": 668,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "3  naive bayes teorema bayes merupakan teorema yang memberikan cara untuk menghitung probabilitas suatu hipotesis berdasarkan probabilitas awalnya  probabilitas mengamati berbagai data yang diberikan hipotesis dan data yang diamati itu sendiri naive bayes menggunakan teorema bayes untuk menghitung probabilitas suatu hipotesis berdasarkan probabilitas awalnya  probabilitas mengamati data yang diberikan hipotesis  dan data yang diamati itu sendiri hal ini membantu dalam menentukan hipotesis yang paling mungkin berdasarkan data pelatihan yang diamati tujuan teorema bayes adalah untuk menentukan hipotesis yang paling mungkin  diberikan data d dan pengetahuan awal tentang probabilitas awal dari berbagai hipotesis dalam h",
          "document_id": 1023
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "mengapa stratified sampling digunakan dalam stratified k folds cross validation ",
              "id": 2851,
              "answers": [
                {
                  "answer_id": 1241,
                  "document_id": 1028,
                  "question_id": 2851,
                  "text": " proses pemilihan data untuk masing masing fold dilakukan menggunakan stratified sampling",
                  "answer_start": 435,
                  "answer_end": 524,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "dalam setiap iterasi  salah satu subset digunakan sebagai data validasi  sementara k 1 subset lainnya digunakan sebagai data pelatihan proses ini diulang k kali  sehingga setiap subset digunakan sebagai data validasi tepat satu kali proses pemilihan data untuk masing masing fold dilakukan menggunakan random sampling 2  stratified k folds cross validation  prinsipnya sama dengan k folds cross validation  hanya saja perbedaannya pada proses pemilihan data untuk masing masing fold dilakukan menggunakan stratified sampling 3  leave one out cross validation  merupakan bentuk khusus dari k folds cross validation  dimana k n  untuk n adalah total jumlah data",
          "document_id": 1028
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Apa yang dilibatkan untuk melakukan pemodelan?",
              "id": 3218,
              "answers": [
                {
                  "answer_id": 1574,
                  "document_id": 1009,
                  "question_id": 3218,
                  "text": "pemodelan melibatkan pemilihan model yang sesuai  seperti menggunakan algoritma machine learning  dan memasukkan data ke dalam model tersebut",
                  "answer_start": 166,
                  "answer_end": 307,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "eksplorasi data melibatkan pengambilan sampel dan transformasi data  serta memeriksa hubungan antara fitur fitur dalam data menggunakan metode statistik selanjutnya  pemodelan melibatkan pemilihan model yang sesuai  seperti menggunakan algoritma machine learning  dan memasukkan data ke dalam model tersebut setelah itu  model diuji menggunakan data uji untuk memeriksa keakuratannya dan melakukan perubahan jika diperlukan langkah terakhir adalah menerapkan model yang memberikan hasil terbaik sesuai dengan pengujian  dan menyebarkannya di lingkungan produksi untuk digunakan dalam konteks bisnis karakteristik penting dalam sains data meliputi pemahaman bisnis  intuisi  dan keingintahuan",
          "document_id": 1009
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Apa saja praktik yang dilakukan oleh ilmuwan data?",
              "id": 3074,
              "answers": [
                {
                  "answer_id": 1572,
                  "document_id": 1002,
                  "question_id": 3074,
                  "text": " sains data telah mengalami evolusi yang signifikan  mulai dari fokus pada pengolahan data dan analisis statistik tradisional hingga pendekatan yang lebih holistik menggunakan kombinasi statistik  pembelajaran mesin  ilmu komputer  dan keahlian domain ",
                  "answer_start": 412,
                  "answer_end": 664,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sebagai kunci dalam memanfaatkan potensi big data  saintis data membawa struktur ke dalamnya  menemukan pola menarik  dan memberikan saran kepada eksekutif tentang implikasi untuk produk  proses  dan pengambilan keputusan yang lebih baik dengan demikian  seorang saintis data perlu memiliki latar belakang dalam pembelajaran mesin  statistik  pemrograman  terutama python atau r   matematika  dan bidang database sains data telah mengalami evolusi yang signifikan  mulai dari fokus pada pengolahan data dan analisis statistik tradisional hingga pendekatan yang lebih holistik menggunakan kombinasi statistik  pembelajaran mesin  ilmu komputer  dan keahlian domain praktik ilmuwan data melibatkan eksplorasi dalam data  pembersihan  persiapan data  pembuatan hipotesis dan pemodelan  evaluasi  dan interpretasi yang berulang selama proses ini  ilmuwan data menggunakan berbagai teknik dan alat untuk mengoptimalkan penggunaan data dan menghasilkan wawasan yang berharga",
          "document_id": 1002
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa kegunaan fungsi f pada supervised learning?",
              "id": 3086,
              "answers": [
                {
                  "answer_id": 1427,
                  "document_id": 1018,
                  "question_id": 3086,
                  "text": " fungsi tersebut dapat digunakan untuk memetakan  memprediksi  input data baru  x  dengan tepat",
                  "answer_start": 646,
                  "answer_end": 741,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "jenis metode pembelajaran dibagi menjadi tiga yaitu supervised learning pembelajaran terbimbing   unsupervised learning pembelajaran tidak terbimbing   reinforcement learning kali ini kita akan membahas lebih detail tentang metode pembelajaran supervised learning supervised learning menggunakan dataset yang terdiri atas pasangan variable input x  dan output y  dimana supervised learning melakukan pembelajaran terhadap variable input x  dan output y  untuk mendapatkan fungsi f x  yang tepat yang dapat memetakan input x menjadi y variable ouput y berperan sebagai teacher yang membimbing proses pembelajaran  setelah fungsi f didapatkan  maka fungsi tersebut dapat digunakan untuk memetakan  memprediksi  input data baru  x  dengan tepat  fungsi f yang dihasilkan dari proses pembelajaran disebut juga sebagai model  classification model terdapat 3 jenis supervised learning yaitu 1  berdasarkan tipe ouputnya  pada jenis ini supervised learning dibagi menjadi 2 yaitu regresi dan klasifikasi  regresi  jika ouput y bernilai kontinu dan klasifikasi  jika ouput y bernilai diskret kategori",
          "document_id": 1018
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "algortima apa yang menggunakan tree sebagai model classifiernya ",
              "id": 2856,
              "answers": [
                {
                  "answer_id": 1242,
                  "document_id": 1029,
                  "question_id": 2856,
                  "text": "decision tree  ",
                  "answer_start": 436,
                  "answer_end": 451,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "algoritma ini mempunyai teknik yang sederhana karena tidak diperlukan pengetahuan awal mengenai bagaimana distribusi data cara kerja dari algortima ini yang pertama algortima ini mengklasifikasikan data baru  test tuple  berdasarkan kelas data dari k tetangga terdekat  nearest neighbors tetangga terdekat adalah training data yang memiliki tingkat kemiripan  similarity  tertinggi atau jarak  distance  terdekat terhadap test tuple 2  decision tree  algortima ini membuat model classifier dalam bentuk tree  pohon   yang terdiri dari  root node  fitur yang menjadi kriteria pertama pada tree yang dibangun   leaf node  label kelas   internal node  node diantara root node dan leaf node  dan branch  nilai yang mungkin muncul dari fitur terkait yang dipresentasikan pada node  root internal pada tree tersebut juga terdapat depth node",
          "document_id": 1029
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa tahap pertama dalam proyek analitik data ",
              "id": 2960,
              "answers": [
                {
                  "answer_id": 1218,
                  "document_id": 996,
                  "question_id": 2960,
                  "text": "business understanding adalah tahap pertama dalam proyek analitik data",
                  "answer_start": 1,
                  "answer_end": 71,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "mengapa proyek data sains juga disebut sebagai proyek bisnis ",
              "id": 2965,
              "answers": [
                {
                  "answer_id": 1219,
                  "document_id": 996,
                  "question_id": 2965,
                  "text": "selalu berorientasi pada pencapaian hasil yang fokus pada bisnis dan memiliki visi yang selaras dengan bisnis ",
                  "answer_start": 157,
                  "answer_end": 267,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "selain harus selalu berorientasi pada pencapaian hasil yang fokus pada bisnis  apakah hal penting yang menunjukkan bahwa proyek data sains adalah proyek bisnis ",
              "id": 2969,
              "answers": [
                {
                  "answer_id": 1220,
                  "document_id": 996,
                  "question_id": 2969,
                  "text": " memiliki visi yang selaras dengan bisnis",
                  "answer_start": 225,
                  "answer_end": 266,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " business understanding adalah tahap pertama dalam proyek analitik data penting untuk diingat bahwa proyek data science adalah proyek bisnis  sehingga harus selalu berorientasi pada pencapaian hasil yang fokus pada bisnis dan memiliki visi yang selaras dengan bisnis fokus utama tahap ini adalah menentukan masalah apa yang akan dicoba diselesaikan tiga hal utama dalam business understanding adalah menentukan masalah yang akan diselesaikan  menentukan tujuan proyek  dan melihat solusi yang memungkinkan dari perspektif bisnis penting juga untuk mendefinisikan bagaimana kita mengukur  keberhasilan  dan bagaimana cara mengukurnya",
          "document_id": 996
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana aplikasi sains data dalam berbagai industri?",
              "id": 3221,
              "answers": [
                {
                  "answer_id": 1577,
                  "document_id": 1015,
                  "question_id": 3221,
                  "text": "sains data memiliki aplikasi yang luas dan beragam dalam berbagai industri  membantu dalam pengambilan keputusan yang lebih baik dan memanfaatkan potensi data secara efektif",
                  "answer_start": 152,
                  "answer_end": 325,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "dalam ritel dan e commerce  sains data dapat digunakan untuk sistem rekomendasi  analisis prediktif  analisis sentimen  dan lainnya secara keseluruhan  sains data memiliki aplikasi yang luas dan beragam dalam berbagai industri  membantu dalam pengambilan keputusan yang lebih baik dan memanfaatkan potensi data secara efektif sains data memiliki beberapa keuntungan yang signifikan hal ini memungkinkan kita untuk mendapatkan wawasan yang berharga dari data historis menggunakan alat yang kuat dengan menggunakan sains data  bisnis dapat dioptimalkan  keputusan masa depan yang lebih baik dapat dibuat  dan target pelanggan dapat dipilih dengan lebih baik",
          "document_id": 1015
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Kenapa kemampuan pemrograman harus dikuasai oleh seorang saintis data?",
              "id": 3073,
              "answers": [
                {
                  "answer_id": 1414,
                  "document_id": 1000,
                  "question_id": 3073,
                  "text": "kemampuan pemrograman  terutama dalam bahasa python atau r  penting dalam mengelola dan memproses data secara efisien ",
                  "answer_start": 280,
                  "answer_end": 398,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "seorang saintis data memiliki keahlian dalam beberapa latar belakang yang penting mereka harus memahami konsep pembelajaran mesin untuk menghasilkan model prediktif yang akurat selain itu  pengetahuan statistik diperlukan untuk menganalisis data dan menarik kesimpulan yang valid kemampuan pemrograman  terutama dalam bahasa python atau r  penting dalam mengelola dan memproses data secara efisien pemahaman matematika juga diperlukan dalam pemodelan dan interpretasi data",
          "document_id": 1000
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Apa alat yang digunakan untuk analisis data?",
              "id": 3079,
              "answers": [
                {
                  "answer_id": 1420,
                  "document_id": 1010,
                  "question_id": 3079,
                  "text": "untuk analisis data  alat yang umum digunakan meliputi percikan  python  dan sas",
                  "answer_start": 88,
                  "answer_end": 168,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "ada berbagai alat yang tersedia bagi ilmuwan data dalam melaksanakan tugas tugas mereka untuk analisis data  alat yang umum digunakan meliputi percikan  python  dan sas dalam hal gudang data  alat seperti hadoop  sql  dan sarang lebah digunakan untuk mengelola dan menyimpan data dalam skala besar untuk visualisasi data  r  tableau  dan mentah menjadi pilihan yang populer untuk membuat visualisasi yang menarik dan informatif sedangkan dalam pembelajaran mesin  alat seperti percikan  azure ml studio  dan mahout digunakan untuk mengembangkan dan menerapkan model pembelajaran mesin",
          "document_id": 1010
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja jenis depth node?",
              "id": 3227,
              "answers": [
                {
                  "answer_id": 1584,
                  "document_id": 1032,
                  "question_id": 3227,
                  "text": "terdapat 4 jenis depth node yaitu id3  c4.5  cart  dii ",
                  "answer_start": 0,
                  "answer_end": 55,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "terdapat 4 jenis depth node yaitu id3  c4.5  cart  dii pada depth node attribute selection method atau splitting rules yang digunakan bervariasi algoritma decision tree bekerja dengan memilih fitur yang paling informatif dan membagi dataset berdasarkan nilai fitur tersebut setiap pemisahan menghasilkan cabang baru dalam pohon keputusan  yang mewakili kondisi yang harus dipenuhi proses ini dilakukan secara berulang hingga mencapai kondisi berhenti  seperti mencapai tingkat kedalaman maksimum atau tidak ada lagi pemisahan yang memberikan peningkatan signifikan dalam pemisahan kelas",
          "document_id": 1032
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa tujuan pelatihan dalam jst?",
              "id": 3231,
              "answers": [
                {
                  "answer_id": 1588,
                  "document_id": 1037,
                  "question_id": 3231,
                  "text": "tujuan pelatihan menentukan bobot bobot penghubung antar neuron dalam jst yang tepat  sehingga jst mampu memetakan input ke output yang tepat",
                  "answer_start": 398,
                  "answer_end": 539,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "menurut kertas mereka  itu berkinerja lebih baik daripada relu dengan tingkat yang sama efisiensi komputasi dalam percobaan di imagenet dengan model identik yang menjalankan relu dan swish  yang baru fungsi mencapai akurasi klasifikasi top  1 0 6 0 9  lebih tinggi learning atau training bertujuan untuk melatih jst proses training memerlukan data latih yang terdiri atas pasangan input dan output tujuan pelatihan menentukan bobot bobot penghubung antar neuron dalam jst yang tepat  sehingga jst mampu memetakan input ke output yang tepat",
          "document_id": 1037
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Bagaimana aplikasi sains data dalam bidang pemasaran?",
              "id": 3179,
              "answers": [
                {
                  "answer_id": 1525,
                  "document_id": 1012,
                  "question_id": 3179,
                  "text": "sains data memiliki berbagai aplikasi yang relevan dalam berbagai industri dalam bidang pemasaran  sains data dapat digunakan untuk mengembangkan strategi harga berdasarkan analisis data  meningkatkan keuntungan perusahaan  dan mengelompokkan pelanggan berdasarkan kebutuhan mereka ",
                  "answer_start": 0,
                  "answer_end": 282,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Bagaimana aplikasi sains data dalam bidang perbankan?",
              "id": 3081,
              "answers": [
                {
                  "answer_id": 1422,
                  "document_id": 1012,
                  "question_id": 3081,
                  "text": " di industri perbankan dan keuangan  sains data dapat membantu dalam deteksi penipuan dan pengelolaan aset bank",
                  "answer_start": 380,
                  "answer_end": 491,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sains data memiliki berbagai aplikasi yang relevan dalam berbagai industri dalam bidang pemasaran  sains data dapat digunakan untuk mengembangkan strategi harga berdasarkan analisis data  meningkatkan keuntungan perusahaan  dan mengelompokkan pelanggan berdasarkan kebutuhan mereka di sektor kesehatan  data dapat digunakan untuk mencegah dan memantau masalah kesehatan  sementara di industri perbankan dan keuangan  sains data dapat membantu dalam deteksi penipuan dan pengelolaan aset bank pemerintah juga dapat menggunakan sains data untuk menyusun kebijakan yang lebih baik berdasarkan data yang tersedia contoh aplikasi sains data dalam pemasaran dan iklan meliputi penggunaan analisis prediktif dan deskriptif untuk mengelompokkan pelanggan  serta analisis media sosial untuk memahami perilaku dan pola pikir pelanggan",
          "document_id": 1012
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "dimanakan produk diuji ketika test phase ",
              "id": 2938,
              "answers": [
                {
                  "answer_id": 1222,
                  "document_id": 1006,
                  "question_id": 2938,
                  "text": "di lingkungan bisnis nyata ",
                  "answer_start": 260,
                  "answer_end": 287,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "setelah produk diuji dan siap untuk digunakan  produk ini dirilis secara resmi di pasar yang sesuai terkadang penyebaran produk terjadi secara bertahap sesuai strategi bisnis organisasi itu produk ini pertama kali dapat dirilis dalam segmen terbatas dan diuji di lingkungan bisnis nyata  uat  user acceptance testing kemudian berdasarkan umpan balik  produk dapat dirilis apa itu atau dengan peningkatan yang disarankan di segmen pasar penargetan setelah produk dirilis di pasar  pemeliharaannya dilakukan untuk basis pelanggan yang ada",
          "document_id": 1006
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": " Apa contoh kekurangan dari penggunaan sains data?",
              "id": 3180,
              "answers": [
                {
                  "answer_id": 1526,
                  "document_id": 1017,
                  "question_id": 3180,
                  "text": "namun  penggunaan sains data juga memiliki beberapa kekurangan salah satunya adalah pelanggaran privasi pelanggan saat profil pelanggan digunakan ",
                  "answer_start": 0,
                  "answer_end": 146,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "namun  penggunaan sains data juga memiliki beberapa kekurangan salah satunya adalah pelanggaran privasi pelanggan saat profil pelanggan digunakan informasi pribadi mereka  seperti transaksi dan pembelian  dapat terlihat oleh perusahaan yang menggunakan sains data selain itu  informasi yang diperoleh melalui sains data juga dapat digunakan dengan cara yang merugikan  baik terhadap kelompok  individu  negara  maupun komunitas tertentu secara keseluruhan  sains data telah memberikan dampak besar pada berbagai industri utama  seperti perawatan kesehatan  e commerce  keuangan  perbankan  dan transportasi",
          "document_id": 1017
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja yang termasuk performance matrics?",
              "id": 3174,
              "answers": [
                {
                  "answer_id": 1520,
                  "document_id": 1027,
                  "question_id": 3174,
                  "text": "contoh dari performance matrics  accuracy  error rate  recall  sensitivity tpr   precision  f measure  fpr  false positive rate  false alarm  fnr false negative rate   specificity",
                  "answer_start": 564,
                  "answer_end": 743,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "teknik ini tidak menjamin distribusi sample data yang sama untuk masing masing kelas selanjutnya ada confusion matrix  matriks yang digunakan untuk merangkum hasil klasifikasi yang benar atau salah yang dihasilkan oleh sebuah metode model klasifikasi pada suatu dataset terdiri dari baris dan kolom yang berkaitan dengan informasi kelas sebenarnya  true classes gold standard actual class  dan kelas yang diprediksi  predicted classes confusion matrix bukanlah metrik performa  tetapi digunakan sebagai referensi untuk menghitung metrik performa terdapat beberapa contoh dari performance matrics  accuracy  error rate  recall  sensitivity tpr   precision  f measure  fpr  false positive rate  false alarm  fnr false negative rate   specificity",
          "document_id": 1027
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa algoritma yang membuat model dalam bentuk pohon?",
              "id": 3224,
              "answers": [
                {
                  "answer_id": 1580,
                  "document_id": 1022,
                  "question_id": 3224,
                  "text": " decision tree  algortima ini membuat model classifier dalam bentuk tree  pohon ",
                  "answer_start": 2,
                  "answer_end": 82,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "2  decision tree  algortima ini membuat model classifier dalam bentuk tree  pohon   yang terdiri dari  root node  fitur yang menjadi kriteria pertama pada tree yang dibangun   leaf node  label kelas   internal node  node diantara root node dan leaf node  dan branch  nilai yang mungkin muncul dari fitur terkait yang dipresentasikan pada node  root internal pada tree tersebut juga terdapat depth node depth node merupakan jumlah langkah minimum yang diperlukan untuk mencapai leaf node dari root node terdapat 4 jenis depth node yaitu id3  c4.5  cart  dii pada depth node attribute selection method atau splitting rules yang digunakan bervariasi",
          "document_id": 1022
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "siapa yang akan menggunakan informasi yang dihasilkan dari penggunaan data ",
              "id": 2844,
              "answers": [
                {
                  "answer_id": 1221,
                  "document_id": 1001,
                  "question_id": 2844,
                  "text": "para pengambilan keputusan",
                  "answer_start": 430,
                  "answer_end": 456,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "Apa saja langkah-langkah penggunaan data?",
              "id": 3177,
              "answers": [
                {
                  "answer_id": 1523,
                  "document_id": 1001,
                  "question_id": 3177,
                  "text": "penggunaan data melibatkan langkah langkah seperti analisis eksplorasi data untuk memahami karakteristik dan pola data  pembangunan model pengetahuan untuk menggambarkan hubungan antarvariabel  dan pengembangan model prediktif untuk membuat prediksi di masa depan",
                  "answer_start": 0,
                  "answer_end": 263,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "penggunaan data melibatkan langkah langkah seperti analisis eksplorasi data untuk memahami karakteristik dan pola data  pembangunan model pengetahuan untuk menggambarkan hubungan antarvariabel  dan pengembangan model prediktif untuk membuat prediksi di masa depan semua langkah langkah tersebut dilakukan di dalam proses penggunaan data setelah itu  data dievaluasi dan ditafsirkan untuk menghasilkan informasi yang berharga bagi para pengambilan keputusan selanjutnya  informasi tersebut dapat diimplementasikan dalam bentuk produk atau digunakan dalam proses pengambilan keputusan dengan menggunakan pendekatan ini  data dapat memberikan wawasan yang berharga dan mendukung pengambilan keputusan yang lebih baik setelah data dievaluasi dan ditafsirkan",
          "document_id": 1001
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "Bagaimana informasi dapat diimplementasikan?",
              "id": 3075,
              "answers": [
                {
                  "answer_id": 1416,
                  "document_id": 1003,
                  "question_id": 3075,
                  "text": "informasi tersebut dapat diimplementasikan dalam bentuk produk atau digunakan dalam proses pengambilan keputusan ",
                  "answer_start": 13,
                  "answer_end": 126,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "selanjutnya  informasi tersebut dapat diimplementasikan dalam bentuk produk atau digunakan dalam proses pengambilan keputusan dengan menggunakan pendekatan ini  data dapat memberikan wawasan yang berharga dan mendukung pengambilan keputusan yang lebih baik setelah data dievaluasi dan ditafsirkan dengan demikian  teradapat lima tahapan penggunaan data untuk menghasilkan informasi berharga bagi pengambilan keputusan  yaitu analisis eksplorasi data  pembangunan model pengetahuan  pengembangan model prediktif  evaluasi data  dan interpretasi data seorang saintis data memiliki keahlian dalam beberapa latar belakang yang penting mereka harus memahami konsep pembelajaran mesin untuk menghasilkan model prediktif yang akurat",
          "document_id": 1003
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kapan intuisi diperlukan?",
              "id": 3113,
              "answers": [
                {
                  "answer_id": 1456,
                  "document_id": 1008,
                  "question_id": 3113,
                  "text": "intuisi diperlukan dalam memilih model yang tepat dengan akurasi yang sesuai  serta merasakan kapan model siap untuk diimplementasikan ",
                  "answer_start": 0,
                  "answer_end": 135,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "intuisi diperlukan dalam memilih model yang tepat dengan akurasi yang sesuai  serta merasakan kapan model siap untuk diimplementasikan keingintahuan juga menjadi kunci dalam sains data  karena bidang ini terus berkembang dengan metode dan teknologi baru yang terus muncul sebagai ilmuwan data  memiliki rasa ingin tahu yang kuat untuk mempelajari dan mengikuti perkembangan teknologi menjadi sangat penting ada berbagai alat yang tersedia bagi ilmuwan data dalam melaksanakan tugas tugas mereka untuk analisis data  alat yang umum digunakan meliputi percikan  python  dan sas",
          "document_id": 1008
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kapan karnel non linear digunakan?",
              "id": 3212,
              "answers": [
                {
                  "answer_id": 1565,
                  "document_id": 1030,
                  "question_id": 3212,
                  "text": "karnel non linear digunakan ketika data hanya dapat dipisahkan dengan garis lengkung atau sebuah bidang pada ruang dimensi tinggi",
                  "answer_start": 0,
                  "answer_end": 129,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "karnel non linear digunakan ketika data hanya dapat dipisahkan dengan garis lengkung atau sebuah bidang pada ruang dimensi tinggi selanjutnya terdapat model assement merupakan proses mengestimasi dan mengevaluasi kinerja berbagai model untuk memilih yang terbaik dan model selection merupakan proses memilih model terbaik setelah melalui evaluasi performa dan mempertimbangkan kesalahan prediksi pada data baru terdapat 3 teknik validasi untuk menguji kinerja model  yaitu 1  k folds cross validation  ini adalah metode validasi yang membagi data latih menjadi k subset atau  fold dalam setiap iterasi  salah satu subset digunakan sebagai data validasi  sementara k 1 subset lainnya digunakan sebagai data pelatihan proses ini diulang k kali  sehingga setiap subset digunakan sebagai data validasi tepat satu kali",
          "document_id": 1030
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dimaksud jaringan recurrent?",
              "id": 3230,
              "answers": [
                {
                  "answer_id": 1587,
                  "document_id": 1036,
                  "question_id": 3230,
                  "text": "jaringan recurrent adalah jaringan yang terdapat neuron output yang memberi sinyal pada unit input sering disebut feedback loop",
                  "answer_start": 0,
                  "answer_end": 127,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "jaringan recurrent adalah jaringan yang terdapat neuron output yang memberi sinyal pada unit input sering disebut feedback loop fungsi aktivasi adalah  gerbang  matematis di antara input yang memberi makan neuron saat ini dan outputnya menuju lapisan berikutnya pada perkembangannya  nn menggunakan fungsi aktivasi non linear yang dapat digunakan untuk membantu jaringan mempelajari data kompleks  dan memberikan prediksi yang akurat tipe fungsi aktivasi terdiri dari binary step function  linear activation function  dan non linear activation function fungsi langkah biner adalah aktivasi berbasis ambang batas fungsi",
          "document_id": 1036
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dimaksud artificial intelligence?",
              "id": 3087,
              "answers": [
                {
                  "answer_id": 1428,
                  "document_id": 1019,
                  "question_id": 3087,
                  "text": " artificial intelligence ai  adalah sebuah teknik yang memungkinkan komputer untuk meniru manusia",
                  "answer_start": 0,
                  "answer_end": 97,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " artificial intelligence ai  adalah sebuah teknik yang memungkinkan komputer untuk meniru manusia  yang membedakan manusia dan komputer adalah cara mereka dalam memahami suatu permasalahan manusia memahami suatu permasalahan melalui pengalaman yang dimiliki  sementara komputer mengandalkan data yang ada di dalam sistemnya machine learning merupakan subbidang dari kecerdasan buatan  machine learning dapat dianggap sebagai proses yang memungkinkan komputer atau mesin untuk meningkatkan kemampuannya berdasarkan pengalama yang bersumber dari data yang ada  sehingga akhirnya memiliki kecerdasan yang mirip dengan manusia jenis metode pembelajaran dibagi menjadi tiga yaitu supervised learning pembelajaran terbimbing   unsupervised learning pembelajaran tidak terbimbing   reinforcement learning kali ini kita akan membahas lebih detail tentang metode pembelajaran supervised learning",
          "document_id": 1019
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara untuk analisis tren data?",
              "id": 3083,
              "answers": [
                {
                  "answer_id": 1424,
                  "document_id": 1014,
                  "question_id": 3083,
                  "text": "analisis tren data menggunakan alat business intelligence ",
                  "answer_start": 566,
                  "answer_end": 624,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "selain itu  informasi yang diperoleh melalui sains data juga dapat digunakan dengan cara yang merugikan  baik terhadap kelompok  individu  negara  maupun komunitas tertentu secara keseluruhan  sains data telah memberikan dampak besar pada berbagai industri utama  seperti perawatan kesehatan  e commerce  keuangan  perbankan  dan transportasi dalam upaya meningkatkan produk dan basis pelanggan  sains data telah menjadi bagian integral dari semua industri selain itu  aplikasi utama sains data juga meliputi deteksi penipuan di sektor keuangan dan perbankan  serta analisis tren data menggunakan alat business intelligence oleh karena itu  sains data menjadi kunci untuk pertumbuhan dan kemajuan industri dalam domain mereka masing masing",
          "document_id": 1014
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dimaksud sebagai clustering ",
              "id": 2891,
              "answers": [
                {
                  "answer_id": 1271,
                  "document_id": 1075,
                  "question_id": 2891,
                  "text": " clustering adalah pengelompokan data points untuk menghasilkan cluster kelompok berdasarkan kesamaan data ",
                  "answer_start": 0,
                  "answer_end": 107,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " clustering adalah pengelompokan data points untuk menghasilkan cluster kelompok berdasarkan kesamaan data clustering masuk dalam kelas unsupervised learning karena proses pelatihan dilakukan tanpa menggunakan label cluster analysis mengelompokkan objek data hanya berdasarkan informasi yang ditemukan dalam data yang menggambarkan objek dan hubungannya tujuannya adalah agar objek objek dalam suatu kelompok serupa  terkait  satu sama lain  dan berbeda  atau tidak terkait  dengan objek objek dalam kelompok lain semakin besar kesamaan  atau homogenitas  dalam suatu kelompok dan semakin besar perbedaan antar kelompok  semakin baik atau lebih jelas pengelompokannya",
          "document_id": 1075
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara kerja fungsi langkah biner ",
              "id": 2873,
              "answers": [
                {
                  "answer_id": 1248,
                  "document_id": 1039,
                  "question_id": 2873,
                  "text": "jika nilai input di atas atau di bawah ambang batas tertentu  maka neuron diaktifkan dan mengirimkan sinyal yang persis sama ke lapisan berikutnya ",
                  "answer_start": 185,
                  "answer_end": 332,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "tipe fungsi aktivasi terdiri dari binary step function  linear activation function  dan non linear activation function fungsi langkah biner adalah aktivasi berbasis ambang batas fungsi jika nilai input di atas atau di bawah ambang batas tertentu  maka neuron diaktifkan dan mengirimkan sinyal yang persis sama ke lapisan berikutnya macam fungsi langkah biner  fungsi undak biner  fungsi undak biner fungsi bipolar  dan fungsi bipolar dengan threshold fungsi aktivasi linier berbentuk ğ´   ğ",
          "document_id": 1039
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang diharapkan setelah proses pelatihan jst?",
              "id": 3098,
              "answers": [
                {
                  "answer_id": 1439,
                  "document_id": 1050,
                  "question_id": 3098,
                  "text": "setelah proses pelatihan jst diharapkan mampu memetakan input data ke output data yang tepat menggunakan bobot bobot yang didapat dari proses pelatihan",
                  "answer_start": 224,
                  "answer_end": 375,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "proses training memerlukan data latih yang terdiri atas pasangan input dan output tujuan pelatihan menentukan bobot bobot penghubung antar neuron dalam jst yang tepat  sehingga jst mampu memetakan input ke output yang tepat setelah proses pelatihan jst diharapkan mampu memetakan input data ke output data yang tepat menggunakan bobot bobot yang didapat dari proses pelatihan layer konvlusi adalah layer untuk ekstrasi fitur map secara spasialm dan sebuah cnn dapat memiliki beberapa layer konvlusi layer konvolusi pada bagian awal akan mempelajari representasi fitur atau pola spasial yang sederhana  sedangkan layer konvolusi yang lebih dalam akan mempelajari representasi fitur yang lebih kompleks",
          "document_id": 1050
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu algoritma decision tree?",
              "id": 3237,
              "answers": [
                {
                  "answer_id": 1594,
                  "document_id": 1055,
                  "question_id": 3237,
                  "text": "decision tree merupakan algoritma supervised learning yang dapat digunakan baik untuk klasifikasi maupun regresi ",
                  "answer_start": 117,
                  "answer_end": 230,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sementara kelemahannya adalah tidak cocok untuk dataset besar dan peforma buruk ketika dataset memiliki banyak noise decision tree merupakan algoritma supervised learning yang dapat digunakan baik untuk klasifikasi maupun regresi decision tree regression  dtr  merupakan algoritma decision tree yang digunakan untuk tugas regresi  sehingga dapat digunakan untuk memprediksi keluaran bernilai kontinu algoritme dtr bekerja dengan membagi data menurut atribut yang berbeda di setiap node sambil mencoba mengurangi ukuran seleksi  gini index  yang kemudian dapat digunakan untuk memprediksi hasil variabel target struktur dari decision tree terdiri dari simpul  node  yang mewakili fitur  cabang  branch  yang mewakili keputusan  dan daun  leaf  mewakili hasil  nilai numerik untuk regresi",
          "document_id": 1055
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa kegunaan prediction error?",
              "id": 3238,
              "answers": [
                {
                  "answer_id": 1596,
                  "document_id": 1060,
                  "question_id": 3238,
                  "text": "prediction error  digunakan untuk menentukan kinerja model kesalahan prediksi juga disebut sebagai residual dan didefinisikan sebagai perbedaan antara nilai aktual dan prediksi metrik evaluasi ",
                  "answer_start": 252,
                  "answer_end": 445,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sementara kelemahannya adalah cenderung overfit dan penggunaan random forest ensembles yang lebih besar dapat meningkatkan performa  namun akan memperlambat waktu komputasi dan membutuhkan lebih banyak memori dalam masalah regresi  kesalahan prediksi  prediction error  digunakan untuk menentukan kinerja model kesalahan prediksi juga disebut sebagai residual dan didefinisikan sebagai perbedaan antara nilai aktual dan prediksi metrik evaluasi regresi diantaranya pertama adalah mean absolute error  mae  adalah rata rata perbedaan absolut antara nilai aktual dalam kumpulan data dan nilai yang diprediksi semakin kecil mae  semakin akurat modelnya",
          "document_id": 1060
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa tujuan utama svr?",
              "id": 3242,
              "answers": [
                {
                  "answer_id": 1600,
                  "document_id": 1065,
                  "question_id": 3242,
                  "text": "tujuan utama svr pada dasarnya adalah mempertimbangkan titik titik data yang berada di dalam decision boundary ",
                  "answer_start": 47,
                  "answer_end": 158,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data ini digunakan untuk memplot boundary line tujuan utama svr pada dasarnya adalah mempertimbangkan titik titik data yang berada di dalam decision boundary pada proses pembuatan model  tidak masalah seberapa jauh titik data dari hyperplane yang dimodelkan selama berada dalam rentang yang ditentukan   Ïµ hingga  Ïµ namun  penyimpangan yang melebihi batas yang ditentukan  decision boundary  tidak diperbolehkan dengan ini  svr memberikan fleksibilitas untuk menentukan seberapa besar error yang dapat diterima pada model  dan akan mencari hyperplane terbaik yang sesuai pada data",
          "document_id": 1065
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "algoritma optimasi mengestimasi parameter koefisien  b  dan konstanta  bo  pada regresi linier variabel jamak dengan menggunakan ",
              "id": 2890,
              "answers": [
                {
                  "answer_id": 1269,
                  "document_id": 1070,
                  "question_id": 2890,
                  "text": "dua cara yaitu least squares dengan menggunakan operasi aljabar linier dan cara kedua yaitu algoritma optimasi dengan gradient descent",
                  "answer_start": 113,
                  "answer_end": 247,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "bnxn parameter koefisien  b  dan konstanta  bo  pada regresi linier variabel jamak dapat di estimasi menggunakan dua cara yaitu least squares dengan menggunakan operasi aljabar linier dan cara kedua yaitu algoritma optimasi dengan gradient descent least squares memerlukan waktu lama pada dataset besar  lebih dari 10000 baris   sementara algoritma optimasi cocok digunakan pada dataset besar metrik mse  mean squared error  digunakan pada estimasi parameter menggunakan optimasi gradient descent untuk menunjukkan nilai error kelebihan regresi linear adalah ringan  mudah dipahami  mudah diimplementasikan dan tidak memerlukan tuning parameter",
          "document_id": 1070
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dihitung dari silhouette coefficient?",
              "id": 3257,
              "answers": [
                {
                  "answer_id": 1615,
                  "document_id": 1080,
                  "question_id": 3257,
                  "text": "nilai kohesi dan separasi ini dapat dievaluasi secara sekaligus yang disebut sebagai silhouette coefficient",
                  "answer_start": 205,
                  "answer_end": 312,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "evaluasi ini disebut juga sebagai supervised measure evaluation beberapa metode untuk melakukan evaluasi tanpa label  inner indices unsupervised evaluation measure  di antaranya adalah kohesi dan separasi nilai kohesi dan separasi ini dapat dievaluasi secara sekaligus yang disebut sebagai silhouette coefficient kohesi adalah ukuran kedekatan data dalam suatu cluster kohesi didapatkan dengan menghitung rata rata jarak data dengan data lain dalam cluster yang sama",
          "document_id": 1080
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja 7 fungsi aktivasi non linear ",
              "id": 2869,
              "answers": [
                {
                  "answer_id": 1249,
                  "document_id": 1040,
                  "question_id": 2869,
                  "text": "7 fungsi aktivasi nonlinear umum yaitu  sigmoid  tanh  relu  leacky relu  paramtric relu  softmax  swish ",
                  "answer_start": 0,
                  "answer_end": 105,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "7 fungsi aktivasi nonlinear umum yaitu  sigmoid  tanh  relu  leacky relu  paramtric relu  softmax  swish salah satu keuntungan fungsi sigmoid yaitu prediksi yang jelas  untuk x di atas 2 atau di bawah  2  cenderung membawa nilai y  the prediksi  ke tepi kurva  sangat dekat dengan 1 atau 0. hal ini memungkinkan jelas prediksi tetapi kekurangannya yaitu vanishing gradient  untuk nilai x yang sangat tinggi atau sangat rendah  hampir tidak ada perubahan pada prediksi  menyebabkan masalah gradien menghilang hal ini dapat mengakibatkan jaringan menolak untuk belajar lebih jauh atau terlalu lambat untuk mencapai prediksi yang akurat fungsi tanh memiliki keuntungan berpusat pada nol mempermudah memodelkan input itu memiliki sangat negatif  netral  dan sangat positif nilai nilai",
          "document_id": 1040
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana pengelompokkan dalam k means clustering?",
              "id": 3254,
              "answers": [
                {
                  "answer_id": 1612,
                  "document_id": 1076,
                  "question_id": 3254,
                  "text": "k means clustering mengelompokkan n objek ke dalam k cluster berdasarkan nilai atribut dari objek tersebut",
                  "answer_start": 261,
                  "answer_end": 367,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "clustering pada bidang biologi dapat digunakan untuk taksonomi makhluk hidup seperti kingdom  filum  kelas  ordo  famili  genus  dan spesies k means clustering adalah prototype based clustering dan merupakan one level partitioning dari objek yang ada pada data k means clustering mengelompokkan n objek ke dalam k cluster berdasarkan nilai atribut dari objek tersebut karena k adalah jumlah cluster  maka k adalah berupa bilangan integer positif berikut adalah algoritma k means clustering  1  pilih sejumlah k titik sebagai centroid awal  2  ulangi langkah langkah 3 dan 4 hingga centroid tidak berubah  3  bentuk sejumlah k cluster dengan mengelompokkan masing masing data point ke centroid terdekat  4  hitung ulang centroid masing masing kelompok  cluster",
          "document_id": 1076
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana algoritma dtr bekerja?",
              "id": 3236,
              "answers": [
                {
                  "answer_id": 1593,
                  "document_id": 1056,
                  "question_id": 3236,
                  "text": "algoritme dtr bekerja dengan membagi data menurut atribut yang berbeda di setiap node sambil mencoba mengurangi ukuran seleksi  gini index  yang kemudian dapat digunakan untuk memprediksi hasil variabel target ",
                  "answer_start": 0,
                  "answer_end": 210,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "algoritme dtr bekerja dengan membagi data menurut atribut yang berbeda di setiap node sambil mencoba mengurangi ukuran seleksi  gini index  yang kemudian dapat digunakan untuk memprediksi hasil variabel target struktur dari decision tree terdiri dari simpul  node  yang mewakili fitur  cabang  branch  yang mewakili keputusan  dan daun  leaf  mewakili hasil  nilai numerik untuk regresi dengan titik data tertentu  dijalankan sepenuhnya melalui seluruh pohon dengan menjawab pertanyaan benar salah hingga mencapai leaf node prediksi akhir adalah rata rata dari nilai variabel dependen dalam leaf node tertentu melalui beberapa iterasi  pohon mampu memprediksi nilai yang tepat untuk titik data",
          "document_id": 1056
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "model regresi linier lebih cocok digunakan untuk  apa?",
              "id": 3243,
              "answers": [
                {
                  "answer_id": 1601,
                  "document_id": 1066,
                  "question_id": 3243,
                  "text": "model regresi linier lebih cocok digunakan untuk mendapatkan akurasi prediksi yang tinggi",
                  "answer_start": 139,
                  "answer_end": 228,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "pada regresi linier  data yang diplot memiliki hubungan linier atau berupa garis lurus antara dependent dan independent variables sehingga model regresi linier lebih cocok digunakan untuk mendapatkan akurasi prediksi yang tinggi jika data berbentuk non linier  model linier akan memberikan nilai error yang tinggi karena terdapat ketidakcocokan maka dari itu perlu dibangun hubungan polinomial yang dapat menyesuaikan data points  model ini dinamakan polynomial regression rumus polynomial regression adalah y   b0 b1x b2x 2 b3x 3",
          "document_id": 1066
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "persentase kesalahan rata rata dari model dihitung dengan apa?",
              "id": 3252,
              "answers": [
                {
                  "answer_id": 1610,
                  "document_id": 1071,
                  "question_id": 3252,
                  "text": "mean percentage error  mpe  adalah persentase kesalahan rata rata yang dihitung dengan perkiraan sebuah model berbeda dari nilai aktual kuantitas yang diramalkan",
                  "answer_start": 245,
                  "answer_end": 406,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "yang keenam  mean absolute percentage error  mape  mengukur akurasi sebagai persentase  dan dapat dihitung sebagai kesalahan persentase absolut rata rata untuk setiap periode waktu dikurangi nilai aktual dibagi dengan nilai aktual yang ketujuh  mean percentage error  mpe  adalah persentase kesalahan rata rata yang dihitung dengan perkiraan sebuah model berbeda dari nilai aktual kuantitas yang diramalkan yang terakhit  r squared yang memperkirakan rasio varian dari elemen dependen yang dijelaskan oleh elemen target",
          "document_id": 1071
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "mengapa lapisan neuron diperlukan?",
              "id": 3235,
              "answers": [
                {
                  "answer_id": 1592,
                  "document_id": 1051,
                  "question_id": 3235,
                  "text": "lapisan neuron diperlukan untuk mempelajari data yang kompleks set dengan tingkat akurasi yang tinggi ",
                  "answer_start": 458,
                  "answer_end": 560,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "mereka mengizinkan model untuk membuat pemetaan kompleks antara input dan output jaringan  yang penting untuk belajar dan memodelkan data yang kompleks  seperti gambar  kumpulan video  audio  dan data yang tidak linier atau berdimensi tinggi mereka mengizinkan backpropagation karena mereka punya fungsi turunan yang terkait dengan input dan juga memungkinkan  penumpukan  beberapa lapisan neuron untuk membuat jaringan saraf yang dalam beberapa tersembunyi lapisan neuron diperlukan untuk mempelajari data yang kompleks set dengan tingkat akurasi yang tinggi 7 fungsi aktivasi nonlinear umum yaitu  sigmoid  tanh  relu  leacky relu  paramtric relu  softmax  swish salah satu keuntungan fungsi sigmoid yaitu prediksi yang jelas  untuk x di atas 2 atau di bawah  2  cenderung membawa nilai y  the prediksi  ke tepi kurva  sangat dekat dengan 1 atau 0. hal ini memungkinkan jelas prediksi",
          "document_id": 1051
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa keunggulan algoritma relieff?",
              "id": 3239,
              "answers": [
                {
                  "answer_id": 1597,
                  "document_id": 1061,
                  "question_id": 3239,
                  "text": "algoritma relieff lebih robost sehingga mampu menangani data yang tidak lengkap dan data yang mengandung noise ",
                  "answer_start": 0,
                  "answer_end": 111,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "algoritma relieff lebih robost sehingga mampu menangani data yang tidak lengkap dan data yang mengandung noise wrapper method mencari kombinasi subset fitur yang optimal dengan mengevaluasinya secara langsung pada algoritma pembelajaran tertentu kriteria evaluasi biasanya berupa metrik performa model pada kasus regresi  dapat berupa mse  sedangkan pada kasus klasifikasi dapat berupa akurasi  precision  recall atau yang lainnya biasanya membutuhkan biaya komputasi yang tinggi",
          "document_id": 1061
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu layer konvolusi?",
              "id": 3097,
              "answers": [
                {
                  "answer_id": 1438,
                  "document_id": 1048,
                  "question_id": 3097,
                  "text": "layer konvlusi adalah layer untuk ekstrasi fitur map secara spasialm dan sebuah cnn dapat memiliki beberapa layer konvlusi layer konvolusi pada bagian awal akan mempelajari representasi fitur atau pola spasial yang sederhana  sedangkan layer konvolusi yang lebih dalam akan mempelajari representasi fitur yang lebih kompleks",
                  "answer_start": 0,
                  "answer_end": 324,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "layer konvlusi adalah layer untuk ekstrasi fitur map secara spasialm dan sebuah cnn dapat memiliki beberapa layer konvlusi layer konvolusi pada bagian awal akan mempelajari representasi fitur atau pola spasial yang sederhana  sedangkan layer konvolusi yang lebih dalam akan mempelajari representasi fitur yang lebih kompleks pooling layer  layer ini berfungsi untuk mereduksi ukuran output dari activation map agar jumlah jumlah parameter jaringan menjadi lebih kecil sehingga dapat mempercepat komputasi dan menghindari overfitting setiap pooling layer umumnya memiliki 2 parameter  yaitu ukuran filter dan panjang stride  pergeseran terdapat 2 jenis operasi pooling yakni max pooling dan average pooling",
          "document_id": 1048
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kenapa model regresi liner lebih cocok digunakan untuk mendapatkan akurasi prediksi yang tinggi?",
              "id": 3100,
              "answers": [
                {
                  "answer_id": 1441,
                  "document_id": 1052,
                  "question_id": 3100,
                  "text": " data yang diplot memiliki hubungan linier atau berupa garis lurus antara dependent dan independent variables sehingga model regresi linier lebih cocok digunakan untuk mendapatkan akurasi prediksi yang tinggi",
                  "answer_start": 440,
                  "answer_end": 648,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "metrik mse  mean squared error  digunakan pada estimasi parameter menggunakan optimasi gradient descent untuk menunjukkan nilai error kelebihan regresi linear adalah ringan  mudah dipahami  mudah diimplementasikan dan tidak memerlukan tuning parameter kelemahan regresi linear adalah sangat sensitif terhadap outliers dan terlalu sederhana untuk real world problems  dengan mengasumsikan hubungan linear antara variabel pada regresi linier  data yang diplot memiliki hubungan linier atau berupa garis lurus antara dependent dan independent variables sehingga model regresi linier lebih cocok digunakan untuk mendapatkan akurasi prediksi yang tinggi",
          "document_id": 1052
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana evaluasi clustering dengan menggunakan clustering ",
              "id": 2916,
              "answers": [
                {
                  "answer_id": 1270,
                  "document_id": 1074,
                  "question_id": 2916,
                  "text": " evaluasi pada clustering dapat dilakukan dengan berbagai cara yang dapat dikelompokkan sebagai evaluasi tanpa label dan evaluasi dengan label",
                  "answer_start": 292,
                  "answer_end": 434,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "cluster yang dihasilkan dinilai valid atau tidak yaitu untuk melihat apakah benar benar ada struktur dalam data yang telah dikelompokkan hasil clustering dibandingkan  baik dengan algoritma yang sama ataupun dengan algoritma yang berbeda  untuk membandingkan dua atau lebih analisa clustering evaluasi pada clustering dapat dilakukan dengan berbagai cara yang dapat dikelompokkan sebagai evaluasi tanpa label dan evaluasi dengan label evaluasi tanpa label dilakukan dengan mengukur baik atau tidaknya hasil clustering tanpa menggunakan data luar atau label evaluasi ini disebut juga sebagai unsupervised measure evaluation",
          "document_id": 1074
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dimaksud dengan relative absolute error?",
              "id": 3245,
              "answers": [
                {
                  "answer_id": 1603,
                  "document_id": 1069,
                  "question_id": 3245,
                  "text": "relative absolute error  rae  dinyatakan sebagai rasio  membandingkan mean error  residual  dengan kesalahan yang dihasilkan oleh sebuah trivial atau naive model ",
                  "answer_start": 53,
                  "answer_end": 215,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "jika mae besar maka modelnya tidak bagus yang kedua  relative absolute error  rae  dinyatakan sebagai rasio  membandingkan mean error  residual  dengan kesalahan yang dihasilkan oleh sebuah trivial atau naive model model yang masuk akal akan menghasilkan rasio kurang dari satu yang ketiga  mean squared error  mse  adalah rata rata perbedaan kuadrat dari nilai aktual dalam kumpulan data dan nilai yang diprediksi oleh model mse berfokus pada kesalahan yang lebih besar  seperti saat kita mengkuadratkan efek kesalahan kesalahan besar menjadi lebih menonjol",
          "document_id": 1069
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "mengapa suatu titik dianggap sebagai core points?",
              "id": 3215,
              "answers": [
                {
                  "answer_id": 1568,
                  "document_id": 1084,
                  "question_id": 3215,
                  "text": "titik diklasifikasikan sebagai core  boundary  atau outlier titik adalah core point jika setidaknya ada sejumlah minpts titik  termasuk titik itu sendiri  di daerah sekitarnya dalam radius eps",
                  "answer_start": 273,
                  "answer_end": 465,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "parameter eps adalah jarak yang menentukan ketetanggaan  neighborhood dua titik dianggap sebagai tetangga jika jarak di antara mereka kurang dari atau sama dengan eps parameter minpts adalah jumlah minimum titik data untuk menentukan cluster berdasarkan dua parameter ini  titik diklasifikasikan sebagai core  boundary  atau outlier titik adalah core point jika setidaknya ada sejumlah minpts titik  termasuk titik itu sendiri  di daerah sekitarnya dalam radius eps",
          "document_id": 1084
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara melakukan agglomerative hierarchical cluster?",
              "id": 3255,
              "answers": [
                {
                  "answer_id": 1613,
                  "document_id": 1078,
                  "question_id": 3255,
                  "text": "agglomerative hierarchical cluster dilakukan dengan  1  menghitung matriks jarak antar data  2  ulangi langkah 3 dan 4 sehingga hanya satu kelompok yang tersisa  3  gabungkan dua kelompok terdekat berdasarkan parameter kedekatan yang ditentukan  4  perbarui matriks jarak antar data untuk merepresentasikan kedekatan di antara kelompok baru dan kelompok yang masih tersisa  5  selesai ",
                  "answer_start": 101,
                  "answer_end": 486,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "strategi pengelompokannya umumnya ada 2 jenis yaitu agglomerative  bottom up  dan divisive  top down agglomerative hierarchical cluster dilakukan dengan  1  menghitung matriks jarak antar data  2  ulangi langkah 3 dan 4 sehingga hanya satu kelompok yang tersisa  3  gabungkan dua kelompok terdekat berdasarkan parameter kedekatan yang ditentukan  4  perbarui matriks jarak antar data untuk merepresentasikan kedekatan di antara kelompok baru dan kelompok yang masih tersisa  5  selesai dbscan  density based spatial clustering of application with noise  clustering adalah algoritma clustering berdasar kepadatan data algoritma ini mampu menemukan cluster dengan sembarang bentuk  tidak harus bentuk sphere  dan mampu menghandle noise dengan baik ide utama dbscan adalah bahwa suatu titik adalah milik suatu cluster jika terletak dekat dengan banyak titik dari cluster tersebut",
          "document_id": 1078
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dimaksud dengan mean squared error?",
              "id": 3104,
              "answers": [
                {
                  "answer_id": 1595,
                  "document_id": 1058,
                  "question_id": 3104,
                  "text": "mean squared error  mse  adalah rata rata perbedaan kuadrat dari nilai aktual dalam kumpulan data dan nilai yang diprediksi oleh model ",
                  "answer_start": 13,
                  "answer_end": 148,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "yang ketiga  mean squared error  mse  adalah rata rata perbedaan kuadrat dari nilai aktual dalam kumpulan data dan nilai yang diprediksi oleh model mse berfokus pada kesalahan yang lebih besar  seperti saat kita mengkuadratkan efek kesalahan kesalahan besar menjadi lebih menonjol yang keempat  relative squared error  rse  yang mengambil kesalahan kuadrat total dan menormalkannya dengan membaginya dengan kuadrat total kesalahan prediktor sederhana yang kelima  root mean squared error  rmse  adalah perbedaan rata rata akar kuadrat antara nilai sebenarnya dan nilai prediksi dengan mengambil sebuah kuadrat dari mse  kita mendapatkan root mean square error",
          "document_id": 1058
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa kelebihan random forest regression?",
              "id": 3241,
              "answers": [
                {
                  "answer_id": 1599,
                  "document_id": 1063,
                  "question_id": 3241,
                  "text": "kelebihan random forest regression adalah mudah dipahami dan diinterpretasikan serta baik dalam mempelajari hubungan yang kompleks dan non linear ",
                  "answer_start": 244,
                  "answer_end": 390,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "dengan menggabungkan beberapa decision tree yang tidak berkorelasi  seringkali peningkatan akurasi model yang signifikan dapat dicapai decision tree yang memiliki kelemahan overfitting dapat dikurangi dengan menggunakan algoritma random forest kelebihan random forest regression adalah mudah dipahami dan diinterpretasikan serta baik dalam mempelajari hubungan yang kompleks dan non linear sementara kelemahannya adalah cenderung overfit dan penggunaan random forest ensembles yang lebih besar dapat meningkatkan performa  namun akan memperlambat waktu komputasi dan membutuhkan lebih banyak memori dalam masalah regresi  kesalahan prediksi  prediction error  digunakan untuk menentukan kinerja model",
          "document_id": 1063
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa masalah dari fungsi linear?",
              "id": 3233,
              "answers": [
                {
                  "answer_id": 1590,
                  "document_id": 1045,
                  "question_id": 3233,
                  "text": "dua masalah utama fungsi linier  tidak mungkin menggunakan backpropagation  gradient descent  untuk melatih model  turunan dari fungsi adalah konstanta  dan tidak memiliki kaitannya dengan input  x jadi tidak mungkin untuk kembali dan memahami yang bobot di input ",
                  "answer_start": 160,
                  "answer_end": 424,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "macam fungsi langkah biner  fungsi undak biner  fungsi undak biner fungsi bipolar  dan fungsi bipolar dengan threshold fungsi aktivasi linier berbentuk ğ´   ğ dua masalah utama fungsi linier  tidak mungkin menggunakan backpropagation  gradient descent  untuk melatih model  turunan dari fungsi adalah konstanta  dan tidak memiliki kaitannya dengan input  x jadi tidak mungkin untuk kembali dan memahami yang bobot di input neuron dapat memberikan prediksi yang lebih baik dan semua lapisan jaringan saraf runtuh menjadi satu  dengan linier fungsi aktivasi  tidak peduli berapa banyak lapisan dalam saraf jaringan  lapisan terakhir akan menjadi fungsi linier dari lapisan pertama  karena kombinasi linear dari fungsi linear tetaplah linear fungsi jadi fungsi aktivasi linier mengubah jaringan saraf menjadi hanya satu lapisan",
          "document_id": 1045
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dimaksud dengan atribut binary ",
              "id": 2977,
              "answers": [
                {
                  "answer_id": 1258,
                  "document_id": 1049,
                  "question_id": 2977,
                  "text": " atribut binary merupakan atribut nominal dengan hanya 2 nilai  yaitu 0 dan 1",
                  "answer_start": 324,
                  "answer_end": 401,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa yang dimaksud dengan atribut ",
              "id": 2981,
              "answers": [
                {
                  "answer_id": 1259,
                  "document_id": 1049,
                  "question_id": 2981,
                  "text": "atribut juga dikenal dengan sebutan variabel atau fitur ",
                  "answer_start": 96,
                  "answer_end": 152,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "atribut terbagi menjadi tipe apa saja ",
              "id": 2997,
              "answers": [
                {
                  "answer_id": 1261,
                  "document_id": 1049,
                  "question_id": 2997,
                  "text": " nominal  binary  ordinal  dan numeric",
                  "answer_start": 202,
                  "answer_end": 240,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa yang dimaksud dengan atribut ordinal ",
              "id": 2980,
              "answers": [
                {
                  "answer_id": 1260,
                  "document_id": 1049,
                  "question_id": 2980,
                  "text": " atribut ordinal merupakan nilai yang merepresentasikan urutan  misalkan nilai mata kuliah",
                  "answer_start": 402,
                  "answer_end": 492,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "misalnya  untuk data mahasiswa  terdapat atribut nama  nim  usia  jenis kelamin  dan sebagainya atribut juga dikenal dengan sebutan variabel atau fitur atribut terbagi menjadi beberapa tipe  antara lain nominal  binary  ordinal  dan numeric atribut nominal berupa kategori  misal jenis kelamin  status perkawinan  agama  dll atribut binary merupakan atribut nominal dengan hanya 2 nilai  yaitu 0 dan 1. atribut ordinal merupakan nilai yang merepresentasikan urutan  misalkan nilai mata kuliah",
          "document_id": 1049
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kenapa model non linear lebih rumit?",
              "id": 3102,
              "answers": [
                {
                  "answer_id": 1443,
                  "document_id": 1054,
                  "question_id": 3102,
                  "text": "model non linier lebih rumit daripada model linier untuk dikembangkan karena fungsi dibuat melalui serangkaian perkiraan  iterasi  itu mungkin berasal dari trial and error",
                  "answer_start": 0,
                  "answer_end": 171,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "model non linier lebih rumit daripada model linier untuk dikembangkan karena fungsi dibuat melalui serangkaian perkiraan  iterasi  itu mungkin berasal dari trial and error support vector machines  svm  merupakan algoritma yang banyak digunakan pada tugas klasifikasi support vector regression  svr  merupakan algoritma regresi yang didasarkan pada svm  dan bertujuan untuk memprediksi real values persamaan pada support vector regression sama seperti pada linear regression  yaitu y   wx b pada svr  garis lurus disebut dengan hyperplane",
          "document_id": 1054
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa persamaan dari svr?",
              "id": 3240,
              "answers": [
                {
                  "answer_id": 1598,
                  "document_id": 1062,
                  "question_id": 3240,
                  "text": "persamaan pada support vector regression sama seperti pada linear regression  yaitu y   wx b ",
                  "answer_start": 0,
                  "answer_end": 93,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "persamaan pada support vector regression sama seperti pada linear regression  yaitu y   wx b pada svr  garis lurus disebut dengan hyperplane data di pada kedua sisi hyperplane yang paling dekat dengan hyperplane disebut dengan support vectors data ini digunakan untuk memplot boundary line tujuan utama svr pada dasarnya adalah mempertimbangkan titik titik data yang berada di dalam decision boundary",
          "document_id": 1062
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja kelebihan support vector regression ",
              "id": 2887,
              "answers": [
                {
                  "answer_id": 1267,
                  "document_id": 1067,
                  "question_id": 2887,
                  "text": "kelebihan support vector regression adalah robust pada outliers  generalisasi sangat baik dan akurasi prediksi tinggi ",
                  "answer_start": 300,
                  "answer_end": 418,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa saja kelemahan support vector regression ",
              "id": 2888,
              "answers": [
                {
                  "answer_id": 1268,
                  "document_id": 1067,
                  "question_id": 2888,
                  "text": " kelemahannya adalah tidak cocok untuk dataset besar dan peforma buruk ketika dataset memiliki banyak noise ",
                  "answer_start": 427,
                  "answer_end": 535,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "konsep dari slack variable yaitu untuk setiap nilai yang berada di luar Ïµ  dapat dinyatakan deviasinya dari margin sebagai Î¾ deviasi berusaha untuk diminimalkan  sehingga dapat ditambahkan pada objective function  minimize   yaitu min Â½   w   2   c _ i 1  n   Î¾i    dengan batasan  yi   wixi   É  Î¾i kelebihan support vector regression adalah robust pada outliers  generalisasi sangat baik dan akurasi prediksi tinggi sementara kelemahannya adalah tidak cocok untuk dataset besar dan peforma buruk ketika dataset memiliki banyak noise decision tree merupakan algoritma supervised learning yang dapat digunakan baik untuk klasifikasi maupun regresi",
          "document_id": 1067
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dimaksud dengan metode bottom up dalam hierarchical clustering ",
              "id": 2894,
              "answers": [
                {
                  "answer_id": 1272,
                  "document_id": 1077,
                  "question_id": 2894,
                  "text": "agglomerative  bottom up",
                  "answer_start": 559,
                  "answer_end": 583,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa yang dimaksud dengan metode top down dalam hierarchical clustering ",
              "id": 2895,
              "answers": [
                {
                  "answer_id": 1273,
                  "document_id": 1077,
                  "question_id": 2895,
                  "text": "divisive  top down ",
                  "answer_start": 589,
                  "answer_end": 608,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "karena k adalah jumlah cluster  maka k adalah berupa bilangan integer positif berikut adalah algoritma k means clustering  1  pilih sejumlah k titik sebagai centroid awal  2  ulangi langkah langkah 3 dan 4 hingga centroid tidak berubah  3  bentuk sejumlah k cluster dengan mengelompokkan masing masing data point ke centroid terdekat  4  hitung ulang centroid masing masing kelompok  cluster hierarchical clustering adalah metode analisis kelompok yang berusaha untuk membangun sebuah hirarki kelompok data strategi pengelompokannya umumnya ada 2 jenis yaitu agglomerative  bottom up  dan divisive  top down agglomerative hierarchical cluster dilakukan dengan  1  menghitung matriks jarak antar data  2  ulangi langkah 3 dan 4 sehingga hanya satu kelompok yang tersisa  3  gabungkan dua kelompok terdekat berdasarkan parameter kedekatan yang ditentukan  4  perbarui matriks jarak antar data untuk merepresentasikan kedekatan di antara kelompok baru dan kelompok yang masih tersisa  5  selesai",
          "document_id": 1077
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu model regresi linear?",
              "id": 3213,
              "answers": [
                {
                  "answer_id": 1566,
                  "document_id": 1059,
                  "question_id": 3213,
                  "text": " regresi linier adalah model pembelajaran mesin yang diawasi dimana model menemukan hubungan linier antara variabel bebas dan variabel tak bebas",
                  "answer_start": 0,
                  "answer_end": 144,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " regresi linier adalah model pembelajaran mesin yang diawasi dimana model menemukan hubungan linier antara variabel bebas dan variabel tak bebas variabel tak bebas  y  adalah variabel yang ingin kita prediksi atau jelaskan  sementara variabel bebas  x  adalah variabel yang digunakan untuk menjelaskan variabel tak bebas regresi linier terdiri dari dua jenis yaitu regresi linier sederhana yang hanya memiliki satu variabel bebas dengan persamaan y   a   bx dan regresi variabel jamak yang memiliki lebih dari satu variabel bebas dengan persamaan y   b0   b1x1  b2x2 b3x3. bnxn parameter koefisien  b  dan konstanta  bo  pada regresi linier variabel jamak dapat di estimasi menggunakan dua cara yaitu least squares dengan menggunakan operasi aljabar linier dan cara kedua yaitu algoritma optimasi dengan gradient descent",
          "document_id": 1059
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa rumus polynomial regression?",
              "id": 3253,
              "answers": [
                {
                  "answer_id": 1611,
                  "document_id": 1072,
                  "question_id": 3253,
                  "text": "rumus polynomial regression adalah y   b0 b1x b2x 2 b3x 3 bnx n ",
                  "answer_start": 128,
                  "answer_end": 192,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "maka dari itu perlu dibangun hubungan polinomial yang dapat menyesuaikan data points  model ini dinamakan polynomial regression rumus polynomial regression adalah y   b0 b1x b2x 2 b3x 3 bnx n Îµ regresi non linear adalah salah satu bentuk regresi analisis di mana data cocok dengan model dan kemudian dinyatakan sebagai fungsi matematika regresi linier sederhana menghubungkan dua variabel  x dan y  dengan garis lurus  y   mx   b   sedangkan nonlinier regresi menghubungkan kedua variabel secara nonlinier hubungan  melengkung",
          "document_id": 1072
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kapan proses pembelajaran cnn akan berakhir ",
              "id": 2880,
              "answers": [
                {
                  "answer_id": 1257,
                  "document_id": 1047,
                  "question_id": 2880,
                  "text": "hingga kondisi berhenti terpenuhi",
                  "answer_start": 1030,
                  "answer_end": 1063,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "setiap pooling layer umumnya memiliki 2 parameter  yaitu ukuran filter dan panjang stride  pergeseran terdapat 2 jenis operasi pooling yakni max pooling dan average pooling max pooling   mengambil nilai tertinggi dari nilai masukan yang ditempati oleh filter  sedangkan average pooling   mengambil nilai rata rata dari nilai masukan yang ditempati oleh filter sebagai contoh  operasi max pooling pada sebuah masukan berukuran 4x4 dengan ukuran filter 2x2 dan panjang stride 1 akan menghasilkan matriks berukuran 2x2.pembelajaran pada convulutional neural network adalah sebagai berikut  proses pembelajaran pada cnn umumnya diawali dengan inisialisasi nilai bobot bobot jaringan secara random  proses forward yaitu memasukkan data latih ke jaringan dan menghitung output  nya  lalu menghitung loss antara output jaringan dengan target output seharusnya yang telah diketahui pada data latih  proses backward untuk memperbaiki nilai bobot bobot jaringan yang dapat meminimalkan nilai loss nya dan yang terakhir kembali ke langkah 2 hingga kondisi berhenti terpenuhi",
          "document_id": 1047
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu regresi non linear?",
              "id": 3101,
              "answers": [
                {
                  "answer_id": 1442,
                  "document_id": 1053,
                  "question_id": 3101,
                  "text": "regresi non linear adalah salah satu bentuk regresi analisis di mana data cocok dengan model dan kemudian dinyatakan sebagai fungsi matematika ",
                  "answer_start": 0,
                  "answer_end": 143,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "regresi non linear adalah salah satu bentuk regresi analisis di mana data cocok dengan model dan kemudian dinyatakan sebagai fungsi matematika regresi linier sederhana menghubungkan dua variabel  x dan y  dengan garis lurus  y   mx   b   sedangkan nonlinier regresi menghubungkan kedua variabel secara nonlinier hubungan  melengkung pemodelan regresi nonlinier mirip dengan pemodelan regresi linear di mana keduanya berusaha untuk melacak respon tertentu dari sekumpulan variabel secara grafis model non linier lebih rumit daripada model linier untuk dikembangkan karena fungsi dibuat melalui serangkaian perkiraan  iterasi  itu mungkin berasal dari trial and error support vector machines  svm  merupakan algoritma yang banyak digunakan pada tugas klasifikasi",
          "document_id": 1053
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja yang termasuk metrik evaluasi regresi ",
              "id": 2885,
              "answers": [
                {
                  "answer_id": 1262,
                  "document_id": 1057,
                  "question_id": 2885,
                  "text": "metrik evaluasi regresi diantaranya pertama adalah mean absolute error  mae ",
                  "answer_start": 0,
                  "answer_end": 76,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "metrik evaluasi regresi diantaranya pertama adalah mean absolute error  mae  adalah rata rata perbedaan absolut antara nilai aktual dalam kumpulan data dan nilai yang diprediksi semakin kecil mae  semakin akurat modelnya jika mae nol  itu menunjukkan modelnya sempurna jika mae besar maka modelnya tidak bagus yang kedua  relative absolute error  rae  dinyatakan sebagai rasio  membandingkan mean error  residual  dengan kesalahan yang dihasilkan oleh sebuah trivial atau naive model",
          "document_id": 1057
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "prediksi akhir adalah apa?",
              "id": 3214,
              "answers": [
                {
                  "answer_id": 1567,
                  "document_id": 1064,
                  "question_id": 3214,
                  "text": "prediksi akhir adalah rata rata dari nilai variabel dependen dalam leaf node tertentu melalui beberapa iterasi  ",
                  "answer_start": 0,
                  "answer_end": 112,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "prediksi akhir adalah rata rata dari nilai variabel dependen dalam leaf node tertentu melalui beberapa iterasi  pohon mampu memprediksi nilai yang tepat untuk titik data kelebihan decision tree regression adalah mudah dipahami dan diinterpretasikan  dapat bekerja pada fitur numerical maupun fitur categorical  dan tidka memerlukan banyak pemrosesan data  seperti one hot encoding  dummy variables  etc sementara kelemahananya adalah cenderung overfit dan perubahan kecil pada data cenderung menyebabkan perbedaan besar pada struktur decision tree  sehingga menyebabkan ketidakstabilan random forest merupakan algoritma berbasis  tree  yang menggunakan fitur kualitas dari beberapa decision tree untuk membuat keputusan",
          "document_id": 1064
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang terjadi jika nilai rmse semakin kecil?",
              "id": 3244,
              "answers": [
                {
                  "answer_id": 1602,
                  "document_id": 1068,
                  "question_id": 3244,
                  "text": "semakin kecil nilai root mean squared error  semakin akurat modelnya",
                  "answer_start": 209,
                  "answer_end": 277,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "yang kelima  root mean squared error  rmse  adalah perbedaan rata rata akar kuadrat antara nilai sebenarnya dan nilai prediksi dengan mengambil sebuah kuadrat dari mse  kita mendapatkan root mean square error semakin kecil nilai root mean squared error  semakin akurat modelnya yang keenam  mean absolute percentage error  mape  mengukur akurasi sebagai persentase  dan dapat dihitung sebagai kesalahan persentase absolut rata rata untuk setiap periode waktu dikurangi nilai aktual dibagi dengan nilai aktual yang ketujuh  mean percentage error  mpe  adalah persentase kesalahan rata rata yang dihitung dengan perkiraan sebuah model berbeda dari nilai aktual kuantitas yang diramalkan",
          "document_id": 1068
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana dbscan mengelompokkan titik?",
              "id": 3256,
              "answers": [
                {
                  "answer_id": 1614,
                  "document_id": 1079,
                  "question_id": 3256,
                  "text": " ide utama dbscan adalah bahwa suatu titik adalah milik suatu cluster jika terletak dekat dengan banyak titik dari cluster tersebut",
                  "answer_start": 128,
                  "answer_end": 259,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "algoritma ini mampu menemukan cluster dengan sembarang bentuk  tidak harus bentuk sphere  dan mampu menghandle noise dengan baik ide utama dbscan adalah bahwa suatu titik adalah milik suatu cluster jika terletak dekat dengan banyak titik dari cluster tersebut terdapat dua parameter utama dalam dbscan  yaitu parameter eps dan parameter minpts parameter eps adalah jarak yang menentukan ketetanggaan  neighborhood dua titik dianggap sebagai tetangga jika jarak di antara mereka kurang dari atau sama dengan eps",
          "document_id": 1079
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja yang dijelaskan dalam beberapa fase dari sdlc ",
              "id": 2929,
              "answers": [
                {
                  "answer_id": 1287,
                  "document_id": 1091,
                  "question_id": 2929,
                  "text": "sdlc menjelaskan tentang mengembangkan perangkat lunak yang digerakkan untuk solusi masalah bisnis ",
                  "answer_start": 0,
                  "answer_end": 99,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sdlc menjelaskan tentang mengembangkan perangkat lunak yang digerakkan untuk solusi masalah bisnis sdlc disebut juga siklus hidup pengembangan solusi bisnis sdlc terdiri dari beberapa fase yang menjelaskan cara mengembangkan  memelihara  mengganti  dan meningkatkan perangkat lunak fase fase sdlc yaitu planning  analysis  design  build  test  dan deployment planning phase analisis kebutuhannya adalah fase yang paling penting dan mendasar dalam sdlc",
          "document_id": 1091
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja yang merupakan solusi berbasis perangkat lunak?",
              "id": 3273,
              "answers": [
                {
                  "answer_id": 1632,
                  "document_id": 1114,
                  "question_id": 3273,
                  "text": "solusi berbasis perangkat lunak terdiri dari dua bagian yaitu model dan sistem ",
                  "answer_start": 137,
                  "answer_end": 216,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "model spiral melewati fase perencanaan  desain  pembangunan dan pengujian berulang ulang  dengan perbaikan bertahap pada setiap lintasan solusi berbasis perangkat lunak terdiri dari dua bagian yaitu model dan sistem model memiliki terdiri dari prototipe dan diagram dan dokumen pendukung sistem terdiri dari perangkat keras dan perangkat lunak arsitektur data kecil dan data besar yang khas untuk sains data adalah suatu struktur atau rancangan yang digunakan untuk mengatur dan mengelola data dalam proyek sains data",
          "document_id": 1114
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa operator boolean yang digunakan untuk menggambarkan sesuatu yang lebih kecil sama dengan ",
              "id": 2952,
              "answers": [
                {
                  "answer_id": 1312,
                  "document_id": 1125,
                  "question_id": 2952,
                  "text": "setiap operator boolean dapat digunakan untuk subset data    untuk lebih besar    lebih kecil     sama dengan     lebih besar sama dengan     lebih kecil sama dengan     tidak sama dengan",
                  "answer_start": 0,
                  "answer_end": 187,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa pustaka yang dibangun di atas numpy  scipy  dan matplotlib ",
              "id": 2945,
              "answers": [
                {
                  "answer_id": 1311,
                  "document_id": 1125,
                  "question_id": 2945,
                  "text": "pustaka scikit learn",
                  "answer_start": 349,
                  "answer_end": 369,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "setiap operator boolean dapat digunakan untuk subset data    untuk lebih besar    lebih kecil     sama dengan     lebih besar sama dengan     lebih kecil sama dengan     tidak sama dengan kemudian untuk pustaka pada scikit learn menyediakan algoritma pembelajaran mesin seperti klasifikasi  regresi  pengelompokan  validasi model  dan lainnya serta pustaka scikit learn ini dibangun di atas numpy  scipy  dan matplotlib selanjutnya untuk pustaka python pada seaborn berdasarkan matplotlib  menyediakan antarmuka tingkat tinggi untuk menggambar grafik statistik yang menarik  serta mirip  dalam gaya  dengan perpustakaan ggplot2 yang populer dalam bahasa r",
          "document_id": 1125
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa nama method yang digunakan untuk menghapus kolom yang hanya berisi single value ",
              "id": 3026,
              "answers": [
                {
                  "answer_id": 1314,
                  "document_id": 1130,
                  "question_id": 3026,
                  "text": "df nunique",
                  "answer_start": 230,
                  "answer_end": 240,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "drop   dari library pandas untuk menghapus kolom yang berisi nilai unik pada setiap barisnya atau kolom dengan banyak missing data mengidentifikasi dan hapus kolom yang hanya berisi single value  zero variance  menggunakan method df nunique jika nilai unik pada sebuah kolom   1  kolom tersebut tidak berguna untuk proses modelling mengidentifikasi dan hapus kolom dengan low variance  yaitu kolom yang memiliki sedikit nilai unik dan variance mendekati nol  terutama pada atribut numerik",
          "document_id": 1130
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa resiko dari model big bang?",
              "id": 3249,
              "answers": [
                {
                  "answer_id": 1607,
                  "document_id": 1100,
                  "question_id": 3249,
                  "text": "model big bang berisiko tinggi membuang sebagian besar sumber dayanya dalam pengembangan dan bekerja paling baik untuk proyek proyek kecil ini tidak memiliki tahap definisi persyaratan menyeluruh dari metode lain ",
                  "answer_start": 181,
                  "answer_end": 394,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "model berbentuk v merupakan perpanjangan model air terjun  metodologi sdlc ini menguji pada setiap tahap pengembangan seperti halnya air terjun  proses ini dapat mengalami hambatan model big bang berisiko tinggi membuang sebagian besar sumber dayanya dalam pengembangan dan bekerja paling baik untuk proyek proyek kecil ini tidak memiliki tahap definisi persyaratan menyeluruh dari metode lain model spiral yang paling fleksibel dari model sdlc",
          "document_id": 1100
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana jika cluster tidak begitu kohesif?",
              "id": 3260,
              "answers": [
                {
                  "answer_id": 1619,
                  "document_id": 1087,
                  "question_id": 3260,
                  "text": "jika sebuah cluster tidak begitu kohesif  maka cluster tersebut dapat dibagi menjadi beberapa cluster",
                  "answer_start": 169,
                  "answer_end": 270,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "separasi dinyatakan dalam ukuran between cluster sum of square  ssb cluster yang baik akan mempunyai nilai sse  kohesi  yang rendah dan nilai bss  separasi  yang tinggi jika sebuah cluster tidak begitu kohesif  maka cluster tersebut dapat dibagi menjadi beberapa cluster jika dua cluster telah kohesif tetapi nilai separasinya tinggi  maka cluster tersebut dapat digabungkan menjadi satu cluster",
          "document_id": 1087
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "mengapa togaf populer?",
              "id": 3266,
              "answers": [
                {
                  "answer_id": 1625,
                  "document_id": 1105,
                  "question_id": 3266,
                  "text": "framework ini populer karena beberapa alasan pertama  togaf merupakan standard terbuka yang tidak tergantung pada vendor ataupun teknologi yang digunakan selain itu  togaf mendukung keselarasan antara it dan bisnis  berdasarkan praktik praktik terbaik  dan dapat disesuaikan sesuai kebutuhan organisasi yang menerapkannya",
                  "answer_start": 0,
                  "answer_end": 321,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "framework ini populer karena beberapa alasan pertama  togaf merupakan standard terbuka yang tidak tergantung pada vendor ataupun teknologi yang digunakan selain itu  togaf mendukung keselarasan antara it dan bisnis  berdasarkan praktik praktik terbaik  dan dapat disesuaikan sesuai kebutuhan organisasi yang menerapkannya togaf 9 memiliki beberapa komponen utama yang membentuk kerangka kerja  yaitu architecture development method  adm   adm guidelines and techniques  architecture content framework  togaf reference models  the enterprise continuum  dan the architecture capability framework dengan menggunakan komponen komponen ini dapat mengembangkan arsitektur yang sesuai dengan kebutuhan bisnis mereka dan mencapai keselarasan antara it dan bisnis",
          "document_id": 1105
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana siklus pada model agile?",
              "id": 3270,
              "answers": [
                {
                  "answer_id": 1629,
                  "document_id": 1110,
                  "question_id": 3270,
                  "text": " model agile sdlc memisahkan produk menjadi siklus dan memberikan produk yang berfungsi dengan sangat cepat metodologi ini menghasilkan suksesi rilis pengujian setiap rilis feed kembali info yang dimasukkan ke dalam versi berikutnya",
                  "answer_start": 196,
                  "answer_end": 428,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "setiap fase memiliki mini plan sendiri dan setiap fase  air terjun  ke fase berikutnya kelemahan terbesar dari model ini adalah detail kecil yang tersisa tidak lengkap dapat menahan seluruh proses model agile sdlc memisahkan produk menjadi siklus dan memberikan produk yang berfungsi dengan sangat cepat metodologi ini menghasilkan suksesi rilis pengujian setiap rilis feed kembali info yang dimasukkan ke dalam versi berikutnya",
          "document_id": 1110
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa parameter yang harus dinilai pada dds?",
              "id": 3269,
              "answers": [
                {
                  "answer_id": 1628,
                  "document_id": 1108,
                  "question_id": 3269,
                  "text": "terdapat berbagai parameter yang harus dinilai seperti penilaian risiko  ketahanan produk  modularitas desain  anggaran dan batasan waktu ",
                  "answer_start": 274,
                  "answer_end": 412,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "desain proyek dipilih berdasarkan persyaratan yang ditentukan dalam srs  biasanya lebih dari satu pendekatan desain untuk arsitektur produk diusulkan dan didokumentasikan dalam dds   spesifikasi dokumen desain dds ini ditinjau oleh semua pemangku kepentingan penting karena terdapat berbagai parameter yang harus dinilai seperti penilaian risiko  ketahanan produk  modularitas desain  anggaran dan batasan waktu  pendekatan desain terbaik dipilih untuk produk pendekatan desain dengan jelas mendefinisikan semua modul arsitektur produk bersama dengan komunikasi dan representasi aliran data dengan modul pihak eksternal dan ketiga  jika ada desain internal dari semua modul arsitektur yang diusulkan harus didefinisikan dengan jelas dengan notulen detail dalam dds berdasarkan dds  dokumen desain internal   dokumen desain tingkat tinggi  hld  dan detail desain  ddd  dapat dibuat",
          "document_id": 1108
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa arsitektur data dalam sains data?",
              "id": 3251,
              "answers": [
                {
                  "answer_id": 1609,
                  "document_id": 1102,
                  "question_id": 3251,
                  "text": "arsitektur data kecil dan data besar yang khas untuk sains data adalah suatu struktur atau rancangan yang digunakan untuk mengatur dan mengelola data dalam proyek sains data",
                  "answer_start": 56,
                  "answer_end": 229,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sistem terdiri dari perangkat keras dan perangkat lunak arsitektur data kecil dan data besar yang khas untuk sains data adalah suatu struktur atau rancangan yang digunakan untuk mengatur dan mengelola data dalam proyek sains data arsitektur data kecil biasanya digunakan untuk proyek proyek dengan volume data yang relatif kecil  sedangkan arsitektur data besar digunakan untuk proyek proyek dengan volume data yang sangat besar arsitektur data dirancang untuk memastikan data dapat diakses  disimpan  dan dianalisis dengan efisien dan efektif proses tradisional untuk membangun model prediktif dan mencetak data melibatkan beberapa langkah",
          "document_id": 1102
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa input dari test phase ",
              "id": 2939,
              "answers": [
                {
                  "answer_id": 1293,
                  "document_id": 1097,
                  "question_id": 2939,
                  "text": "program   perangkat lunak yang belum diuji",
                  "answer_start": 344,
                  "answer_end": 386,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa tujuan menggunakan alat pemograman ",
              "id": 2937,
              "answers": [
                {
                  "answer_id": 1294,
                  "document_id": 1097,
                  "question_id": 2937,
                  "text": "untuk menghasilkan kode ",
                  "answer_start": 266,
                  "answer_end": 290,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "jika desain dilakukan secara rinci dan terorganisir  pembuatan kode dapat dicapai tanpa banyak kerumitan pengembang harus mengikuti pedoman pengkodean yang ditentukan oleh organisasi mereka dan alat pemrograman seperti kompiler  interpreter  debugger  dll digunakan untuk menghasilkan kode outputnya berupa program software test phase inputnya program   perangkat lunak yang belum diuji  uji dokumen rencana fase ini mengacu pada tahap pengujian hanya produk di mana cacat produk dilaporkan  dilacak  diperbaiki dan diuji ulang  sampai produk mencapai standar kualitas yang ditentukan dalam srs outputnya berupa program  perangkat lunak yang diuji",
          "document_id": 1097
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa pustaka yang menyediakan alat untuk manipulasi data seperti menyortir dan agregasi ",
              "id": 2949,
              "answers": [
                {
                  "answer_id": 1310,
                  "document_id": 1122,
                  "question_id": 2949,
                  "text": "pustaka panda",
                  "answer_start": 219,
                  "answer_end": 232,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "untuk melihat fungsi pustaka scipy dengan import scipy dan help scipy scipy memiliki jenis scipy linear algebra   scipy linalg  scipy curve fitting   scipy curve_fit  dan scipy integral   scipy integrate kemudian untuk pustaka panda dapat menambahkan struktur dan alat data yang dirancang untuk bekerja dengan data seperti tabel  mirip dengan series dan data frame dalam r   menyediakan alat untuk manipulasi data seperti membentuk kembali  menggabungkan  menyortir  mengiris  agregasi  dan lainnya  pandas juga memungkinkan penanganan data yang hilang dalam pandas juga dapat membaca data dan mendeskripsikan data untuk membaca data dengan pandas terdapat sejumlah perintah panda untuk membaca format data lainnya seperti pd",
          "document_id": 1122
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa fase yang paling penting dalam sdlc?",
              "id": 3262,
              "answers": [
                {
                  "answer_id": 1621,
                  "document_id": 1092,
                  "question_id": 3262,
                  "text": "planning phase analisis kebutuhannya adalah fase yang paling penting dan mendasar dalam sdlc ",
                  "answer_start": 77,
                  "answer_end": 170,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "fase fase sdlc yaitu planning  analysis  design  build  test  dan deployment planning phase analisis kebutuhannya adalah fase yang paling penting dan mendasar dalam sdlc ini dilakukan oleh anggota senior tim dengan masukan dari pelanggan  departemen penjualan  survei pasar dan ahli domain di industri informasi ini kemudian digunakan untuk merencanakan pendekatan proyek dasar dan untuk melakukan studi kelayakan produk di bidang ekonomi  operasional dan teknis perencanaan untuk persyaratan jaminan kualitas dan identifikasi risiko yang terkait dengan proyek juga dilakukan dalam tahap perencanaan",
          "document_id": 1092
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang menyebabkan sebuah titik adalah outlier?",
              "id": 3259,
              "answers": [
                {
                  "answer_id": 1618,
                  "document_id": 1086,
                  "question_id": 3259,
                  "text": "sebuah titik adalah outlier jika titik tersebut bukan titik inti dan tidak dapat dijangkau dari titik manapun ",
                  "answer_start": 0,
                  "answer_end": 110,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sebuah titik adalah outlier jika titik tersebut bukan titik inti dan tidak dapat dijangkau dari titik manapun evaluasi pada clustering dibutuhkan untuk beberapa alasan seperti interpretasi hasil clustering  menilai validitas cluster yang dihasilkan  serta membandingkan hasil clustering  baik dengan algoritma yang sama ataupun dengan algoritma yang berbeda interpretasi hasil clustering dibutuhkan jika semisal cluster memiliki nilai evaluasi sejumlah 10  apakah cluster yang dihasilkan sudah bagus atau belum cluster yang dihasilkan dinilai valid atau tidak yaitu untuk melihat apakah benar benar ada struktur dalam data yang telah dikelompokkan hasil clustering dibandingkan  baik dengan algoritma yang sama ataupun dengan algoritma yang berbeda  untuk membandingkan dua atau lebih analisa clustering",
          "document_id": 1086
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu model iteratif?",
              "id": 3271,
              "answers": [
                {
                  "answer_id": 1630,
                  "document_id": 1112,
                  "question_id": 3271,
                  "text": "model iteratif menekankan pengulangan pengembang membuat versi dengan sangat cepat dan dengan biaya yang relatif sedikit  kemudian menguji dan memperbaikinya melalui versi cepat dan berturut turut ",
                  "answer_start": 0,
                  "answer_end": 197,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "model iteratif menekankan pengulangan pengembang membuat versi dengan sangat cepat dan dengan biaya yang relatif sedikit  kemudian menguji dan memperbaikinya melalui versi cepat dan berturut turut satu kelemahan besar di sini adalah bahwa hal itu dapat memakan sumber daya dengan cepat jika dibiarkan model berbentuk v merupakan perpanjangan model air terjun  metodologi sdlc ini menguji pada setiap tahap pengembangan seperti halnya air terjun  proses ini dapat mengalami hambatan",
          "document_id": 1112
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa model sdlc yang paling tertua?",
              "id": 3250,
              "answers": [
                {
                  "answer_id": 1608,
                  "document_id": 1101,
                  "question_id": 3250,
                  "text": "model waterfall adalah model tertua dan paling mudah ",
                  "answer_start": 179,
                  "answer_end": 232,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "dalam \nsdlc terdapat 9 model yang dapat digunakan  seperti model waterfall  agile  iterative  v shaped  big bang  spiral  rad  rapid application development dan model prototyping model waterfall adalah model tertua dan paling mudah dengan ini  kita menyelesaikan satu fase dan kemudian memulai yang berikutnya setiap fase memiliki mini plan sendiri dan setiap fase  air terjun  ke fase berikutnya kelemahan terbesar dari model ini adalah detail kecil yang tersisa tidak lengkap dapat menahan seluruh proses",
          "document_id": 1101
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu fungsi range dalam python ",
              "id": 2946,
              "answers": [
                {
                  "answer_id": 1303,
                  "document_id": 1116,
                  "question_id": 2946,
                  "text": " fungsi range adalah objek yang dapat dilinyalir  tetapi tidak identik di mana fungsi range tidak menghasilkan semua nilai sekaligus  tetapi menghasilkan nilai secara berurutan ketika diperlukan ",
                  "answer_start": 14,
                  "answer_end": 209,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa yang dihasilkan dan tidak dihasilkan dari fungsi range ",
              "id": 2950,
              "answers": [
                {
                  "answer_id": 1304,
                  "document_id": 1116,
                  "question_id": 2950,
                  "text": " fungsi range tidak menghasilkan semua nilai sekaligus  tetapi menghasilkan nilai secara berurutan",
                  "answer_start": 92,
                  "answer_end": 190,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "kemudian untuk fungsi range adalah objek yang dapat dilinyalir  tetapi tidak identik di mana fungsi range tidak menghasilkan semua nilai sekaligus  tetapi menghasilkan nilai secara berurutan ketika diperlukan sehingga disebut lazy iterator terdapat pula files input yang terdiri dari inflobj   open  data    r   untuk membuka file  data  untuk input  kemudian s   inflobj read   untuk membaca keseluruhan file pada satu string  lalu s   inflobj read n  untuk membaca n bytes  n    1   kemudian l   inflobj readline   untuk membaca satu line  dan l   inflobj",
          "document_id": 1116
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apakah mendefinisikan bagaimana kita mengukur  keberhasilan  dan bagaimana cara mengukurnya merupakan hal yang penting dalam business understanding ",
              "id": 2966,
              "answers": [
                {
                  "answer_id": 1316,
                  "document_id": 1131,
                  "question_id": 2966,
                  "text": "penting juga untuk mendefinisikan bagaimana kita mengukur  keberhasilan  dan bagaimana cara mengukurnya ",
                  "answer_start": 180,
                  "answer_end": 284,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apakah masalah dan solusi termasuk dalam tahapan desain alur sistem ",
              "id": 2970,
              "answers": [
                {
                  "answer_id": 1317,
                  "document_id": 1131,
                  "question_id": 2970,
                  "text": "tahapan business understanding dalam ai meliputi business case  desain alur sistem  komponen  masalah  dan solusi",
                  "answer_start": 284,
                  "answer_end": 397,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "tiga hal utama dalam business understanding adalah menentukan masalah yang akan diselesaikan  menentukan tujuan proyek  dan melihat solusi yang memungkinkan dari perspektif bisnis penting juga untuk mendefinisikan bagaimana kita mengukur  keberhasilan  dan bagaimana cara mengukurnya tahapan business understanding dalam ai meliputi business case  desain alur sistem  komponen  masalah  dan solusi business case   kasus kendaraan otonom dengan tujuan untuk menyediakan kendaraan tanpa pengemudi yang aman  ekonomis  dan praktis desain alur sistem  meliputi sistem sensor  machine learning  dan output  aktuator",
          "document_id": 1131
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana peran metodologi crisp dm dalam proyek data mining ",
              "id": 2933,
              "answers": [
                {
                  "answer_id": 1286,
                  "document_id": 1090,
                  "question_id": 2933,
                  "text": "dirancang untuk menjadi independen dari perangkat lunak  vendor  atau teknik analisis data",
                  "answer_start": 571,
                  "answer_end": 661,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " metodologi dasar sains data adalah langkah langkah yang digunakan dalam proyek data science agar dapat menghasilkan hasil yang optimal dapat menjawab pertanyaan dari suatu masalah yang ingin diselesaikan metodologi ini tidak tergantung pada teknologi atau tools tertentu dalam sains data  terdapat dua metodologi dasar yang sering digunakan  yaitu cross industry standard process for data mining  crisp dm  dan software development life cycle  sdlc crisp dm secara teratur berada di tempat nomor satu dalam berbagai survei industri keuntungan utama dari crisp dm adalah dirancang untuk menjadi independen dari perangkat lunak  vendor  atau teknik analisis data",
          "document_id": 1090
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa input dari deployment phase?",
              "id": 3267,
              "answers": [
                {
                  "answer_id": 1626,
                  "document_id": 1106,
                  "question_id": 3267,
                  "text": "deployment phase inputnya berupa program   perangkat lunak yang diuji  rencana migrasi setelah produk diuji dan siap untuk digunakan",
                  "answer_start": 240,
                  "answer_end": 372,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "fase ini mengacu pada tahap pengujian hanya produk di mana cacat produk dilaporkan  dilacak  diperbaiki dan diuji ulang  sampai produk mencapai standar kualitas yang ditentukan dalam srs outputnya berupa program  perangkat lunak yang diuji deployment phase inputnya berupa program   perangkat lunak yang diuji  rencana migrasi setelah produk diuji dan siap untuk digunakan  produk ini dirilis secara resmi di pasar yang sesuai terkadang penyebaran produk terjadi secara bertahap sesuai strategi bisnis organisasi itu",
          "document_id": 1106
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana penggunaan operator boolean dalam subset data ",
              "id": 2947,
              "answers": [
                {
                  "answer_id": 1641,
                  "document_id": 1127,
                  "question_id": 2947,
                  "text": "untuk subset data dapat menerapkan pengindeksan boolean pengindeksan ini umumnya dikenal sebagai filter ",
                  "answer_start": 38,
                  "answer_end": 142,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "mean lalu untuk data frame filtering  untuk subset data dapat menerapkan pengindeksan boolean pengindeksan ini umumnya dikenal sebagai filter  contohnya jika ingin subset baris di mana nilai gaji lebih besar dari  120k maka dengan df_sub   df df  salary     120000   sebagai contoh dalam menghitung gaji rata rata untuk setiap peringkat profesor setiap operator boolean dapat digunakan untuk subset data    untuk lebih besar    lebih kecil     sama dengan     lebih besar sama dengan     lebih kecil sama dengan     tidak sama dengan kemudian untuk pustaka pada scikit learn menyediakan algoritma pembelajaran mesin seperti klasifikasi  regresi  pengelompokan  validasi model  dan lainnya serta pustaka scikit learn ini dibangun di atas numpy  scipy  dan matplotlib",
          "document_id": 1127
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara membangun model prediktif?",
              "id": 3272,
              "answers": [
                {
                  "answer_id": 1631,
                  "document_id": 1113,
                  "question_id": 3272,
                  "text": "untuk membangun model prediktif dan mencetak data melibatkan beberapa langkah pertama  data harus diekstraksi dari sumber yang relevan kemudian  data tersebut harus diintegrasikan dan dipersiapkan agar siap digunakan setelah itu  model model dibangun berdasarkan data yang telah dipersiapkan",
                  "answer_start": 134,
                  "answer_end": 425,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "arsitektur data dirancang untuk memastikan data dapat diakses  disimpan  dan dianalisis dengan efisien dan efektif proses tradisional untuk membangun model prediktif dan mencetak data melibatkan beberapa langkah pertama  data harus diekstraksi dari sumber yang relevan kemudian  data tersebut harus diintegrasikan dan dipersiapkan agar siap digunakan setelah itu  model model dibangun berdasarkan data yang telah dipersiapkan",
          "document_id": 1113
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa output dari design phase?",
              "id": 3247,
              "answers": [
                {
                  "answer_id": 1605,
                  "document_id": 1094,
                  "question_id": 3247,
                  "text": "output dari design phase berupa hld dan   atau ddd  ",
                  "answer_start": 240,
                  "answer_end": 292,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "desain internal dari semua modul arsitektur yang diusulkan harus didefinisikan dengan jelas dengan notulen detail dalam dds berdasarkan dds  dokumen desain internal   dokumen desain tingkat tinggi  hld  dan detail desain  ddd  dapat dibuat output dari design phase berupa hld dan   atau ddd  kadang kadang  ddd dapat dikembangkan oleh pengembang build phase inputnya ddd  dokumen desain detail pada design phase pengembangan aktual dimulai dan produk dibangun",
          "document_id": 1094
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa model yang paling fleksibel dari model sdlc?",
              "id": 3248,
              "answers": [
                {
                  "answer_id": 1606,
                  "document_id": 1099,
                  "question_id": 3248,
                  "text": "model spiral yang paling fleksibel dari model sdlc",
                  "answer_start": 74,
                  "answer_end": 124,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "ini tidak memiliki tahap definisi persyaratan menyeluruh dari metode lain model spiral yang paling fleksibel dari model sdlc model spiral mirip dengan model berulang dalam penekanannya pada pengulangan model spiral melewati fase perencanaan  desain  pembangunan dan pengujian berulang ulang  dengan perbaikan bertahap pada setiap lintasan solusi berbasis perangkat lunak terdiri dari dua bagian yaitu model dan sistem",
          "document_id": 1099
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa input dari analysis phase?",
              "id": 3268,
              "answers": [
                {
                  "answer_id": 1627,
                  "document_id": 1107,
                  "question_id": 3268,
                  "text": "analysis phase inputnya studi kelayakan teknis dan pendanaan ",
                  "answer_start": 51,
                  "answer_end": 112,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "outputnya studi kelayakan teknis   inisiasi proyek analysis phase inputnya studi kelayakan teknis dan pendanaan analisis proyek dilakukan setelah analisis persyaratan dilakukan  tahap selanjutnya adalah mendefinisikan dan mendokumentasikan persyaratan produk dengan jelas dan membuatnya disetujui dari pelanggan atau analis pasar hal ini dilakukan melalui dokumen srs  software requirement specification  yang terdiri dari semua persyaratan produk yang akan dirancang dan dikembangkan selama siklus hidup proyek output berupa srs  spesifikasi persyaratan perangkat lunak",
          "document_id": 1107
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja yang dilakukan pada tahap mendefinisikan tujuan mengolah data",
              "id": 3283,
              "answers": [
                {
                  "answer_id": 1644,
                  "document_id": 1135,
                  "question_id": 3283,
                  "text": "mendeskripsikan tipe masalah seperti klustering  prediksi atau klasifikasi \n menentukan hasil dari pengolahan data seperti model  laporan  presentasi  dan dataset yang terproses\n menentukan kriteria keberhasilan pengolahan data",
                  "answer_start": 113,
                  "answer_end": 340,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "mengestimasi cost dan menghitung keuntungan atau manfaat yang didapatkan\n3. mendefinisikan tujuan mengolah data\n mendeskripsikan tipe masalah seperti klustering  prediksi atau klasifikasi \n menentukan hasil dari pengolahan data seperti model  laporan  presentasi  dan dataset yang terproses\n menentukan kriteria keberhasilan pengolahan data\n4. merencanakan project\ntuliskan langkah demi langkah rencana kegiatan untuk project yang akan dikerjakan tambahkan tiap langkah tersebut   sumber daya yang dibutuhkan  input  output  ketergantungan langkah sebelumnya  perjelas langkah yang diulang kemudian menentukan alur proses penyelesaian sub sub problem  dan solusi  serta tools dan teknik yang dibutuhkan analytic approach dilakukan setelah masalah bisnis telah dinyatakan dengan jelas mencakup penyelesaian masalah dengan teknik statistik dan pembelajaran mesin",
          "document_id": 1135
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "dimanakah togaf banyak digunakan ",
              "id": 2943,
              "answers": [
                {
                  "answer_id": 1295,
                  "document_id": 1098,
                  "question_id": 2943,
                  "text": " untuk pembuatan arsitektur enterprise ",
                  "answer_start": 147,
                  "answer_end": 186,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa sebutan lain dengan togaf ",
              "id": 2944,
              "answers": [
                {
                  "answer_id": 1296,
                  "document_id": 1098,
                  "question_id": 2944,
                  "text": "hadoop ",
                  "answer_start": 89,
                  "answer_end": 96,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "pengguna dan aplikasi dapat dengan mudah mengakses data dari database data warehouse dan hadoop togaf adalah sebuah framework yang banyak digunakan untuk pembuatan arsitektur enterprise togaf juga merupakan metode umum yang komprehensif framework ini populer karena beberapa alasan pertama  togaf merupakan standard terbuka yang tidak tergantung pada vendor ataupun teknologi yang digunakan",
          "document_id": 1098
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa hasil yang harus disesuaikan dengan ddd ",
              "id": 2936,
              "answers": [
                {
                  "answer_id": 1300,
                  "document_id": 1109,
                  "question_id": 2936,
                  "text": "kode pemrograman",
                  "answer_start": 114,
                  "answer_end": 130,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "build phase inputnya ddd  dokumen desain detail pada design phase pengembangan aktual dimulai dan produk dibangun kode pemrograman dihasilkan sesuai ddd  detail design document  selama fase ini jika desain dilakukan secara rinci dan terorganisir  pembuatan kode dapat dicapai tanpa banyak kerumitan pengembang harus mengikuti pedoman pengkodean yang ditentukan oleh organisasi mereka dan alat pemrograman seperti kompiler  interpreter  debugger  dll digunakan untuk menghasilkan kode",
          "document_id": 1109
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "software requirement specification terdiri atas apa saja?",
              "id": 3246,
              "answers": [
                {
                  "answer_id": 1604,
                  "document_id": 1093,
                  "question_id": 3246,
                  "text": " software requirement specification  yang terdiri dari semua persyaratan produk yang akan dirancang dan dikembangkan selama siklus hidup proyek",
                  "answer_start": 38,
                  "answer_end": 181,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "hal ini dilakukan melalui dokumen srs  software requirement specification  yang terdiri dari semua persyaratan produk yang akan dirancang dan dikembangkan selama siklus hidup proyek output berupa srs  spesifikasi persyaratan perangkat lunak design phase inputnya srs  spesifikasi persyaratan perangkat lunak desain proyek dipilih berdasarkan persyaratan yang ditentukan dalam srs  biasanya lebih dari satu pendekatan desain untuk arsitektur produk diusulkan dan didokumentasikan dalam dds   spesifikasi dokumen desain dds ini ditinjau oleh semua pemangku kepentingan penting karena terdapat berbagai parameter yang harus dinilai seperti penilaian risiko  ketahanan produk  modularitas desain  anggaran dan batasan waktu  pendekatan desain terbaik dipilih untuk produk",
          "document_id": 1093
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu penyampelan kluster?",
              "id": 3208,
              "answers": [
                {
                  "answer_id": 1560,
                  "document_id": 1142,
                  "question_id": 3208,
                  "text": "penyampelan kluster adalah suatu prosedur penarikan sampel probabilitas yang memilih subpopulasi yang disebut kluster  ",
                  "answer_start": 0,
                  "answer_end": 119,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "penyampelan kluster adalah suatu prosedur penarikan sampel probabilitas yang memilih subpopulasi yang disebut kluster  biasanya sumber datanya sangat luas penyampelan sistematis adalah teknik pengambilan sampel berdasarkan urutan dari anggota populasi yang telah diberi nomor urut penyampelan daerah merupakan bagian dari penyampelan kluster yang secara khusus melibatkan suatu daerah sampel sementara itu  metode sampling non probabilitas adalah prosedur penarikan sampel yang bersifat subjektif setiap elemen penelitian tidak memiliki peluang yang sama untuk dipilih",
          "document_id": 1142
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang harus digunakan untuk  mengintegrasikan data secara otomatis?",
              "id": 3264,
              "answers": [
                {
                  "answer_id": 1623,
                  "document_id": 1103,
                  "question_id": 3264,
                  "text": "database  data warehouse  dan hadoop bekerja sama dalam mengintegrasikan data secara otomatis",
                  "answer_start": 0,
                  "answer_end": 93,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "database  data warehouse  dan hadoop bekerja sama dalam mengintegrasikan data secara otomatis data dari rdbms  relational database management system  dapat diunggah dan divirtualisasikan ke hadoop analisis data juga dapat diunggah dan hasilnya digabungkan pengguna dan aplikasi dapat dengan mudah mengakses data dari database data warehouse dan hadoop togaf adalah sebuah framework yang banyak digunakan untuk pembuatan arsitektur enterprise",
          "document_id": 1103
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa metode untuk membagi data menjadi beberapa grup?",
              "id": 3277,
              "answers": [
                {
                  "answer_id": 1636,
                  "document_id": 1120,
                  "question_id": 3277,
                  "text": " metode  group by  dapat membagi data menjadi grup berdasarkan beberapa kriteria  menghitung statistik  atau menerapkan fungsi  untuk setiap kelompok ",
                  "answer_start": 75,
                  "answer_end": 225,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "selanjutnya  dalam pandas memiliki data frame groupby method di mana dengan metode  group by  dapat membagi data menjadi grup berdasarkan beberapa kriteria  menghitung statistik  atau menerapkan fungsi  untuk setiap kelompok  dan mirip dengan fungsi dplyr   dalam r  nantinya setelah objek groupby dibuat barulah dapat menghitung berbagai statistik untuk setiap kelompok pada groupby ini terdapat catatan kinerjanya yaitu tidak ada pengelompokan atau pemisahan terjadi sampai diperlukan  membuat objek groupby hanya memverifikasi bahwa telah melewati pemetaan yang valid  secara default kunci grup diurutkan selama operasi groupby  dan untuk lulus sort   false untuk potensi speedup seperti dalam menghitung gaji rata rata untuk setiap peringkat profesor dengan df groupby   rank     sort false     salary mean lalu untuk data frame filtering  untuk subset data dapat menerapkan pengindeksan boolean",
          "document_id": 1120
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "setelah masalah bisnis dinyatakan jelas maka dilakukan apa?",
              "id": 3209,
              "answers": [
                {
                  "answer_id": 1561,
                  "document_id": 1138,
                  "question_id": 3209,
                  "text": "analytic approach dilakukan setelah masalah bisnis telah dinyatakan dengan jelas mencakup penyelesaian masalah dengan teknik statistik dan pembelajaran mesin",
                  "answer_start": 0,
                  "answer_end": 157,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "analytic approach dilakukan setelah masalah bisnis telah dinyatakan dengan jelas mencakup penyelesaian masalah dengan teknik statistik dan pembelajaran mesin setelah melakukan tahap analitik maka tahap selanjutnya adalah \n data collection   pengumpulan data dari satu sumber\n gathering data   pengumpulan data dari satu sumber",
          "document_id": 1138
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang digunakan  untuk me return sebuah list?",
              "id": 3280,
              "answers": [
                {
                  "answer_id": 1639,
                  "document_id": 1124,
                  "question_id": 3280,
                  "text": " l   inflobj readlines   untuk me return sebuah list dari baris string s",
                  "answer_start": 100,
                  "answer_end": 172,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "read n  untuk membaca n bytes  n    1   kemudian l   inflobj readline   untuk membaca satu line  dan l   inflobj readlines   untuk me return sebuah list dari baris string sedangkan untuk files output terdapat outflobj   open  data    w   untuk membuka file  data  untuk memodifikasi  outflobj write s  untuk memodifikasi string s pada file  outflobj",
          "document_id": 1124
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa perintah pada pandas untuk membaca format data lainnya?",
              "id": 3281,
              "answers": [
                {
                  "answer_id": 1642,
                  "document_id": 1128,
                  "question_id": 3281,
                  "text": "perintah panda untuk membaca format data lainnya seperti pd read_excel  myfile xlsx   sheet_name  sheet1   index_col none na_values   na     pd read_stata  myfile",
                  "answer_start": 113,
                  "answer_end": 275,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "dalam pandas juga dapat membaca data dan mendeskripsikan data untuk membaca data dengan pandas terdapat sejumlah perintah panda untuk membaca format data lainnya seperti pd read_excel  myfile xlsx   sheet_name  sheet1   index_col none na_values   na     pd read_stata  myfile",
          "document_id": 1128
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "akurasi, precision, recall digunakan pada kasus apa?",
              "id": 3284,
              "answers": [
                {
                  "answer_id": 1646,
                  "document_id": 1137,
                  "question_id": 3284,
                  "text": "pada kasus klasifikasi dapat berupa akurasi  precision  recall atau yang lainnya",
                  "answer_start": 48,
                  "answer_end": 128,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "pada kasus regresi  dapat berupa mse  sedangkan pada kasus klasifikasi dapat berupa akurasi  precision  recall atau yang lainnya biasanya membutuhkan biaya komputasi yang tinggi wrapper method dependen terhadap algoritma pembelajaran yang digunakan  sehingga lebih berisiko overfitting jika dibandingkan dengan filter method biasanya mampu mencapai predicitive accuracy pada algoritma pembelajaran dibandingkan dengan filter method langkah langkah dalam wrapper method yaitu  1  mencari subset fitur   2  menggunakan subset fitur yang dipilih pada langkah 1 secara langsung pada algoritma pembelajaran yang digunakan  lalu mengevaluasi performa algoritma pembelajaran pada subset fitur tersebut   3  mengulangi langkah 1 dan 2 hingga kondisi berhenti atau kriteria evaluasi tertentu terpenuhi",
          "document_id": 1137
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kumpulan dari data disebut sebagai apa?",
              "id": 3286,
              "answers": [
                {
                  "answer_id": 1649,
                  "document_id": 1153,
                  "question_id": 3286,
                  "text": "data atau dataset merupakan kumpulan dari data objek yang merepresentasikan sebuah entitas  atribut ",
                  "answer_start": 0,
                  "answer_end": 100,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data atau dataset merupakan kumpulan dari data objek yang merepresentasikan sebuah entitas  atribut sementara itu  data objek disebut juga sebagai record  point  sample  dan instance atribut merepresentasikan karakteristik sebuah data objek misalnya  untuk data mahasiswa  terdapat atribut nama  nim  usia  jenis kelamin  dan sebagainya atribut juga dikenal dengan sebutan variabel atau fitur",
          "document_id": 1153
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "data yang ordered terdiri atas apa saja?",
              "id": 3207,
              "answers": [
                {
                  "answer_id": 1559,
                  "document_id": 1143,
                  "question_id": 3207,
                  "text": "data yang ordered terdiri atas video data  spatio temporal data  sequential data  dan genetic sequence data ",
                  "answer_start": 0,
                  "answer_end": 108,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data yang ordered terdiri atas video data  spatio temporal data  sequential data  dan genetic sequence data sedangkan data spatial  image  dan multimedia mencakup spatial data  maps   image data  voice data  dan video data sumber data dikelompokkan menjadi dua  yakni sumber internal dan eksternal contoh sumber internal adalah database  teks dokumen  multimedia dokumen  audio  video   dan spreadsheet  excel  csv  json  dll sedangkan contoh sumber eksternal adalah open data repositories dan public domain web pages",
          "document_id": 1143
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa kegunaan dari sunburst?",
              "id": 3291,
              "answers": [
                {
                  "answer_id": 1655,
                  "document_id": 1176,
                  "question_id": 3291,
                  "text": "menunjukkan proporsi bagian dari jumlah total dengan tree map  histogram  pie chart  stacked bar  peta  dan sunburst ",
                  "answer_start": 3,
                  "answer_end": 120,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "7  menunjukkan proporsi bagian dari jumlah total dengan tree map  histogram  pie chart  stacked bar  peta  dan sunburst 8  menunjukkan perubahan nilai pada satu variabel dengan kolomi dan scatter plot 9  menampilkan simpangan atau deviasi data dengan kombinasi  deviation bar  bar chart  dan area 10  menggunakan teks sebagai data utama dengan heatmap  word cloud  dan teks 11  menampilkan perubahan nilai dari waktu ke waktu atau tren dengan slopegraph  line chart  dot plot  dan deviation bar",
          "document_id": 1176
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja contoh sumber internal?",
              "id": 3202,
              "answers": [
                {
                  "answer_id": 1554,
                  "document_id": 1159,
                  "question_id": 3202,
                  "text": "contoh sumber internal adalah database  teks dokumen  multimedia dokumen  audio  video   dan spreadsheet  excel  csv  json  dll ",
                  "answer_start": 0,
                  "answer_end": 128,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "contoh sumber internal adalah database  teks dokumen  multimedia dokumen  audio  video   dan spreadsheet  excel  csv  json  dll sedangkan contoh sumber eksternal adalah open data repositories dan public domain web pages populasi merupakan wilayah generalisasi yang terdiri atas subjek atau objek yang mempunyai kualitas dan karakteristik tertentu yang ditetapkan oleh peneliti untuk dipelajari  kemudian ditarik kesimpulannya populasi bukan hanya mengacu pada orang  tetapi bisa objek atau benda alam lainnya sementara itu  sampel merupakan bagian dari populasi  mencakup sejumlah anggota yang dipilih dari populasi",
          "document_id": 1159
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kapan stacked bar chart digunakan?",
              "id": 3117,
              "answers": [
                {
                  "answer_id": 1460,
                  "document_id": 1164,
                  "question_id": 3117,
                  "text": "jika di breakdown terhadap suatu dimensi data visualisasi yang biasa digunakan adalah stacked bar chart",
                  "answer_start": 216,
                  "answer_end": 319,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "jika ingin melihat distribusi di dua variabel  maka dapat menggunakan visualisasi data scatterplot tujuan visualisasi ke   tiga yaitu komposisi atau composition digunakan untuk melihat komposisi dari suatu variabel  jika di breakdown terhadap suatu dimensi data visualisasi yang biasa digunakan adalah stacked bar chart untuk data kategorikal  sedangkan jika data berkaitan dengan waktu maka visualisasi data yang biasa digunakan adalah stacked line chart tujuan visualisasi ke   empat yaitu relasi atau relationship digunakan untuk melihat keterhubungan antara suatu variabel dengan variabel lain visualisasi yang biasa digunakan adalah scatter plot",
          "document_id": 1164
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "metode sampling probabilitas adalah apa?",
              "id": 3204,
              "answers": [
                {
                  "answer_id": 1556,
                  "document_id": 1148,
                  "question_id": 3204,
                  "text": "metode sampling probabilitas adalah suatu prosedur dimana probabilitas pemilihan diketahui terlebih dulu untuk setiap unit atau elemen populasi ",
                  "answer_start": 65,
                  "answer_end": 209,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "ada dua metode sampling  yaitu probabilitas dan non probabilitas metode sampling probabilitas adalah suatu prosedur dimana probabilitas pemilihan diketahui terlebih dulu untuk setiap unit atau elemen populasi setiap elemen populasi mempunyai peluang yang sama sebagai sampel ketika kita ingin mengurangi bias sampel  metode ini akan menghasilkan temuan yang berkualitas lebih tinggi karena memberikan representasi yang tidak bias dari populasi ketika populasi biasanya beragam  metode pengambilan sampel ini akan membantu memilih sampel dari berbagai strata sosial ekonomi  latar belakang  dll untuk mewakili populasi secara lebih luas",
          "document_id": 1148
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "visualisasi data dapat menggunakan apa?",
              "id": 3199,
              "answers": [
                {
                  "answer_id": 1551,
                  "document_id": 1170,
                  "question_id": 3199,
                  "text": "visualisasi data dapat menggunakan teknik visualisasi dengan bahasa python",
                  "answer_start": 0,
                  "answer_end": 74,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "visualisasi data dapat menggunakan teknik visualisasi dengan bahasa python dengan python untuk membuat visualisasi dapat menggunakan toolkit seperti matplotlib pyplot dan seaborn kemudian jalankan import matplotlib pyplot tetapi harus dipastikan sudah terinstal sebelumnya terdapat beberapa macam visualisasi dengan berbagai macam yang diantaranya pie chart  bar chart  line graphs  scatter plot  heatmap  histogram  boxplot  dan macam   macam visualisasi lainnya dengan berbagai macam visualisasi yang ada dapat diberikan penjelasan masing   masing macam visualisasi",
          "document_id": 1170
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa manfaat penyampelan kemudahan untuk informasi?",
              "id": 3206,
              "answers": [
                {
                  "answer_id": 1558,
                  "document_id": 1144,
                  "question_id": 3206,
                  "text": "penyampelan kemudahan digunakan untuk mendapatkan informasi dengan cepat  murah  dan mudah yang biasanya untuk kuisioner menguji atau penelitian eksplorasi ",
                  "answer_start": 0,
                  "answer_end": 156,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "penyampelan kemudahan digunakan untuk mendapatkan informasi dengan cepat  murah  dan mudah yang biasanya untuk kuisioner menguji atau penelitian eksplorasi penyampelan pertimbangan didasarkan pada kriteria kriteria tertentu  misalnya penelitian tentang kualitas makanan  sampel sumber data ahli makanan atau ahli gizi penyampelan kuota pada dasarnya sama dengan penyampelan pertimbangan penyampelan bola salju merupakan suatu metode penarikan sampel dimana responden yang berhasil diperoleh diminta untuk menunjukkan responden lainnya secara berantai statistik dasar dapat digunakan untuk mendeskripsikan data  sehingga dapat memahami data terkait pusat distribusi  variasi  dan sebaran data",
          "document_id": 1144
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "data understanding dilakukan setelah langkah apa?",
              "id": 3203,
              "answers": [
                {
                  "answer_id": 1555,
                  "document_id": 1149,
                  "question_id": 3203,
                  "text": " data understanding dilakukan setelah langkah business understanding",
                  "answer_start": 109,
                  "answer_end": 177,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " data understanding yang biasa disebut dengan telaah data dilakukan untuk mendapatkan gambaran utuh atas data data understanding dilakukan setelah langkah business understanding sehingga problem bisnis sudah terselesaikan setelah awal data dipahami atau data understanding telah dilakukan  dilanjutkan dengan data preparation data yang ada belum tentu bisa langsung dipakai karena bisa jadi datanya terpisah pisah atau justru terintegrasi secara ketat  sehingga diperlukan adanya data understanding data understanding dapat memberikan gambaran awal tentang kelebihan atau kekuatan data  kekurangan dan batasan penggunaan data  tingkat kesesuaian data dengan masalah bisnis yang akan dipecahkan  serta ketersediaan data  open data  data public  biaya akses  dll",
          "document_id": 1149
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara mendapatkan rata rata ",
              "id": 2992,
              "answers": [
                {
                  "answer_id": 1348,
                  "document_id": 1158,
                  "question_id": 2992,
                  "text": "mean atau rata rata dapat diperoleh dengan cara membagi jumlah semua bilangan dengan banyaknya bilangan dalam kumpulan ",
                  "answer_start": 305,
                  "answer_end": 424,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "penyampelan bola salju merupakan suatu metode penarikan sampel dimana responden yang berhasil diperoleh diminta untuk menunjukkan responden lainnya secara berantai statistik dasar dapat digunakan untuk mendeskripsikan data  sehingga dapat memahami data terkait pusat distribusi  variasi  dan sebaran data mean atau rata rata dapat diperoleh dengan cara membagi jumlah semua bilangan dengan banyaknya bilangan dalam kumpulan simpangan baku adalah salah satu ukuran sebaran data jika nilai simpangan baku besar  maka data secara umum tersebar jauh dari nilai rerata aritmetik",
          "document_id": 1158
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana tujuan visualisasi dalam konteks distribusi ",
              "id": 3010,
              "answers": [
                {
                  "answer_id": 1355,
                  "document_id": 1163,
                  "question_id": 3010,
                  "text": "untuk melihat distribusi atau persebaran data di suatu variabel ",
                  "answer_start": 73,
                  "answer_end": 137,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "tujuan visualisasi ke   dua yaitu distribusi atau distribution digunakan untuk melihat distribusi atau persebaran data di suatu variabel visualisasi yang lazim digunakan pada distribusi adalah visualisasi data histogram distribusi juga dapat digunakan untuk melihat apakah datanya banyak terkumpul di nilai nilai kecil  berat di kanan  atau simetris  ataupun berdistribusi normal jika ingin melihat distribusi di dua variabel  maka dapat menggunakan visualisasi data scatterplot tujuan visualisasi ke   tiga yaitu komposisi atau composition digunakan untuk melihat komposisi dari suatu variabel  jika di breakdown terhadap suatu dimensi data",
          "document_id": 1163
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana scatter plot digunakan untuk menggambarkan hubungan antara dua variabel ",
              "id": 3008,
              "answers": [
                {
                  "answer_id": 1361,
                  "document_id": 1172,
                  "question_id": 3008,
                  "text": "masing   masing data diplot menjadi sebuah titik yang diposisikan sesuai nilai pada sumbu xy ",
                  "answer_start": 270,
                  "answer_end": 363,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "bagaimana data direpresentasikan dalam scatter plot ",
              "id": 3009,
              "answers": [
                {
                  "answer_id": 1362,
                  "document_id": 1172,
                  "question_id": 3009,
                  "text": " sumbu x biasanya mewakili nilai abstrak yang tidak tergantung variabel lain  sehingga disebut variabel independen sedangkan untuk nilai y merupakan variabel dependen dan ditempatkan pada sumbu vertikal",
                  "answer_start": 362,
                  "answer_end": 564,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sebagai contoh misalnya  grafik garis dapat berguna dalam membuat grafik berat badan balita tiap bulan  temperatur dari waktu ke waktu  harga saham dari waktu ke waktu  dan lain lain 4  scatter plot  grafik ini digunakan untuk menggambarkan hubungan antara dua variabel masing   masing data diplot menjadi sebuah titik yang diposisikan sesuai nilai pada sumbu xy sumbu x biasanya mewakili nilai abstrak yang tidak tergantung variabel lain  sehingga disebut variabel independen sedangkan untuk nilai y merupakan variabel dependen dan ditempatkan pada sumbu vertikal",
          "document_id": 1172
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "pada scatter plot dengan contoh perbandingan apel dengan pear dengan data berat g  dan diameter cm  apa informasi yang dapat diperoleh ",
              "id": 3018,
              "answers": [
                {
                  "answer_id": 1365,
                  "document_id": 1177,
                  "question_id": 3018,
                  "text": "sumbu x biasanya mewakili nilai abstrak yang tidak tergantung variabel lain  sehingga disebut variabel independen sedangkan untuk nilai y merupakan variabel dependen dan ditempatkan pada sumbu vertikal dalam grafik ini juga dapat memberikan informasi tentang pola data atau data pencilan",
                  "answer_start": 0,
                  "answer_end": 287,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sumbu x biasanya mewakili nilai abstrak yang tidak tergantung variabel lain  sehingga disebut variabel independen sedangkan untuk nilai y merupakan variabel dependen dan ditempatkan pada sumbu vertikal dalam grafik ini juga dapat memberikan informasi tentang pola data atau data pencilan 5  heatmap  heatmap adalah jenis visualisasi yang menggunakan kode warna untuk mewakili nilai   kepadatan relatif data di seluruh permukaan warna   warna pada heatmap kemudian dapat digunakan untuk memeriksa data secara visual guna menemukan kelompok dengan nilai serupa dan mendeteksi tren dalam data",
          "document_id": 1177
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dicatat untuk inventarisi sumber daya yang ada?",
              "id": 3282,
              "answers": [
                {
                  "answer_id": 1643,
                  "document_id": 1134,
                  "question_id": 3282,
                  "text": "hardware yang dibutuhkan \n sumber data dan penyimpanan pengetahuan serta sumber daya personal",
                  "answer_start": 200,
                  "answer_end": 293,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "business success criteria  \n dokumentasikan kriteria keberhasilan project\n setiap tujuan bisnis memiliki kriteria untuk sukses\n2. menilai dan memahami situasi anda\na inventaris sumber daya yang ada \n hardware yang dibutuhkan \n sumber data dan penyimpanan pengetahuan serta sumber daya personal \nb menentukan kebutuhan  asumsi dan batasan\n bagaimana kebutuhan datanya  apakah data yang dibutuhkan aman dan legal \n adakah faktor ekonomi yang mempengaruhi project  \n apakah ada asumsi untuk kualitas data\n apakah mempunyai semua password untuk mengakses data",
          "document_id": 1134
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "histogram dapat digunakan untuk apa?",
              "id": 3288,
              "answers": [
                {
                  "answer_id": 1652,
                  "document_id": 1168,
                  "question_id": 3288,
                  "text": "histogram adalah salah satu visualisasi yang dapat digunakan untuk memahami distribusi pada data ",
                  "answer_start": 14,
                  "answer_end": 111,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "6  histogram  histogram adalah salah satu visualisasi yang dapat digunakan untuk memahami distribusi pada data pandas histogram menyediakan metode yang memudahkan kita untuk membuat histogram plot histogram secara tradisional hanya membutuhkan satu dimensi data grafik histogram digunakan untuk menunjukkan jumlah nilai atau kumpulan nilai secara seial dua histogram atau lebih juga dapat diplot dalam satu grafik",
          "document_id": 1168
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dicakup dari data exploration report?",
              "id": 3287,
              "answers": [
                {
                  "answer_id": 1650,
                  "document_id": 1155,
                  "question_id": 3287,
                  "text": "data exploration report mencakup beberapa aspek penting  yaitu hipotesis data  atribut yang  menjanjikan  untuk dianalisis lebih lanjut  eksplorasi karakteristik baru dari data  bagaimana mengubah initial hipotesis  mengidentifikasi subset dari data untuk digunakan nantinya  serta perbandingan dengan tujuan data",
                  "answer_start": 0,
                  "answer_end": 313,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data exploration report mencakup beberapa aspek penting  yaitu hipotesis data  atribut yang  menjanjikan  untuk dianalisis lebih lanjut  eksplorasi karakteristik baru dari data  bagaimana mengubah initial hipotesis  mengidentifikasi subset dari data untuk digunakan nantinya  serta perbandingan dengan tujuan data quality report mencakup beberapa aspek penting  yaitu missing data  kesalahan data  menghitung kesalahan  atribut yang hilang dan kosong  noise  memeriksa keberadaan redudansi data  pertimbangan untuk data pencicilan   outlier  serta bagaimana data disimpan ada beberapa istilah penting dalam data understanding  yaitu dataset  data objek  dan atribut data atau dataset merupakan kumpulan dari data objek yang merepresentasikan sebuah entitas  atribut sementara itu  data objek disebut juga sebagai record  point  sample  dan instance",
          "document_id": 1155
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa hal yang harus dipertimbangkan dalam data usability ",
              "id": 3034,
              "answers": [
                {
                  "answer_id": 1351,
                  "document_id": 1160,
                  "question_id": 3034,
                  "text": "data usability mempertimbangkan kesiapan data",
                  "answer_start": 182,
                  "answer_end": 227,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data correctness berkaitan dengan akurasi data  termasuk kebersihan dan standardisasi data data quantity mengevaluasi apakah jumlah data yang tersedia sudah mencukupi sementara itu  data usability mempertimbangkan kesiapan data tugas dalam data cleaning meliputi menghilangkan data yang tidak relevan termasuk duplikasi data  memperbaiki structural errors  menangani outliers  menangani missing data  serta validasi data dan qa  quality assurance yang pertama yaitu menghilangkan data yang tidak relevan  menghapus data yang tidak sesuai dengan permasalahan dan kolom fitur yang tidak diperlukan",
          "document_id": 1160
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara memuat data ke pandas?",
              "id": 3105,
              "answers": [
                {
                  "answer_id": 1446,
                  "document_id": 1146,
                  "question_id": 3105,
                  "text": "cara memuat data ke pandas yaitu pertama menyalakan jupyter notebook di folder kerja  lalu buka atau buat baru satu skrip ipynb  import pandas dan numpy  kemudian load file csv yang sudah diunduh sebelumnya",
                  "answer_start": 0,
                  "answer_end": 206,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "cara memuat data ke pandas yaitu pertama menyalakan jupyter notebook di folder kerja  lalu buka atau buat baru satu skrip ipynb  import pandas dan numpy  kemudian load file csv yang sudah diunduh sebelumnya  gunakan perintah read_csv untuk menampilkan beberapa baris pertama terakhir dari data yang kita muat  gunakan perintah head   dan tail   pada dataframe dataframe dengan perintah describe   akan membantu kita untuk menampilkan statistik dasar setiap kolom data yang bertipe numerik perintah describe include  all   akan menampilkan statistik kolom yang bertipe non numerik",
          "document_id": 1146
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara mencari modus?",
              "id": 3107,
              "answers": [
                {
                  "answer_id": 1449,
                  "document_id": 1151,
                  "question_id": 3107,
                  "text": "mencari nilai yang paling sering muncul pada sekumpulan data",
                  "answer_start": 248,
                  "answer_end": 308,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "median merupakan nilai tengah atau biasa disebut q2. iqr dapat dicari dengan rumus iqr   q3   q1. outlier adalah nilai yang lebih tinggi rendah dari 1.5 x iqr modus dipakai sebagai ukuran pusat data untuk data bertipe nominal kategoris dengan cara mencari nilai yang paling sering muncul pada sekumpulan data modus tidak dijamin unik dalam suatu distribusi data  karena bisa ada lebih dari satu modus dalam suatu distribusi cara memuat data ke pandas yaitu pertama menyalakan jupyter notebook di folder kerja  lalu buka atau buat baru satu skrip ipynb  import pandas dan numpy  kemudian load file csv yang sudah diunduh sebelumnya  gunakan perintah read_csv untuk menampilkan beberapa baris pertama terakhir dari data yang kita muat  gunakan perintah head   dan tail   pada dataframe",
          "document_id": 1151
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja jenis sampling probabilitas?",
              "id": 3116,
              "answers": [
                {
                  "answer_id": 1459,
                  "document_id": 1141,
                  "question_id": 3116,
                  "text": "penyampelan acak sederhana yaitu pengambilan anggota sampel dari populasi dilakukan secara acak tanpa memperhatikan strata yang ada dalam populasi tersebut pada penyampelan acak berstrata  subsampel acak sederhana ditarik dari setiap strata yang kurang lebih sama dalam beberapa karakteristik penyampelan kluster adalah suatu prosedur penarikan sampel probabilitas yang memilih subpopulasi yang disebut kluster  biasanya sumber datanya sangat luas penyampelan sistematis adalah teknik pengambilan sampel berdasarkan urutan dari anggota populasi yang telah diberi nomor urut",
                  "answer_start": 53,
                  "answer_end": 626,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sampling probabilitas terbagi menjadi beberapa jenis penyampelan acak sederhana yaitu pengambilan anggota sampel dari populasi dilakukan secara acak tanpa memperhatikan strata yang ada dalam populasi tersebut pada penyampelan acak berstrata  subsampel acak sederhana ditarik dari setiap strata yang kurang lebih sama dalam beberapa karakteristik penyampelan kluster adalah suatu prosedur penarikan sampel probabilitas yang memilih subpopulasi yang disebut kluster  biasanya sumber datanya sangat luas penyampelan sistematis adalah teknik pengambilan sampel berdasarkan urutan dari anggota populasi yang telah diberi nomor urut",
          "document_id": 1141
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa perbedaan bar chart dengan diagram lingkaran?",
              "id": 3118,
              "answers": [
                {
                  "answer_id": 1461,
                  "document_id": 1165,
                  "question_id": 3118,
                  "text": "bar chart mirip dengan diagram lingkaran  namun diagram ini dapat digunakan untuk membandingkan kategori data satu sama lai",
                  "answer_start": 601,
                  "answer_end": 724,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "terdapat beberapa macam visualisasi dengan berbagai macam yang diantaranya pie chart  bar chart  line graphs  scatter plot  heatmap  histogram  boxplot  dan macam   macam visualisasi lainnya dengan berbagai macam visualisasi yang ada dapat diberikan penjelasan masing   masing macam visualisasi berikut merupakan penjelasan disetiap macam visualisasi  1  pie chart  pie chart digunakan untuk menunjukkan seberapa banyak dari setiap jenis kategori dalam dataset berbanding dengan keseluruhan 2  bar chart  bar chart merupakan tools visualisasi yang dapat digunakan untuk membandingkan data kategorikal bar chart mirip dengan diagram lingkaran  namun diagram ini dapat digunakan untuk membandingkan kategori data satu sama lain",
          "document_id": 1165
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang digambarkan pada box plot?",
              "id": 3119,
              "answers": [
                {
                  "answer_id": 1463,
                  "document_id": 1169,
                  "question_id": 3119,
                  "text": "boxplot menggambarkan variable variable statistik seperti quartil 1  median   quartil 2  quartil 3  nilai maksimum  nilai minimum  dan outlier",
                  "answer_start": 297,
                  "answer_end": 439,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "grafik histogram digunakan untuk menunjukkan jumlah nilai atau kumpulan nilai secara seial dua histogram atau lebih juga dapat diplot dalam satu grafik salah satu contoh grafik yang dapat di implementasikan yaitu membuat dua histogram untuk atribut bore dan stroke sebuah mesin mobil 7  box plot  boxplot menggambarkan variable variable statistik seperti quartil 1  median   quartil 2  quartil 3  nilai maksimum  nilai minimum  dan outlier pemilihan jenis visualisasi dapat disesuaikan berdasarkan dengan kebutuhannya",
          "document_id": 1169
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "box plot menggambarkan apa saja?",
              "id": 3198,
              "answers": [
                {
                  "answer_id": 1550,
                  "document_id": 1178,
                  "question_id": 3198,
                  "text": "box plot  boxplot menggambarkan variable variable statistik seperti quartil 1  median   quartil 2  quartil 3  nilai maksimum  nilai minimum  dan outlier",
                  "answer_start": 3,
                  "answer_end": 155,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "7  box plot  boxplot menggambarkan variable variable statistik seperti quartil 1  median   quartil 2  quartil 3  nilai maksimum  nilai minimum  dan outlier pemilihan jenis visualisasi dapat disesuaikan berdasarkan dengan kebutuhannya berikut merupakan jenis visualisasi data yang dapat dipilih sesuai dengan kebutuhan yang diinginkan   berdasarkan referensi evergreen  stephanie d h 2020. effective data visualization   the right chart for the right data   yaitu  1  menunjukkan satu nilai variabel dengan satu nilai   dalam bentuk persen  contoh 78     pie chart  dan grid 2  menunjukkan peringkat atau ranking dengan bubble chart  diagram batang  slopegraph  dot  dan lolipop",
          "document_id": 1178
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa visualisasi yang digunakan untuk melihat keterhubungan antara suatu variabel?",
              "id": 3290,
              "answers": [
                {
                  "answer_id": 1654,
                  "document_id": 1174,
                  "question_id": 3290,
                  "text": "untuk melihat keterhubungan antara suatu variabel dengan variabel lain visualisasi yang biasa digunakan adalah scatter plot ",
                  "answer_start": 71,
                  "answer_end": 195,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "tujuan visualisasi ke   empat yaitu relasi atau relationship digunakan untuk melihat keterhubungan antara suatu variabel dengan variabel lain visualisasi yang biasa digunakan adalah scatter plot tujuan visualisasi ke   lima yaitu visualisasi data berdasarkan dengan tujuannya visualisasi data dapat menggunakan teknik visualisasi dengan bahasa python dengan python untuk membuat visualisasi dapat menggunakan toolkit seperti matplotlib pyplot dan seaborn kemudian jalankan import matplotlib",
          "document_id": 1174
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa visualisasi yang digunakan untuk membandingkan data kategorikal?",
              "id": 3289,
              "answers": [
                {
                  "answer_id": 1653,
                  "document_id": 1171,
                  "question_id": 3289,
                  "text": "  bar chart merupakan tools visualisasi yang dapat digunakan untuk membandingkan data kategorikal",
                  "answer_start": 12,
                  "answer_end": 109,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "2  bar chart  bar chart merupakan tools visualisasi yang dapat digunakan untuk membandingkan data kategorikal bar chart mirip dengan diagram lingkaran  namun diagram ini dapat digunakan untuk membandingkan kategori data satu sama lain dengan menggunakan diagram batang dapat menampilkan lebih banyak kategori data daripada diagram lingkaran maka dari itu  bar chart memiliki keunggulan daripada diagram lingkaran 3  line graphs  line graph adalah bentuk visualisasi lainya selain diagram lingkaran dan diagram batang",
          "document_id": 1171
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "data dikelompokkan menjadi apa saja ",
              "id": 2999,
              "answers": [
                {
                  "answer_id": 1336,
                  "document_id": 1145,
                  "question_id": 2999,
                  "text": "data dikelompokkan menjadi beberapa jenis  yaitu bentuk record  bentuk graph dan network  ordered  serta spatial  image  dan multimedia ",
                  "answer_start": 0,
                  "answer_end": 136,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data dikelompokkan menjadi beberapa jenis  yaitu bentuk record  bentuk graph dan network  ordered  serta spatial  image  dan multimedia data yang berbentuk record terdiri atas data matrix  document data  dan transaction data data yang berbentuk graph dan network mencakup world wide web  molecular structures  dan social networks data yang ordered terdiri atas video data  spatio temporal data  sequential data  dan genetic sequence data sedangkan data spatial  image  dan multimedia mencakup spatial data  maps   image data  voice data  dan video data",
          "document_id": 1145
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa bentuk visualisasi lainnya selain diagram lingkaran?",
              "id": 3200,
              "answers": [
                {
                  "answer_id": 1552,
                  "document_id": 1166,
                  "question_id": 3200,
                  "text": "line graph adalah bentuk visualisasi lainya selain diagram lingkaran dan diagram batang",
                  "answer_start": 88,
                  "answer_end": 175,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "maka dari itu  bar chart memiliki keunggulan daripada diagram lingkaran 3  line graphs  line graph adalah bentuk visualisasi lainya selain diagram lingkaran dan diagram batang diagram garis   line graphs   lebih berguna untuk menunjukkan bagaimana kemajuan data selama beberapa periode sebagai contoh misalnya  grafik garis dapat berguna dalam membuat grafik berat badan balita tiap bulan  temperatur dari waktu ke waktu  harga saham dari waktu ke waktu  dan lain lain 4  scatter plot  grafik ini digunakan untuk menggambarkan hubungan antara dua variabel",
          "document_id": 1166
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "tipe metode sampling non probabilitas penyampelan kemudahan digunakan untuk apa?",
              "id": 3106,
              "answers": [
                {
                  "answer_id": 1448,
                  "document_id": 1150,
                  "question_id": 3106,
                  "text": " tipe metode sampling non probabilitas penyampelan kemudahan digunakan untuk mendapatkan informasi dengan cepat  murah  dan mudah yang biasanya untuk kuisioner menguji atau penelitian",
                  "answer_start": 190,
                  "answer_end": 373,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sementara itu  metode sampling non probabilitas adalah prosedur penarikan sampel yang bersifat subjektif setiap elemen penelitian tidak memiliki peluang yang sama untuk dipilih ada  beberapa tipe metode sampling non probabilitas penyampelan kemudahan digunakan untuk mendapatkan informasi dengan cepat  murah  dan mudah yang biasanya untuk kuisioner menguji atau penelitian eksplorasi penyampelan pertimbangan didasarkan pada kriteria kriteria tertentu  misalnya penelitian tentang kualitas makanan  sampel sumber data ahli makanan atau ahli gizi",
          "document_id": 1150
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang harus dilakukan agar audiens dapat memahami informasi yang ingin disampaikan?",
              "id": 3110,
              "answers": [
                {
                  "answer_id": 1453,
                  "document_id": 1161,
                  "question_id": 3110,
                  "text": "pemilihan jenis visualisasi yang tepat dan pemahaman tentang tujuan visualisasi akan memastikan bahwa informasi yang ingin disampaikan dapat dipahami dengan jelas dan efektif oleh audiens",
                  "answer_start": 733,
                  "answer_end": 920,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "visualisasi yang tepat akan memudahkan pemahaman dan mengungkap pola  tren  serta hubungan yang terdapat dalam data yang kompleks dalam menginterpretasikan hasil visualisasi  penting untuk memperhatikan konteks data dan memastikan bahwa visualisasi yang dipilih memenuhi tujuan yang diinginkan untuk mengkomunikasikan informasi dengan jelas dan efektif kepada audiens maka dapat diberi kesimpulan bahwa visualisasi data adalah teknik yang penting dalam membantu kita memahami dan menganalisis data yang kompleks dengan menggunakan berbagai macam visualisasi seperti pie chart  bar chart  line graphs  scatter plot  heatmap  histogram  box plot  dan lainnya  kita dapat mengungkap pola  tren  dan hubungan yang tersembunyi dalam data pemilihan jenis visualisasi yang tepat dan pemahaman tentang tujuan visualisasi akan memastikan bahwa informasi yang ingin disampaikan dapat dipahami dengan jelas dan efektif oleh audiens",
          "document_id": 1161
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "data matrix dan document data termasuk data bebentuk apa?",
              "id": 3109,
              "answers": [
                {
                  "answer_id": 1451,
                  "document_id": 1156,
                  "question_id": 3109,
                  "text": "data yang berbentuk record terdiri atas data matrix  document data  dan transaction data",
                  "answer_start": 551,
                  "answer_end": 639,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "atribut nominal berupa kategori  misal jenis kelamin  status perkawinan  agama  dll atribut binary merupakan atribut nominal dengan hanya 2 nilai  yaitu 0 dan 1. atribut ordinal merupakan nilai yang merepresentasikan urutan  misalkan nilai mata kuliah sedangkan atribut numeric mencakup quantity  bilangan integer atau real   interval  ukuran skala unit  misal suhu  tanggal   dan ratio  misal panjang  harga  umur data dikelompokkan menjadi beberapa jenis  yaitu bentuk record  bentuk graph dan network  ordered  serta spatial  image  dan multimedia data yang berbentuk record terdiri atas data matrix  document data  dan transaction data",
          "document_id": 1156
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "outlier dapat disebabkan oleh apa saja?",
              "id": 3292,
              "answers": [
                {
                  "answer_id": 1656,
                  "document_id": 1180,
                  "question_id": 3292,
                  "text": "outlier dapat disebabkan oleh data entry error  measurement error  sampling error  data corruption  serta pengamatan outlier yang sebenarnya",
                  "answer_start": 0,
                  "answer_end": 140,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "outlier dapat disebabkan oleh data entry error  measurement error  sampling error  data corruption  serta pengamatan outlier yang sebenarnya keberadaan outlier dapat menyebabkan masalah saat memodelkan  terutama dalam model linear  dan dapat mempengaruhi evaluasi seperti perhitungan mse  mean squared error statistics based outlier detection techniques mengasumsikan bahwa normal data point akan muncul pada area dengan probabilitas tinggi  sedangkan outlier biasanya muncul pada area dengan probabilitas rendah pada model stokastik beberapa cara untuk mengidentifikasi outlier yaitu menggunakan standard deviation method  interquartile range method  dan automatic outlier detection metode pertama adalah standard deviation method  yang cocok digunakan pada sample dengan distribusi nilai gaussian atau mendekati distribusi gaussian",
          "document_id": 1180
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "hal apa yang melatarbelakangi reduksi dimensi ",
              "id": 3052,
              "answers": [
                {
                  "answer_id": 1368,
                  "document_id": 1179,
                  "question_id": 3052,
                  "text": "reduksi dimensi menjadi solusi untuk permasalahan dimana ketika dimensi data meningkat  performa classifier juga meningkat hingga jumlah fitur yang optimal tertentu dan jika dimensi data terus ditambah  tanpa ada peningkatan jumlah sampel pelatihan  maka performa classifier juga akan menurun ",
                  "answer_start": 0,
                  "answer_end": 293,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "reduksi dimensi menjadi solusi untuk permasalahan dimana ketika dimensi data meningkat  performa classifier juga meningkat hingga jumlah fitur yang optimal tertentu dan jika dimensi data terus ditambah  tanpa ada peningkatan jumlah sampel pelatihan  maka performa classifier juga akan menurun reduksi dimensi adalah proses mengurangi dimensi data ke ruang dimensi yang lebih rendah  namun tetap mempertahankan karakteristik asli dari data tersebut teknik reduksi dimensi dibagi menjadi seleksi fitur dan ekstraksi fitur seleksi fitur akan memilih subset fitur yang signifikan dan nilai fitur tetap berada pada domain aslinya sedangkan ekstraksi fitur akan mengekstrak fitur ke dalam format tertentu dan nilai hasil ekstraksi fitur berada pada domain yang berbeda dengan data aslinya",
          "document_id": 1179
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dapat digunakan untuk dapat membuat histogram dengan mudah ",
              "id": 3020,
              "answers": [
                {
                  "answer_id": 1359,
                  "document_id": 1167,
                  "question_id": 3020,
                  "text": "pandas histogram ",
                  "answer_start": 500,
                  "answer_end": 517,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "apa yang dimaksud heatmap ",
              "id": 3004,
              "answers": [
                {
                  "answer_id": 1358,
                  "document_id": 1167,
                  "question_id": 3004,
                  "text": " heatmap adalah jenis visualisasi yang menggunakan kode warna untuk mewakili nilai   kepadatan relatif data di seluruh permukaan warna",
                  "answer_start": 11,
                  "answer_end": 145,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "5  heatmap  heatmap adalah jenis visualisasi yang menggunakan kode warna untuk mewakili nilai   kepadatan relatif data di seluruh permukaan warna   warna pada heatmap kemudian dapat digunakan untuk memeriksa data secara visual guna menemukan kelompok dengan nilai serupa dan mendeteksi tren dalam data untuk mengimplementasikannya dalam bahasa python  biasanya menggunakan library seaborn 6  histogram  histogram adalah salah satu visualisasi yang dapat digunakan untuk memahami distribusi pada data pandas histogram menyediakan metode yang memudahkan kita untuk membuat histogram",
          "document_id": 1167
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "populasi pada data understanding mengacu pada apa ",
              "id": 2993,
              "answers": [
                {
                  "answer_id": 1347,
                  "document_id": 1157,
                  "question_id": 2993,
                  "text": "populasi bukan hanya mengacu pada orang  tetapi bisa objek atau benda alam lainnya ",
                  "answer_start": 0,
                  "answer_end": 83,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "populasi bukan hanya mengacu pada orang  tetapi bisa objek atau benda alam lainnya sementara itu  sampel merupakan bagian dari populasi  mencakup sejumlah anggota yang dipilih dari populasi penyampelan bertujuan untuk memperoleh informasi tentang populasi ada dua metode sampling  yaitu probabilitas dan non probabilitas metode sampling probabilitas adalah suatu prosedur dimana probabilitas pemilihan diketahui terlebih dulu untuk setiap unit atau elemen populasi",
          "document_id": 1157
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "visualisasi merupakan teknik untuk menampilkan apa?",
              "id": 3201,
              "answers": [
                {
                  "answer_id": 1553,
                  "document_id": 1162,
                  "question_id": 3201,
                  "text": "visualisasi merupakan suatu teknik dalam pembuatan grafik atau diagram untuk menampilkan atau merepresentasikan secara visual sebuah informasi dengan memvisualisasikan data membantu pengguna untuk memahami pola  tren  hubungan  dan outlier yang tersembunyi di dalam data yang besar dan kompleks v",
                  "answer_start": 1,
                  "answer_end": 297,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " visualisasi merupakan suatu teknik dalam pembuatan grafik atau diagram untuk menampilkan atau merepresentasikan secara visual sebuah informasi dengan memvisualisasikan data membantu pengguna untuk memahami pola  tren  hubungan  dan outlier yang tersembunyi di dalam data yang besar dan kompleks visualisasi sendiri memiliki empat tujuan antara lain pertama perbandingan atau comparison digunakan untuk membandingkan suatu sekumpulan nilai dengan nilai lainnya  mana yang lebih besar  lebih tinggi  mana yang naik  dsb untuk data yang berkaitan dengan waktu maka visualisasi yang digunakan biasanya berupa line chart sedangkan untuk data kategorikal maka lebih cocok menggunakan bar chart tujuan visualisasi ke   dua yaitu distribusi atau distribution digunakan untuk melihat distribusi atau persebaran data di suatu variabel visualisasi yang lazim digunakan pada distribusi adalah visualisasi data histogram",
          "document_id": 1162
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana jika nilai unik sebuah kolom hanya 1?",
              "id": 3123,
              "answers": [
                {
                  "answer_id": 1468,
                  "document_id": 1184,
                  "question_id": 3123,
                  "text": "jika nilai unik pada sebuah kolom   1  kolom tersebut tidak berguna untuk proses modelling",
                  "answer_start": 0,
                  "answer_end": 90,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "jika nilai unik pada sebuah kolom   1  kolom tersebut tidak berguna untuk proses modelling mengidentifikasi dan hapus kolom dengan low variance  yaitu kolom yang memiliki sedikit nilai unik dan variance mendekati nol  terutama pada atribut numerik besarnya variance threshold dapat diuji coba dengan beberapa nilai melalui eksperimen untuk mendapatkan hasil yang terbaik mengidentifikasi dan hapus duplikasi baris data yang dapat terjadi saat pengumpulan data dari beberapa sumber atau pengulangan observasi eksperimen duplikasi baris tidak memberikan informasi tambahan dan dapat mengakibatkan bias pada evaluasi model",
          "document_id": 1184
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa tujuan dari proses reduksi dimensi ",
              "id": 3024,
              "answers": [
                {
                  "answer_id": 1374,
                  "document_id": 1187,
                  "question_id": 3024,
                  "text": "reduksi dimensi bertujuan mengurangi dimensi data yang terlalu besar untuk efisiensi dalam proses analisis dan mendapatkan hasil yang lebih baik ",
                  "answer_start": 244,
                  "answer_end": 389,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "data cleaning melibatkan identifikasi dan perbaikan error dalam dataset  seperti menghapus duplikasi  menangani missing data  dan outlier transformasi data dilakukan untuk mengubah format data agar lebih mudah dipahami dan dianalisis sedangkan reduksi dimensi bertujuan mengurangi dimensi data yang terlalu besar untuk efisiensi dalam proses analisis dan mendapatkan hasil yang lebih baik proses data preparation dapat bervariasi karena tergantung pada tujuan analisis  keahlian pengguna data  dan pertanyaan yang ingin dijawab aspek dalam data preparation meliputi data completeness  data correctness  data quantity  dan data usability",
          "document_id": 1187
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu proses iterative imputation?",
              "id": 3194,
              "answers": [
                {
                  "answer_id": 1544,
                  "document_id": 1192,
                  "question_id": 3194,
                  "text": "iterative imputation adalah proses di mana setiap fitur dimodelkan sebagai fungsi dari fitur lainnya  ",
                  "answer_start": 77,
                  "answer_end": 179,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "parameter tersebut seperti ukuran jarak  jumlah tetangga terdekat  dan bobot iterative imputation adalah proses di mana setiap fitur dimodelkan sebagai fungsi dari fitur lainnya  misalnya sebagai masalah regresi untuk memprediksi missing value setiap fitur diperhitungkan secara berurutan  satu demi satu  memungkinkan nilai yang telah diperhitungkan sebelumnya untuk digunakan sebagai bagian dari model untuk memprediksi fitur berikutnya disebut iteratif karena proses ini diulang beberapa kali  memungkinkan hasil estimasi missing value yang semakin meningkat sebagaimana missing value pada semua fitur diestimasi jumlah iterasi umumnya diset dengan nilai kecil  seperti 10. algoritma regresi yang berbeda dapat digunakan untuk memperkirakan missing value untuk setiap fitur",
          "document_id": 1192
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa contoh regularization method pada embedded method ",
              "id": 3066,
              "answers": [
                {
                  "answer_id": 1379,
                  "document_id": 1195,
                  "question_id": 3066,
                  "text": "regularization method dengan fungsi objektif yang meminimalkan fitting error   sementara itu memaksa koefisien menjadi kecil atau tepat nol",
                  "answer_start": 918,
                  "answer_end": 1057,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "embedded method menggabungkan kelebihan filter dan wrapper method dengan cara meng embed proses seleksi fitur dengan pembangunan model classifier namun  embedded method tidak mencoba semua kemungkinan subset fitur seperti pada wrapper method  sehingga waktu komputasi yang diperlukan lebih reasonable dan risiko overfitting juga lebih kecil dibanding dengan wrapper method embedded method melibatkan algoritma pembelajaran tertentu   sehinga tidak independen sepenuhnya terhadap algoritma pembelajaran seperti pada filter method secara umum embedded method ini terdiri atas  1  pruning methods yang menggunakan semua fitur untuk melatih model di awal   lalu mengeliminasi beberapa fitur secara iteratif mengeset koefisiennya menjadi 0  sambil mempertahankan performa model contoh   svm rfe  svm recursive feature elimination    2  model dengan proses seleksi fitur di dalamnya  seperti decision tree id3 dan c4.5   3  regularization method dengan fungsi objektif yang meminimalkan fitting error   sementara itu memaksa koefisien menjadi kecil atau tepat nol",
          "document_id": 1195
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "random oversampling mereplikasi apa?",
              "id": 3190,
              "answers": [
                {
                  "answer_id": 1539,
                  "document_id": 1205,
                  "question_id": 3190,
                  "text": "random oversampling merupakan metode non heuristik yang mereplikasi sampel dari kelas minoritas secara random  sehingga jumlahnya menyamai sampel dari kelas mayoritas ",
                  "answer_start": 210,
                  "answer_end": 377,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "kelemahannya jumlah data semakin bertambah  dapat memperlambat waktu pembelajaran contohnya yaitu random oversampling  synthetic minority oversampling technique  smote   dan adaptive synthetic sampling  adasyn random oversampling merupakan metode non heuristik yang mereplikasi sampel dari kelas minoritas secara random  sehingga jumlahnya menyamai sampel dari kelas mayoritas kelemahannya dapat meningkatkan resiko overfitting karena adanya replikasi data dapat diimplementasikan menggunakan class randomoversampler dari library imblearn",
          "document_id": 1205
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "data terdiri dari apa?",
              "id": 3189,
              "answers": [
                {
                  "answer_id": 1538,
                  "document_id": 1208,
                  "question_id": 3189,
                  "text": " data biasanya terdiri dari banyak variabel input atau fitur yang mana masing masing fitur dapat memiliki rentang nilai atau satuan yang berbeda",
                  "answer_start": 0,
                  "answer_end": 144,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": " data biasanya terdiri dari banyak variabel input atau fitur yang mana masing masing fitur dapat memiliki rentang nilai atau satuan yang berbeda variabel input dengan rentang nilai yang besar dapat mendominasi variabel input yang nilainya lebih kecil beberapa algoritma machine learning  ml  menjadi lebih condong ke nilai besar tersebut dan mengabaikan variabel dengan rentang nilai yang kecil  maka dari itu diperlukan data scaling sebelum proses modelling banyak algoritma ml yang dapat bekerja lebih baik ketika variabel input numerik diskalakan ke rentang standar tertentu hal ini berlaku untuk algoritma ml yang menggunakan weighted sum of inputs seperti linear regression  logistic regression  dan jaringan syaraf tiruan serta algoritma ml yang memperhitungkan jarak antar sampel data seperti k nearest neighbors  k means clustering  dan support vector machines  svm",
          "document_id": 1208
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa sebutan lain untuk discretization ",
              "id": 3036,
              "answers": [
                {
                  "answer_id": 1382,
                  "document_id": 1200,
                  "question_id": 3036,
                  "text": "discretization disebut juga sebagai binning atau k bins",
                  "answer_start": 0,
                  "answer_end": 55,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "discretization disebut juga sebagai binning atau k bins  dengan k adalah jumlah kelompok hasil mapping variabel numerik terdapat 3 jenis strategi dalam discretization yaitu uniform  quantile  dan clustered uniform discretization transform berarti setiap bin memiliki lebar yang sama dalam rentang nilai yang mungkin untuk sebuah variabel  transformasi ini akan mempertahankan distribusi probabilitas dari setiap input variabel dapat diimplementasikan menggunakan class kbinsdiscretizer dari library skylearn dengan mengeset parameter strategy  uniform   parameter encode  ordinal  dan menentukan jumlah bin pada parameter n_bin k means cluster discretization transform dilakukan dengan cara membentuk k cluster untuk setiap variabel input  lalu memasukkan setiap nilai ke sebuah kluster yang sesuai",
          "document_id": 1200
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa algoritma ml yang menggunakan weighted sum of inputs?",
              "id": 3297,
              "answers": [
                {
                  "answer_id": 1665,
                  "document_id": 1219,
                  "question_id": 3297,
                  "text": " algoritma ml yang menggunakan weighted sum of inputs seperti linear regression  logistic regression  dan jaringan syaraf tiruan",
                  "answer_start": 140,
                  "answer_end": 268,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "banyak algoritma ml yang dapat bekerja lebih baik ketika variabel input numerik diskalakan ke rentang standar tertentu hal ini berlaku untuk algoritma ml yang menggunakan weighted sum of inputs seperti linear regression  logistic regression  dan jaringan syaraf tiruan serta algoritma ml yang memperhitungkan jarak antar sampel data seperti k nearest neighbors  k means clustering  dan support vector machines  svm beberapa algoritma ml tidak terpengaruh oleh perbedaan sckala pada data numerik  seperti decision tree dan random forest teknik data scaling terbagi menjadi normalization dan standardization normalization menskalakan nilai variabel numerik ke dalam rentang nilai tertentu  biasanya 0 1 sedangkan standardization menskalakan nilai variabel numerik hingga memiliki mean   0 dan standar deviasi   1. jika nilai variabel input mengikuti distribusi gaussian  maka standardisasi kemungkinan lebih tepat untuk dilakukan",
          "document_id": 1219
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa kelebihan dari metode oversampling ",
              "id": 3050,
              "answers": [
                {
                  "answer_id": 1662,
                  "document_id": 1213,
                  "question_id": 3050,
                  "text": "oversampling akan meningkatkan jumlah sampel dari kelas minoritas kelebihannya tidak ada informasi yang hilang  karena tidak ada eliminasi sampel ",
                  "answer_start": 15,
                  "answer_end": 161,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "under_sampling oversampling akan meningkatkan jumlah sampel dari kelas minoritas kelebihannya tidak ada informasi yang hilang  karena tidak ada eliminasi sampel kelemahannya jumlah data semakin bertambah  dapat memperlambat waktu pembelajaran contohnya yaitu random oversampling  synthetic minority oversampling technique  smote   dan adaptive synthetic sampling  adasyn",
          "document_id": 1213
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu teknik data scaling normalization ",
              "id": 3038,
              "answers": [
                {
                  "answer_id": 1381,
                  "document_id": 1198,
                  "question_id": 3038,
                  "text": "normalization menskalakan nilai variabel numerik ke dalam rentang nilai tertentu  biasanya 0 1",
                  "answer_start": 70,
                  "answer_end": 164,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "teknik data scaling terbagi menjadi normalization dan standardization normalization menskalakan nilai variabel numerik ke dalam rentang nilai tertentu  biasanya 0 1 sedangkan standardization menskalakan nilai variabel numerik hingga memiliki mean   0 dan standar deviasi   1. jika nilai variabel input mengikuti distribusi gaussian  maka standardisasi kemungkinan lebih tepat untuk dilakukan jika tidak  maka normalisasi dapat diterapkan khususnya saat range data cukup besar atau kecil alternatifnya dapat dilakukan eksperimen menggunakan normalisasi dan standardisasi  atau bahkan kombinasi keduanya lalu dilihat hasil yang didapat pada saat evaluasi mana yang lebih baik categorical data dapat berupa variabel nominal dan variabel ordinal",
          "document_id": 1198
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa class yang digunakan untuk mengimplementasikan one hot encoding ",
              "id": 3045,
              "answers": [
                {
                  "answer_id": 1394,
                  "document_id": 1220,
                  "question_id": 3045,
                  "text": " class onehotencoder dari library scikit learn",
                  "answer_start": 376,
                  "answer_end": 422,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            },
            {
              "question": "mengapa one hote encoding digunakan ",
              "id": 3039,
              "answers": [
                {
                  "answer_id": 1392,
                  "document_id": 1220,
                  "question_id": 3039,
                  "text": "one hot encoding digunakan untuk encoding variabel nominal ke nilai numerik ",
                  "answer_start": 196,
                  "answer_end": 272,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "urutan nilai integer secara natural juga merepresentasikan urutan di dalam nilai nilai variabel ordinal tersebut dalam diimplementasikan menggunakan class ordinalencoder dari library scikit learn one hot encoding digunakan untuk encoding variabel nominal ke nilai numerik setiap nilai kategori dalam variabel akan diubah menjadi nilai biner dapat diimplementasikan menggunakan class onehotencoder dari library scikit learn",
          "document_id": 1220
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang tidak dapat ditangani oleh algoritma relief?",
              "id": 3172,
              "answers": [
                {
                  "answer_id": 1517,
                  "document_id": 1225,
                  "question_id": 3172,
                  "text": "algoritma relief mampu menangani fitur kategorikal maupun numerik  namun tidak dapat menangani data yang tidak lengkap  dan terbatas ",
                  "answer_start": 117,
                  "answer_end": 250,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "sebaliknya  jika nilai fitur a pada sampel r i dan nearest miss adalah berbeda  maka bobot fitur a akan ditingkatkan algoritma relief mampu menangani fitur kategorikal maupun numerik  namun tidak dapat menangani data yang tidak lengkap  dan terbatas untuk permasalahan klasifikasi biner algoritma relieff merupakan ekstensi dari algoritma basic relief untuk menangani permasalahan klasifikasi multikelas algoritma relieff lebih robost sehingga mampu menangani data yang tidak lengkap dan data yang mengandung noise wrapper method mencari kombinasi subset fitur yang optimal dengan mengevaluasinya secara langsung pada algoritma pembelajaran tertentu",
          "document_id": 1225
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apakah missing value dapat meningkat?",
              "id": 3122,
              "answers": [
                {
                  "answer_id": 1467,
                  "document_id": 1182,
                  "question_id": 3122,
                  "text": "kemungkinan missing value semakin meningkat seiring bertambahnya ukuran dataset ",
                  "answer_start": 0,
                  "answer_end": 80,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "kemungkinan missing value semakin meningkat seiring bertambahnya ukuran dataset penyebab missing value dapat bervariasi seperti masalah spesifik pada problem domain  observasi yang tidak tercatat  data corruption  data unavailability  malfunctioning measurement equipment penanganan missing value sangat penting karena beberapa algoritma machine learning tidak mendukung adanya missing value terdapat beberapa strategi untuk menangani missing value  seperti menghapus kolom atau baris yang berisi missing value  serta missing value imputation yang mana mengidentifikasi missing value dalam dataset  lalu mengisinya dengan nilai hasil estimasi contohnya seperti statistical imputation  knn imputation  iterative imputation",
          "document_id": 1182
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana mengidentifikasi outlier pada sample yang datanya tidak mengikuti distribusi normal?",
              "id": 3156,
              "answers": [
                {
                  "answer_id": 1501,
                  "document_id": 1186,
                  "question_id": 3156,
                  "text": "interquartile range  iqr  method  yang dapat digunakan pada sample yang datanya tidak mengikuti distribusi normal  gaussian ",
                  "answer_start": 94,
                  "answer_end": 218,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "menggunakan cut off standard deviasi dari mean untuk identifikasi outlier metode kedua adalah interquartile range  iqr  method  yang dapat digunakan pada sample yang datanya tidak mengikuti distribusi normal  gaussian metode ketiga adalah automatic outlier detection yang menggunakan metode lof  local outlier factor metode ini menggunakan ide konsep nearest neighbors untuk identifikasi outlier lof menghitung deviasi local density dari titik data tertentu terhadap tetangganya",
          "document_id": 1186
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kapan missing value terjadi?",
              "id": 3159,
              "answers": [
                {
                  "answer_id": 1504,
                  "document_id": 1194,
                  "question_id": 3159,
                  "text": "missing value terjadi ketika satu atau beberapa nilai kolom dalam dataset tidak tersedia ",
                  "answer_start": 183,
                  "answer_end": 272,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "setiap sampel akan diberi skor untuk mengindikasikan tingkat isolasi berdasarkan ukurannya terhadap local neighborhood tugas keempat dalam data cleaning yaitu menangani missing value missing value terjadi ketika satu atau beberapa nilai kolom dalam dataset tidak tersedia kemungkinan missing value semakin meningkat seiring bertambahnya ukuran dataset penyebab missing value dapat bervariasi seperti masalah spesifik pada problem domain  observasi yang tidak tercatat  data corruption  data unavailability  malfunctioning measurement equipment",
          "document_id": 1194
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana imbalanced ratio dihitung?",
              "id": 3191,
              "answers": [
                {
                  "answer_id": 1540,
                  "document_id": 1203,
                  "question_id": 3191,
                  "text": "imbalanced ratio dapat dihitung dengan membagi jumlah sampel di kelas mayoritas dengan jumlah sampel di kelas minoritas ",
                  "answer_start": 0,
                  "answer_end": 120,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "imbalanced ratio dapat dihitung dengan membagi jumlah sampel di kelas mayoritas dengan jumlah sampel di kelas minoritas metode resampling menyeimbangkan ruang sampel dengan cara menyamakan jumlah sampel data di setiap kelas lebih fleksibel karena independen terhadap algoritma klasifikasi yang digunakan metodenya yaitu undersampling  oversampling  dan hybrid sampling undersampling akan mengeliminasi sampel dari kelas mayoritas",
          "document_id": 1203
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa kegunaan image augmentation?",
              "id": 3167,
              "answers": [
                {
                  "answer_id": 1512,
                  "document_id": 1209,
                  "question_id": 3167,
                  "text": "image augmentation digunakan untuk meningkatkan jumlah training image dengan memodifikasi training image yang ada menggunakan metode atau teknik tertentu",
                  "answer_start": 0,
                  "answer_end": 153,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "image augmentation digunakan untuk meningkatkan jumlah training image dengan memodifikasi training image yang ada menggunakan metode atau teknik tertentu image baru yang dihasilkan memiliki kelas data yang sama sesuai dengan image asli yang dimodifikasi keuntungannya dapat dilakukan dengan mudah  tanpa harus melakukan pengumpulan data lagi beberapa cara populer yang dapat dilakukan antara lain image rotation  image shifting  image flipping  image noising dan image blurring",
          "document_id": 1209
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu tomek link?",
              "id": 3169,
              "answers": [
                {
                  "answer_id": 1514,
                  "document_id": 1215,
                  "question_id": 3169,
                  "text": "tomek link adalah pasangan instance dari dua kelas berbeda yang merupakan tetangga terdekatnya",
                  "answer_start": 0,
                  "answer_end": 94,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "tomek link adalah pasangan instance dari dua kelas berbeda yang merupakan tetangga terdekatnya algoritma ini menemukan pasangan tersebut  lalu menghapus instance dari kelas mayoritas untuk mempertegas pemisah antara kelas yang berbeda tomek link dapat diimplementasikan menggunakan class tomeklinks dari library imblearn under_sampling cara kerja estimated nearest neighbors yaitu instance dari kelas mayoritas dihapus berdasarkan k tetangga terdekatnya",
          "document_id": 1215
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja kelebihan filter method?",
              "id": 3302,
              "answers": [
                {
                  "answer_id": 1672,
                  "document_id": 1231,
                  "question_id": 3302,
                  "text": "kelebihan filter method yaitu  1  independen terhadap algoritma pembelajaran sehingga bias pada algoritma pembelajaran tidak akan berpengaruh terhadap proses seleksi fitur dan  2  waktu komputasi yang lebih cepat   efisien ",
                  "answer_start": 0,
                  "answer_end": 223,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "kelebihan filter method yaitu  1  independen terhadap algoritma pembelajaran sehingga bias pada algoritma pembelajaran tidak akan berpengaruh terhadap proses seleksi fitur dan  2  waktu komputasi yang lebih cepat   efisien kekurangan filter method yaitu akurasi pada algoritma pembelajaran bisa jadi tidak optimal karena tidak dilibatkan dalam proses seleksi fitur fitur yang berkualitas adalah fitur yang memiliki nilai sama pada instance yang berasal dari kelas yang sama dan nilai yang berbeda terhadap instance yang berasal dari kelas berbeda algoritma fisher score mengevaluasi fitur secara independen sehingga tidak mampu menangani redundant features algoritma information gain mengukur dependensi antara fitur terhadap label kelas",
          "document_id": 1231
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa fungsi method df.drop   pada library pandas ",
              "id": 3023,
              "answers": [
                {
                  "answer_id": 1372,
                  "document_id": 1183,
                  "question_id": 3023,
                  "text": "df drop   dari library pandas untuk menghapus kolom yang berisi nilai unik pada setiap barisnya atau kolom dengan banyak missing data ",
                  "answer_start": 387,
                  "answer_end": 521,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "tugas dalam data cleaning meliputi menghilangkan data yang tidak relevan termasuk duplikasi data  memperbaiki structural errors  menangani outliers  menangani missing data  serta validasi data dan qa  quality assurance yang pertama yaitu menghilangkan data yang tidak relevan  menghapus data yang tidak sesuai dengan permasalahan dan kolom fitur yang tidak diperlukan menggunakan method df drop   dari library pandas untuk menghapus kolom yang berisi nilai unik pada setiap barisnya atau kolom dengan banyak missing data mengidentifikasi dan hapus kolom yang hanya berisi single value  zero variance  menggunakan method df",
          "document_id": 1183
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "categorical data dapat berupa apa saja?",
              "id": 3305,
              "answers": [
                {
                  "answer_id": 1677,
                  "document_id": 1199,
                  "question_id": 3305,
                  "text": "categorical data dapat berupa variabel nominal dan variabel ordinal ",
                  "answer_start": 187,
                  "answer_end": 255,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "alternatifnya dapat dilakukan eksperimen menggunakan normalisasi dan standardisasi  atau bahkan kombinasi keduanya lalu dilihat hasil yang didapat pada saat evaluasi mana yang lebih baik categorical data dapat berupa variabel nominal dan variabel ordinal variabel nominal adalah variabel yang terdiri atas sekumpulan nilai diskret tanpa adanya hubungan urutan di antara nilai nilai tersebut variabel ordinal adalah variabel yang terdiri atas sekumpulan nilai diskret dengan adanya keterurutan di antara nilai nilai tersebut beberapa algoritma ml mengharuskan semua nilai variabel input dan output berupa nilai numerik  seperti artificial neural network  support vector machine  dsb",
          "document_id": 1199
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara untuk mengidentifikasi outlier?",
              "id": 3157,
              "answers": [
                {
                  "answer_id": 1502,
                  "document_id": 1188,
                  "question_id": 3157,
                  "text": "beberapa cara untuk mengidentifikasi outlier yaitu menggunakan standard deviation method  interquartile range method  dan automatic outlier detection",
                  "answer_start": 0,
                  "answer_end": 149,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "beberapa cara untuk mengidentifikasi outlier yaitu menggunakan standard deviation method  interquartile range method  dan automatic outlier detection metode pertama adalah standard deviation method  yang cocok digunakan pada sample dengan distribusi nilai gaussian atau mendekati distribusi gaussian pada distribusi gaussian  sebarapa jauh standard deviasi dari nilai rata ratanya menunjukkan persentase nilai pada sample menggunakan cut off standard deviasi dari mean untuk identifikasi outlier metode kedua adalah interquartile range  iqr  method  yang dapat digunakan pada sample yang datanya tidak mengikuti distribusi normal  gaussian",
          "document_id": 1188
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu missing value imputation?",
              "id": 3158,
              "answers": [
                {
                  "answer_id": 1503,
                  "document_id": 1193,
                  "question_id": 3158,
                  "text": "missing value imputation yang mana mengidentifikasi missing value dalam dataset  lalu mengisinya dengan nilai hasil estimasi ",
                  "answer_start": 126,
                  "answer_end": 251,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "terdapat beberapa strategi untuk menangani missing value  seperti menghapus kolom atau baris yang berisi missing value  serta missing value imputation yang mana mengidentifikasi missing value dalam dataset  lalu mengisinya dengan nilai hasil estimasi contohnya seperti statistical imputation  knn imputation  iterative imputation statistical imputation memiliki salah satu keuntungan yaitu sederhana karena nilai statistik dapat dihitung dengan cepat dan terbukti efektif pada berbagai kasus statistical imputation menggunakan metode statistik untuk mengestimasi nilai pada sebuah kolom yang terdapat missing value  lalu menggantikan semua missing value dengan nilai tersebut contohnya yaitu column mean value  median value  mode value  serta constant value",
          "document_id": 1193
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa kelemahan dari metode undersampling ",
              "id": 3047,
              "answers": [
                {
                  "answer_id": 1661,
                  "document_id": 1204,
                  "question_id": 3047,
                  "text": "kelemahannya berpotensi mengeliminasi sampel yang berkualitas untuk proses pembelajaran",
                  "answer_start": 126,
                  "answer_end": 213,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "metodenya yaitu undersampling  oversampling  dan hybrid sampling undersampling akan mengeliminasi sampel dari kelas mayoritas kelemahannya berpotensi mengeliminasi sampel yang berkualitas untuk proses pembelajaran keuntungannya dapat mempercepat proses pelatihan karena jumlah dataset berkurang jenisnya yaitu random undersampling  tomek link  dan edited nearest neighbor  enn",
          "document_id": 1204
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "kenapa diperlukan transformasi data numeric ke categorical?",
              "id": 3168,
              "answers": [
                {
                  "answer_id": 1513,
                  "document_id": 1210,
                  "question_id": 3168,
                  "text": "transformasi nilai numerik ke categorical diperlukan karena beberapa algoritma ml  seperti decision tree atau rule based algorithm memerlukan input berupa kategori atau variabel ordinal serta banyak algoritma ml yang bekerja lebih baik saat variabel input numerik yang digunakan mengikuti standard probability distribution",
                  "answer_start": 151,
                  "answer_end": 473,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "setiap nilai kategori dalam variabel akan diubah menjadi nilai biner dapat diimplementasikan menggunakan class onehotencoder dari library scikit learn transformasi nilai numerik ke categorical diperlukan karena beberapa algoritma ml  seperti decision tree atau rule based algorithm memerlukan input berupa kategori atau variabel ordinal serta banyak algoritma ml yang bekerja lebih baik saat variabel input numerik yang digunakan mengikuti standard probability distribution solusinya transformasi variabel numerik menjadi nilai diskret dimana setiap nilai diberikan label yang memiliki keterurutan discretization adalah transformasi nilai variabel input output numerik menjadi nilai diskret atau label ordinal",
          "document_id": 1210
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa algoritma ml yang dapat digunakan saat dataset tidak seimbang?",
              "id": 3296,
              "answers": [
                {
                  "answer_id": 1663,
                  "document_id": 1214,
                  "question_id": 3296,
                  "text": "beberapa algoritma ml juga robust saat digunakan pada kasus dataset tidak seimbang seperti decision tree  random forest  gradient boosted tree",
                  "answer_start": 143,
                  "answer_end": 285,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "memodifikasi algoritma klasifikasi agar dapat secara spesifik menangani dataset tidak seimbang tanpa mengubah distribusi dari original dataset beberapa algoritma ml juga robust saat digunakan pada kasus dataset tidak seimbang seperti decision tree  random forest  gradient boosted tree cost sensitive method akan memberikan misclassification cost yang lebih tinggi untuk sampel dari kelas minoritas  dibanding cost untuk sampel dari kelas mayoritas image augmentation digunakan untuk meningkatkan jumlah training image dengan memodifikasi training image yang ada menggunakan metode atau teknik tertentu image baru yang dihasilkan memiliki kelas data yang sama sesuai dengan image asli yang dimodifikasi",
          "document_id": 1214
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu sampel adasyn?",
              "id": 3186,
              "answers": [
                {
                  "answer_id": 1534,
                  "document_id": 1224,
                  "question_id": 3186,
                  "text": "adasyn adalah sampel dari kelas minoritas diciptakan berdasarkan distribusi densitasnya ",
                  "answer_start": 0,
                  "answer_end": 88,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "adasyn adalah sampel dari kelas minoritas diciptakan berdasarkan distribusi densitasnya adasyn menghasilkan lebih banyak data sintetis dari kelas minortas yang lebih sulit dipelajari dibandingkan dengan sampel minoritas yang lebih mudah dipelajari dapat diimplementasikan dengan class adasyn dari library imblearn over_sampling hybrid method adalah kombinasi dari oversampling dan undersampling untuk menyeimbangkan jumlah sampel dari setiap kelas dalam dataset",
          "document_id": 1224
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara memperbaiki structural errors?",
              "id": 3193,
              "answers": [
                {
                  "answer_id": 1543,
                  "document_id": 1196,
                  "question_id": 3193,
                  "text": "memperbaiki structural errors yang mana meliputi perbaikan kesalahan pada penamaan  typo  incorrect capitalization  atau inkonsistensi pada kategori atau pelabelan data  merapikan isi kolom date of publication dan isi kolom place of publication",
                  "answer_start": 299,
                  "answer_end": 543,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "mengidentifikasi dan hapus duplikasi baris data yang dapat terjadi saat pengumpulan data dari beberapa sumber atau pengulangan observasi eksperimen duplikasi baris tidak memberikan informasi tambahan dan dapat mengakibatkan bias pada evaluasi model tugas kedua dalam data cleaning selanjutnya yaitu memperbaiki structural errors yang mana meliputi perbaikan kesalahan pada penamaan  typo  incorrect capitalization  atau inkonsistensi pada kategori atau pelabelan data  merapikan isi kolom date of publication dan isi kolom place of publication selain itu  terdapat penanganan outlier dalam tugas data cleaning tidak ada definisi dan metode yang pasti untuk mengidentifikasi outlier karena bergantung pada dataset yang spesifik",
          "document_id": 1196
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja langkah metode filter?",
              "id": 3185,
              "answers": [
                {
                  "answer_id": 1533,
                  "document_id": 1226,
                  "question_id": 3185,
                  "text": "metode filter biasanya terdiri atas dua langkah  yaitu  1  merangking fitur berdasarkan kriteria tertentu dengan melakukan evaluasi fitur yang dapat dilakukan secara univariate  setiap feature di ranking secara independen  sehingga tidak mampu menangani redundant features  atau multivariate  pe rangking an fitur dilakukan secara batch  mampu menangani redundant features  dan  2  sejumlah fitur dengan ranking tertinggi dipilih sebagai input ke algoritma pembelajaran ",
                  "answer_start": 217,
                  "answer_end": 687,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "filter method tidak memiliki ketergantungan  indenpenden  terhadap algoritma pembelajaran yang digunakan contoh  fisher score  information gain  relief  relieff  fast correlation based filter  fcbf   chi squared  dll metode filter biasanya terdiri atas dua langkah  yaitu  1  merangking fitur berdasarkan kriteria tertentu dengan melakukan evaluasi fitur yang dapat dilakukan secara univariate  setiap feature di ranking secara independen  sehingga tidak mampu menangani redundant features  atau multivariate  pe rangking an fitur dilakukan secara batch  mampu menangani redundant features  dan  2  sejumlah fitur dengan ranking tertinggi dipilih sebagai input ke algoritma pembelajaran kelebihan filter method yaitu  1  independen terhadap algoritma pembelajaran sehingga bias pada algoritma pembelajaran tidak akan berpengaruh terhadap proses seleksi fitur dan  2  waktu komputasi yang lebih cepat   efisien kekurangan filter method yaitu akurasi pada algoritma pembelajaran bisa jadi tidak optimal karena tidak dilibatkan dalam proses seleksi fitur",
          "document_id": 1226
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa cara popular untuk mengubah data categorical ke numerik?",
              "id": 3188,
              "answers": [
                {
                  "answer_id": 1537,
                  "document_id": 1211,
                  "question_id": 3188,
                  "text": "cara yang populer untuk mengubah data categorical ke numerik adalah dengan ordinal encoding dan one hot encoding",
                  "answer_start": 0,
                  "answer_end": 112,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "cara yang populer untuk mengubah data categorical ke numerik adalah dengan ordinal encoding dan one hot encoding ordinal encoding digunakan untuk encoding variabel ordinal ke nilai numerik setiap nilai kategori unik dikonversi ke nilai integer urutan nilai integer secara natural juga merepresentasikan urutan di dalam nilai nilai variabel ordinal tersebut dalam diimplementasikan menggunakan class ordinalencoder dari library scikit learn",
          "document_id": 1211
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "sampel dikatakan outlier jika apa?",
              "id": 3294,
              "answers": [
                {
                  "answer_id": 1659,
                  "document_id": 1191,
                  "question_id": 3294,
                  "text": "sampel dikatakan outlier jika memiliki density yang jauh lebih rendah dari tetangganya",
                  "answer_start": 162,
                  "answer_end": 248,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "metode ini menggunakan ide konsep nearest neighbors untuk identifikasi outlier lof menghitung deviasi local density dari titik data tertentu terhadap tetangganya sampel dikatakan outlier jika memiliki density yang jauh lebih rendah dari tetangganya setiap sampel akan diberi skor untuk mengindikasikan tingkat isolasi berdasarkan ukurannya terhadap local neighborhood tugas keempat dalam data cleaning yaitu menangani missing value",
          "document_id": 1191
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "algoritma apa yang hanya menggunakan nilai numerik?",
              "id": 3192,
              "answers": [
                {
                  "answer_id": 1542,
                  "document_id": 1201,
                  "question_id": 3192,
                  "text": "beberapa algoritma ml mengharuskan semua nilai variabel input dan output berupa nilai numerik  seperti artificial neural network  support vector machine  dsb",
                  "answer_start": 133,
                  "answer_end": 290,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "variabel ordinal adalah variabel yang terdiri atas sekumpulan nilai diskret dengan adanya keterurutan di antara nilai nilai tersebut beberapa algoritma ml mengharuskan semua nilai variabel input dan output berupa nilai numerik  seperti artificial neural network  support vector machine  dsb jika variabel input atau output mengandung categorical data  maka harus diubah ke bentuk numerik cara yang populer untuk mengubah data categorical ke numerik adalah dengan ordinal encoding dan one hot encoding ordinal encoding digunakan untuk encoding variabel ordinal ke nilai numerik",
          "document_id": 1201
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja kategori dari ekstraksi fitur?",
              "id": 3303,
              "answers": [
                {
                  "answer_id": 1673,
                  "document_id": 1230,
                  "question_id": 3303,
                  "text": "dua kategori utama ekstraksi fitur adalah linear dan non linear ",
                  "answer_start": 0,
                  "answer_end": 64,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "dua kategori utama ekstraksi fitur adalah linear dan non linear linear feature extraction memproyeksikan mentransformasi data secara linear contoh   pca  principle component analysis   lda  linear discriminant analysis nonlinear feature extraction memetakan data ke high dimensional space menggunakan lifting function sehingga relasi antarfitur dapat dipandang secara linear dan lebih mudah dideteksi  lalu data dipetakan lagi ke ruang dimensi yang lebih rendah sehingga relasi antar fitur kini dapat dipandang secara non linear contoh   wavelet transform  radon transform",
          "document_id": 1230
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara kerja estimated nearest neighbor?",
              "id": 3170,
              "answers": [
                {
                  "answer_id": 1515,
                  "document_id": 1216,
                  "question_id": 3170,
                  "text": "cara kerja estimated nearest neighbors yaitu instance dari kelas mayoritas dihapus berdasarkan k tetangga terdekatnya",
                  "answer_start": 15,
                  "answer_end": 132,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "under_sampling cara kerja estimated nearest neighbors yaitu instance dari kelas mayoritas dihapus berdasarkan k tetangga terdekatnya dapat diimplementasikan menggunakan class editednearestneighbours dari library imblearn under_sampling oversampling akan meningkatkan jumlah sampel dari kelas minoritas",
          "document_id": 1216
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana cara transformasi variabel numerik menjadi nilai diskret?",
              "id": 3298,
              "answers": [
                {
                  "answer_id": 1666,
                  "document_id": 1221,
                  "question_id": 3298,
                  "text": "transformasi variabel numerik menjadi nilai diskret dimana setiap nilai diberikan label yang memiliki keterurutan",
                  "answer_start": 10,
                  "answer_end": 123,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "solusinya transformasi variabel numerik menjadi nilai diskret dimana setiap nilai diberikan label yang memiliki keterurutan discretization adalah transformasi nilai variabel input output numerik menjadi nilai diskret atau label ordinal nilai untuk variabel dikelompokkan menjadi sejumlah discrete bins dan setiap keterurutan di antara sejumlah bin tersebut discretization disebut juga sebagai binning atau k bins  dengan k adalah jumlah kelompok hasil mapping variabel numerik terdapat 3 jenis strategi dalam discretization yaitu uniform  quantile  dan clustered",
          "document_id": 1221
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana algoritma fisher score bekerja?",
              "id": 3301,
              "answers": [
                {
                  "answer_id": 1671,
                  "document_id": 1234,
                  "question_id": 3301,
                  "text": "algoritma fisher score mengevaluasi fitur secara independen sehingga tidak mampu menangani redundant features",
                  "answer_start": 0,
                  "answer_end": 109,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "algoritma fisher score mengevaluasi fitur secara independen sehingga tidak mampu menangani redundant features algoritma information gain mengukur dependensi antara fitur terhadap label kelas sebuah fitur dikatakan relevan jika mempunyai nilai ig yang tinggi algoritma relief menghitung bobot  quality estimation  untuk setiap fitur berdasarkan kemampuannya untuk membedakan sampel terdekat algoritma relief memilih sampel r i secara random  lalu mencari sampel terdekat dari kelas yang sama  nearest hit  dan sampel terdekat dari kelas yang berbeda  nearest mist",
          "document_id": 1234
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa itu nonlinear feature extraction?",
              "id": 3173,
              "answers": [
                {
                  "answer_id": 1532,
                  "document_id": 1227,
                  "question_id": 3173,
                  "text": "nonlinear feature extraction memetakan data ke high dimensional space menggunakan lifting function sehingga relasi antarfitur dapat dipandang secara linear dan lebih mudah dideteksi  lalu data dipetakan lagi ke ruang dimensi yang lebih rendah sehingga relasi antar fitur kini dapat dipandang secara non linear",
                  "answer_start": 0,
                  "answer_end": 309,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "nonlinear feature extraction memetakan data ke high dimensional space menggunakan lifting function sehingga relasi antarfitur dapat dipandang secara linear dan lebih mudah dideteksi  lalu data dipetakan lagi ke ruang dimensi yang lebih rendah sehingga relasi antar fitur kini dapat dipandang secara non linear contoh   wavelet transform  radon transform pca  principal component analysis  adalah transformasi linear yang dapat digunakan untuk mereduksi dimensi data  namun tetap mempertahankan informasi yang penting sebanyak mungkin pca melakukan transformasi linear dengan memilih sistem koordinat baru untuk dataset sedemikian hingga varians terbesar oleh proyeksi tertentu dari dataset terletak pada sumbu pertama  kemudian disebut sebagai principal component pertama   varians terbesar kedua pada sumbu kedua  dan seterusnya principal component didapat dengan menemukan pasangan eigenvalues and eigenvectors dari covariance matrix dataset",
          "document_id": 1227
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "dimana imbalance dataset dapat ditemukan?",
              "id": 3163,
              "answers": [
                {
                  "answer_id": 1508,
                  "document_id": 1202,
                  "question_id": 3163,
                  "text": "kasus imbalance dataset dapat ditemukan dalam berbagai domain seperti fraud detection  spam filtering  prediksi penyakit di bidang kesehatan  customer churn prediction  dll",
                  "answer_start": 0,
                  "answer_end": 172,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "kasus imbalance dataset dapat ditemukan dalam berbagai domain seperti fraud detection  spam filtering  prediksi penyakit di bidang kesehatan  customer churn prediction  dll klasifikasi pada imbalanced dataset biasanya menghasilkan akurasi yang baik secara keseluruhan  tetapi akurasi di setiap kelasnya tidak merata  biasanya akurasi pada kelas minoritas menurun drastis imbalance ratio  ir  adalah rasio antara jumlah sampel di kelas mayoritas terhadap jumlah sampel di kelas minoritas imbalanced ratio dapat dihitung dengan membagi jumlah sampel di kelas mayoritas dengan jumlah sampel di kelas minoritas metode resampling menyeimbangkan ruang sampel dengan cara menyamakan jumlah sampel data di setiap kelas",
          "document_id": 1202
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "algoritma ml apa yang bisa digunakan dengan kasus dataset tidak seimbang?",
              "id": 3166,
              "answers": [
                {
                  "answer_id": 1511,
                  "document_id": 1207,
                  "question_id": 3166,
                  "text": "beberapa algoritma ml juga robust saat digunakan pada kasus dataset tidak seimbang seperti decision tree  random forest  gradient boosted tree",
                  "answer_start": 398,
                  "answer_end": 540,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "over_sampling hybrid method adalah kombinasi dari oversampling dan undersampling untuk menyeimbangkan jumlah sampel dari setiap kelas dalam dataset biasanya algoritma smote digunakan sebagai oversampling sedangkan tomeklink atau enn sebagai undersampling memodifikasi algoritma klasifikasi agar dapat secara spesifik menangani dataset tidak seimbang tanpa mengubah distribusi dari original dataset beberapa algoritma ml juga robust saat digunakan pada kasus dataset tidak seimbang seperti decision tree  random forest  gradient boosted tree",
          "document_id": 1207
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa yang dilakukan oleh ekstraksi fitur?",
              "id": 3176,
              "answers": [
                {
                  "answer_id": 1522,
                  "document_id": 1233,
                  "question_id": 3176,
                  "text": "ekstraksi fitur memetakan original feature space ke new feature space dengan dimensionality yang lebih rendah",
                  "answer_start": 0,
                  "answer_end": 109,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "ekstraksi fitur memetakan original feature space ke new feature space dengan dimensionality yang lebih rendah   namun tetap mempertahankan informasi yang penting sebanyak mungkin fitur diekstrak dari kombinasi fitur yang asli sehingga berada pada feature space atau domain data yang baru yang berbeda fitur aslinya akibatnya   sulit untuk mengkaitkan hasil ekstraksi fitur dengan fitur aslinya untuk analisis fitur lebih lanjut dua kategori utama ekstraksi fitur adalah linear dan non linear linear feature extraction memproyeksikan mentransformasi data secara linear",
          "document_id": 1233
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana statistical imputation menggantikan missing value?",
              "id": 3295,
              "answers": [
                {
                  "answer_id": 1660,
                  "document_id": 1197,
                  "question_id": 3295,
                  "text": "statistical imputation menggunakan metode statistik untuk mengestimasi nilai pada sebuah kolom yang terdapat missing value  lalu menggantikan semua missing value dengan nilai tersebut ",
                  "answer_start": 0,
                  "answer_end": 184,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "statistical imputation menggunakan metode statistik untuk mengestimasi nilai pada sebuah kolom yang terdapat missing value  lalu menggantikan semua missing value dengan nilai tersebut contohnya yaitu column mean value  median value  mode value  serta constant value column mode value dapat diterapkan pada data categorical pada knn imputation  sampel baru diperhitungkan dengan menemukan sejumlah sampel dalam training set yang  paling dekat  dengannya  kemudian nilai sampel yang kosong pada kolom tertentu diisi berdasarkan nilai sample terdekat pada kolom tersebut untuk menerapkan knn imputation dengan tepat  sebaiknya knn imputation hanya dihitung pada latih saja  lalu hasil yang didapat baru diterapkan pada data uji",
          "document_id": 1197
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "class apa yang digunakan untuk mengimplementasikan random undersampling ",
              "id": 3048,
              "answers": [
                {
                  "answer_id": 1388,
                  "document_id": 1212,
                  "question_id": 3048,
                  "text": " classs randomundersampler dari library imblearn under_sampling",
                  "answer_start": 539,
                  "answer_end": 602,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "keuntungannya dapat mempercepat proses pelatihan karena jumlah dataset berkurang jenisnya yaitu random undersampling  tomek link  dan edited nearest neighbor  enn random undersampling adalah metode non heuristic yang mengeliminasi sampel dari kelas mayoritas secara random sehingga jumlahnya sama dengan kelas minoritas  karena eliminasi sampel dilakukan secara random  maka sangat berpotensi menghilangkan sampel yang penting atau menjadikan sampel yang ada tidak merepresentasikan populasi secara umum dapat diimplementasikan menggunakan classs randomundersampler dari library imblearn under_sampling",
          "document_id": 1212
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "smote adalah sampel apa?",
              "id": 3187,
              "answers": [
                {
                  "answer_id": 1536,
                  "document_id": 1217,
                  "question_id": 3187,
                  "text": "smote adalah sebuah sampel sintetis dari kelas minoritas dibuat dengan cara interpolasi di antara k tetangga terdekatnya",
                  "answer_start": 0,
                  "answer_end": 120,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "smote adalah sebuah sampel sintetis dari kelas minoritas dibuat dengan cara interpolasi di antara k tetangga terdekatnya dapat diimlementasikan menggunakan class smote dari library imblearn over_sampling adasyn adalah sampel dari kelas minoritas diciptakan berdasarkan distribusi densitasnya adasyn menghasilkan lebih banyak data sintetis dari kelas minortas yang lebih sulit dipelajari dibandingkan dengan sampel minoritas yang lebih mudah dipelajari",
          "document_id": 1217
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa saja metode seleksi fitur?",
              "id": 3183,
              "answers": [
                {
                  "answer_id": 1530,
                  "document_id": 1229,
                  "question_id": 3183,
                  "text": "berdasarkan ada tidaknya label pada data  metode seleksi fitur dibagi menjadi supervised  unsupervised  dan semi supervised ",
                  "answer_start": 0,
                  "answer_end": 124,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "berdasarkan ada tidaknya label pada data  metode seleksi fitur dibagi menjadi supervised  unsupervised  dan semi supervised feature selection supervised feature selection dibagi menjadi  filter method  wrapper method  dan embedded method filter method memilih subset fitur yang signifikan berdasarkan karakteristik intrinsik pada data latih seperti distance  consistency  dependency  information  dan correlation filter method tidak memiliki ketergantungan  indenpenden  terhadap algoritma pembelajaran yang digunakan contoh  fisher score  information gain  relief  relieff  fast correlation based filter  fcbf   chi squared  dll",
          "document_id": 1229
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagaimana algoritma relieff menghitung bobot?",
              "id": 3300,
              "answers": [
                {
                  "answer_id": 1670,
                  "document_id": 1235,
                  "question_id": 3300,
                  "text": "algoritma relief menghitung bobot  quality estimation  untuk setiap fitur berdasarkan kemampuannya untuk membedakan sampel terdekat",
                  "answer_start": 0,
                  "answer_end": 131,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "algoritma relief menghitung bobot  quality estimation  untuk setiap fitur berdasarkan kemampuannya untuk membedakan sampel terdekat algoritma relief memilih sampel r i secara random  lalu mencari sampel terdekat dari kelas yang sama  nearest hit  dan sampel terdekat dari kelas yang berbeda  nearest mist jika nilai fitur a pada sampel r i dan nearest hit adalah berbeda  maka bobot fitur a akan diturunkan sebaliknya  jika nilai fitur a pada sampel r i dan nearest miss adalah berbeda  maka bobot fitur a akan ditingkatkan algoritma relief mampu menangani fitur kategorikal maupun numerik  namun tidak dapat menangani data yang tidak lengkap  dan terbatas untuk permasalahan klasifikasi biner",
          "document_id": 1235
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa perbedaan dari seleksi fitur dan ekstraksi fitur?",
              "id": 3304,
              "answers": [
                {
                  "answer_id": 1674,
                  "document_id": 1228,
                  "question_id": 3304,
                  "text": "seleksi fitur akan memilih subset fitur yang signifikan dan nilai fitur tetap berada pada domain aslinya sedangkan ekstraksi fitur akan mengekstrak fitur ke dalam format tertentu dan nilai hasil ekstraksi fitur berada pada domain yang berbeda dengan data aslinya",
                  "answer_start": 0,
                  "answer_end": 262,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "seleksi fitur akan memilih subset fitur yang signifikan dan nilai fitur tetap berada pada domain aslinya sedangkan ekstraksi fitur akan mengekstrak fitur ke dalam format tertentu dan nilai hasil ekstraksi fitur berada pada domain yang berbeda dengan data aslinya reduksi dimensi bertujuan untuk menghapus fitur yang tidak relevan atau tidak berkontribusi banyak terhadap variabel target untuk mencapai akurasi model yang lebih baik  mencegah mengurangi resiko overfitting  mempercepat waktu komputasi  mengurangi kompleksitas model sehingga lebih mudah untuk direpresentasikan  noise removal  kompresi data  efisiensi storage   retrieval berdasarkan ada tidaknya label pada data  metode seleksi fitur dibagi menjadi supervised  unsupervised  dan semi supervised feature selection supervised feature selection dibagi menjadi  filter method  wrapper method  dan embedded method",
          "document_id": 1228
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "apa contoh randomized wrapper method ",
              "id": 3069,
              "answers": [
                {
                  "answer_id": 1404,
                  "document_id": 1232,
                  "question_id": 3069,
                  "text": " genetic algorithm  particle swarm optimization  artificial bee colony",
                  "answer_start": 592,
                  "answer_end": 662,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "biasanya mampu mencapai predicitive accuracy pada algoritma pembelajaran dibandingkan dengan filter method langkah langkah dalam wrapper method yaitu  1  mencari subset fitur   2  menggunakan subset fitur yang dipilih pada langkah 1 secara langsung pada algoritma pembelajaran yang digunakan  lalu mengevaluasi performa algoritma pembelajaran pada subset fitur tersebut   3  mengulangi langkah 1 dan 2 hingga kondisi berhenti atau kriteria evaluasi tertentu terpenuhi contoh  forward selection  backward elimination  bi directional elimination  stepwise selection   randomized wrapper method  genetic algorithm  particle swarm optimization  artificial bee colony embedded method menggabungkan kelebihan filter dan wrapper method dengan cara meng embed proses seleksi fitur dengan pembangunan model classifier namun  embedded method tidak mencoba semua kemungkinan subset fitur seperti pada wrapper method  sehingga waktu komputasi yang diperlukan lebih reasonable dan risiko overfitting juga lebih kecil dibanding dengan wrapper method",
          "document_id": 1232
        }
      ]
    },
    {
      "paragraphs": [
        {
          "qas": [
            {
              "question": "bagimana pca melakukan transformasi linear?",
              "id": 3299,
              "answers": [
                {
                  "answer_id": 1669,
                  "document_id": 1236,
                  "question_id": 3299,
                  "text": "pca melakukan transformasi linear dengan memilih sistem koordinat baru untuk dataset sedemikian hingga varians terbesar oleh proyeksi tertentu dari dataset terletak pada sumbu pertama  kemudian disebut sebagai principal component pertama   varians terbesar kedua pada sumbu kedua  dan seterusnya ",
                  "answer_start": 0,
                  "answer_end": 296,
                  "answer_category": null
                }
              ],
              "is_impossible": false
            }
          ],
          "context": "pca melakukan transformasi linear dengan memilih sistem koordinat baru untuk dataset sedemikian hingga varians terbesar oleh proyeksi tertentu dari dataset terletak pada sumbu pertama  kemudian disebut sebagai principal component pertama   varians terbesar kedua pada sumbu kedua  dan seterusnya principal component didapat dengan menemukan pasangan eigenvalues and eigenvectors dari covariance matrix dataset eigenvector merupakan arah sumbu yang memiliki varians paling banyak  sebagian besar informasi   disebut sebagai principal component eigenvalue adalah koefisien yang melekat pada eigenvector yang memberikan jumlah varians yang dibawa dalam setiap principal component algoritma pca terdiri dari step 1  standardisasi  step 2  menghitung covariance matrix  step 3  menghitung eigenvectors dan eigenvalues dari covariance matrix  step 4  memilih principal component untuk membentuk vektor fitur  step 5  menurunkan dataset baru hasil transformasi  dan getting data back  mengembalikan dataset hasil transformasi ke original data",
          "document_id": 1236
        }
      ]
    }
  ]
}